"""
ë…¸ì¸ë³µì§€ RAG ì‹œìŠ¤í…œ - ì„¤ì • íŒŒì¼

ì‹œìŠ¤í…œ ì „ì—­ ì„¤ì •ê³¼ í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬
"""

import os
import logging
from typing import Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# ============== ê¸°ë³¸ ì„¤ì • ==============

# OpenAI ì„¤ì •
OPENAI_MODEL = "gpt-4o-mini"
OPENAI_EMB_MODEL = "text-embedding-ada-002"
TEMPERATURE = 0.1
MAX_TOKENS = 1000

# ë°ì´í„° ì²˜ë¦¬ ì„¤ì •
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200
TOP_K_RESULTS = 5
SIMILARITY_THRESHOLD = 0.7

# ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
GRADIO_SERVER_PORT = 7860
SHARE_GRADIO = False

# ë¡œê¹… ì„¤ì •
LOG_LEVEL = "INFO"
DEBUG_MODE = False

# íŒŒì¼ ê²½ë¡œ
DATA_DIR = os.path.join(PROJECT_ROOT, "data")
LOG_DIR = os.path.join(PROJECT_ROOT, "logs")
EMBEDDING_CACHE_DIR = os.path.join(PROJECT_ROOT, "embeddings_cache")
FEEDBACK_DB_PATH = os.path.join(PROJECT_ROOT, "user_feedback.db")
CHROMA_DB_DIR = os.path.join(PROJECT_ROOT, "chroma_db")

# ============== í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ ==============

def load_env_file():
    """í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ë¡œë“œ"""
    env_path = os.path.join(PROJECT_ROOT, ".env")
    if os.path.exists(env_path):
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip() and not line.startswith('#') and '=' in line:
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value

def get_openai_api_key() -> Optional[str]:
    """OpenAI API í‚¤ íšë“"""
    # 1. í™˜ê²½ë³€ìˆ˜ì—ì„œ í™•ì¸
    api_key = os.environ.get('OPENAI_API_KEY')
    if api_key and api_key != 'your-openai-api-key-here':
        return api_key
    
    # 2. openaikey.txt íŒŒì¼ì—ì„œ í™•ì¸
    key_file = os.path.join(PROJECT_ROOT, "openaikey.txt")
    if os.path.exists(key_file):
        try:
            with open(key_file, 'r', encoding='utf-8') as f:
                key = f.read().strip()
                if key and key != 'your-openai-api-key-here':
                    return key
        except Exception as e:
            logging.warning(f"openaikey.txt íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    return None

def setup_environment():
    """í™˜ê²½ ì„¤ì • ì´ˆê¸°í™”"""
    # í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ë¡œë“œ
    load_env_file()
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    for dir_path in [LOG_DIR, EMBEDDING_CACHE_DIR, DATA_DIR]:
        os.makedirs(dir_path, exist_ok=True)
    
    # OpenAI API í‚¤ ì„¤ì •
    api_key = get_openai_api_key()
    if api_key:
        os.environ['OPENAI_API_KEY'] = api_key
    
    return api_key is not None

def validate_config():
    """ì„¤ì • ê²€ì¦"""
    # API í‚¤ í™•ì¸
    api_key = get_openai_api_key()
    if not api_key:
        logging.warning("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        return False
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(DATA_DIR):
        logging.error(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {DATA_DIR}")
        return False
    
    welfare_data_dir = os.path.join(DATA_DIR, "ë³µì§€ë¡œ")
    if not os.path.exists(welfare_data_dir):
        logging.error(f"âŒ ë³µì§€ ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {welfare_data_dir}")
        return False
    
    logging.info("âœ… ì„¤ì • ê²€ì¦ ì™„ë£Œ")
    return True

def print_config():
    """í˜„ì¬ ì„¤ì • ì¶œë ¥"""
    api_key = get_openai_api_key()
    
    print("\nğŸ“‹ í˜„ì¬ ì„¤ì •:")
    print(f"  ğŸ”‘ API í‚¤: {'âœ… ì„¤ì •ë¨' if api_key else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"  ğŸ¤– ëª¨ë¸: {OPENAI_MODEL}")
    print(f"  ğŸ“Š ì„ë² ë”©: {OPENAI_EMB_MODEL}")
    print(f"  ğŸŒ¡ï¸ ì˜¨ë„: {TEMPERATURE}")
    print(f"  ğŸ“„ ì²­í¬ í¬ê¸°: {CHUNK_SIZE}")
    print(f"  ğŸ” ìƒìœ„ ê²°ê³¼: {TOP_K_RESULTS}")
    print(f"  ğŸŒ í¬íŠ¸: {GRADIO_SERVER_PORT}")
    print(f"  ğŸ“‚ ë°ì´í„°: {DATA_DIR}")
    print(f"  ğŸ“ ë¡œê·¸: {LOG_DIR}")
    print("")

# í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì • ì—…ë°ì´íŠ¸
def update_from_env():
    """í™˜ê²½ ë³€ìˆ˜ë¡œë¶€í„° ì„¤ì • ì—…ë°ì´íŠ¸"""
    global OPENAI_MODEL, OPENAI_EMB_MODEL, TEMPERATURE, MAX_TOKENS
    global CHUNK_SIZE, CHUNK_OVERLAP, TOP_K_RESULTS, SIMILARITY_THRESHOLD
    global GRADIO_SERVER_PORT, LOG_LEVEL, DEBUG_MODE
    
    # OpenAI ì„¤ì •
    OPENAI_MODEL = os.environ.get('OPENAI_MODEL', OPENAI_MODEL)
    OPENAI_EMB_MODEL = os.environ.get('EMBEDDING_MODEL', OPENAI_EMB_MODEL)
    TEMPERATURE = float(os.environ.get('TEMPERATURE', TEMPERATURE))
    MAX_TOKENS = int(os.environ.get('MAX_TOKENS', MAX_TOKENS))
    
    # RAG ì„¤ì •
    CHUNK_SIZE = int(os.environ.get('CHUNK_SIZE', CHUNK_SIZE))
    CHUNK_OVERLAP = int(os.environ.get('CHUNK_OVERLAP', CHUNK_OVERLAP))
    TOP_K_RESULTS = int(os.environ.get('TOP_K_RESULTS', TOP_K_RESULTS))
    SIMILARITY_THRESHOLD = float(os.environ.get('SIMILARITY_THRESHOLD', SIMILARITY_THRESHOLD))
    
    # ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
    GRADIO_SERVER_PORT = int(os.environ.get('GRADIO_SERVER_PORT', GRADIO_SERVER_PORT))
    
    # ë¡œê¹… ì„¤ì •
    LOG_LEVEL = os.environ.get('LOG_LEVEL', LOG_LEVEL)
    DEBUG_MODE = os.environ.get('DEBUG_MODE', 'False').lower() == 'true'

# ì´ˆê¸°í™”ì‹œ í™˜ê²½ë³€ìˆ˜ ì ìš©
update_from_env()