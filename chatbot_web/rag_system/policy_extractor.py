"""
ì •ì±… ì •ë³´ ì¶”ì¶œ ëª¨ë“ˆ - ê°œì„ ëœ ë²„ì „

PDF ë¬¸ì„œì—ì„œ ì •ì±…ëª…, ì„¤ëª…, ëŒ€ìƒì, ì‹ ì²­ë°©ë²• ë“±ì„ ì¶”ì¶œí•˜ì—¬ êµ¬ì¡°í™”
"""

import re
import logging
from typing import Dict, List, Optional, Any
from .policy_metadata import find_policy_metadata

logger = logging.getLogger(__name__)


class SimplePolicyExtractor:
    """ê°œì„ ëœ ì •ì±… ì •ë³´ ì¶”ì¶œê¸° - ë¶ˆí•„ìš”í•œ ì •ë³´ ê°•ë ¥ í•„í„°ë§"""

    def extract_from_text(self, text: str, question: str = "") -> Dict[str, str]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ì •ì±… ì •ë³´ ì¶”ì¶œ

        Returns:
            {
                'name': ì •ì±…ëª…,
                'description': ì„¤ëª…,
                'target': ëŒ€ìƒ,
                'benefits': í˜œíƒ,
                'application': ì‹ ì²­ë°©ë²•
            }
        """
        lines = [line.strip() for line in text.split('\n') if line.strip()]

        # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        question_keywords = self._extract_question_keywords(question)

        result = {
            'name': None,
            'description': None,
            'target': None,
            'benefits': None,
            'application': None
        }

        # ì •ì±…ëª… ì¶”ì¶œ
        result['name'] = self._find_policy_name(lines)

        # ê° í•­ëª©ë³„ë¡œ ê´€ë ¨ ë¬¸ì¥ ìˆ˜ì§‘ (ì—¬ëŸ¬ ê°œ ìˆ˜ì§‘ í›„ ê°€ì¥ ì¢‹ì€ ê²ƒ ì„ íƒ)
        target_candidates = []
        benefit_candidates = []
        application_candidates = []
        description_candidates = []

        for i, line in enumerate(lines):
            # ë„ˆë¬´ ì§§ê±°ë‚˜ ë©”íƒ€ë°ì´í„°ë©´ ìŠ¤í‚µ
            if len(line) < 20 or self._is_junk(line):
                continue

            # ë²•ë¥  ì¡°ë¬¸ë§Œ ìˆëŠ” ë¼ì¸ ì œì™¸
            if self._is_pure_law_reference(line):
                continue

            # ë¶€ì²˜ ì—°ë½ì²˜ë§Œ ìˆëŠ” ë¼ì¸ ì œì™¸
            if self._is_government_contact(line):
                continue

            cleaned_line = self._clean_sentence(line)

            # ëŒ€ìƒ ì°¾ê¸°
            if self._is_target_line(line):
                score = self._score_target_line(cleaned_line)
                if score > 0:
                    target_candidates.append((cleaned_line, score))

            # í˜œíƒ ì°¾ê¸°
            if self._is_benefit_line(line):
                score = self._score_benefit_line(cleaned_line)
                if score > 0:
                    benefit_candidates.append((cleaned_line, score))

            # ì‹ ì²­ ì°¾ê¸°
            if self._is_application_line(line):
                score = self._score_application_line(cleaned_line)
                if score > 0:
                    application_candidates.append((cleaned_line, score))

            # ì„¤ëª… ì°¾ê¸° (ë³µì§€ í‚¤ì›Œë“œ + ì„¤ëª… í‚¤ì›Œë“œ)
            if self._is_description_line(line, question_keywords):
                score = self._score_description_line(cleaned_line, question_keywords)
                if score > 0:
                    description_candidates.append((cleaned_line, score))

        # ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ í›„ë³´ ì„ íƒ
        if target_candidates:
            target_candidates.sort(key=lambda x: x[1], reverse=True)
            result['target'] = target_candidates[0][0][:200]

        if benefit_candidates:
            benefit_candidates.sort(key=lambda x: x[1], reverse=True)
            result['benefits'] = benefit_candidates[0][0][:200]

        if application_candidates:
            application_candidates.sort(key=lambda x: x[1], reverse=True)
            result['application'] = application_candidates[0][0][:200]

        if description_candidates:
            description_candidates.sort(key=lambda x: x[1], reverse=True)
            result['description'] = description_candidates[0][0][:250]

        return result

    def _extract_question_keywords(self, question: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not question:
            return []

        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = ['ëˆ„ê°€', 'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì–´ë””', 'ì–¸ì œ', 'ì™œ', 'ìˆë‚˜ìš”', 'ìˆì–´ìš”', 'ì•Œë ¤ì£¼ì„¸ìš”', 'ë­ì•¼', 'ì–´ë–¤', 'ê²ƒë“¤']
        words = re.findall(r'[ê°€-í£]{2,}', question)
        return [w for w in words if w not in stopwords]

    def _find_policy_name(self, lines: List[str]) -> Optional[str]:
        """ì •ì±…ëª… ì°¾ê¸° - ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„"""
        for line in lines[:10]:  # ì²« 10ì¤„ì—ì„œë§Œ ê²€ìƒ‰
            # 1. ã€Œì •ì±…ëª…ã€ íŒ¨í„´
            match = re.search(r'ã€Œ([^ã€]{3,40})ã€', line)
            if match:
                name = match.group(1)
                # ë²•ë¥ ëª… ì œì™¸
                if 'ë²•ë¥ ' not in name and 'ë²•' not in name[-1:]:
                    return name

            # 2. ìˆ«ì. ì •ì±…ëª… íŒ¨í„´
            match = re.match(r'^\d+[\.\)]\s*(.+)', line)
            if match:
                name = match.group(1).strip()
                if 5 <= len(name) <= 50 and any(kw in name for kw in ['ì‚¬ì—…', 'ì§€ì›', 'ì„œë¹„ìŠ¤', 'ì œë„', 'ê¸‰ì—¬', 'ì—°ê¸ˆ', 'ìˆ˜ë‹¹']):
                    return name

            # 3. ë³µì§€ í‚¤ì›Œë“œ + ì •ì±… í‚¤ì›Œë“œ
            if any(kw in line for kw in ['ë…¸ì¸', 'ì–´ë¥´ì‹ ', 'ê²½ë¡œ', 'ì¥ê¸°ìš”ì–‘', 'ê¸°ì´ˆì—°ê¸ˆ']):
                if any(kw in line for kw in ['ì‚¬ì—…', 'ì§€ì›', 'ì„œë¹„ìŠ¤', 'ì œë„', 'ê¸‰ì—¬', 'ì—°ê¸ˆ', 'ìˆ˜ë‹¹']):
                    if 5 <= len(line) <= 50:
                        return line

        return None

    def _is_target_line(self, line: str) -> bool:
        """ëŒ€ìƒì ê´€ë ¨ ë¬¸ì¥ì¸ì§€ í™•ì¸"""
        keywords = ['ëŒ€ìƒ', 'ì‹ ì²­ìê²©', 'ìˆ˜ê¸‰ê¶Œì', 'ë°›ì„ ìˆ˜ ìˆ', 'ì´ìš©í•  ìˆ˜ ìˆ', 'ì‹ ì²­í•  ìˆ˜ ìˆ', 'í•´ë‹¹í•˜ëŠ” ì‚¬ëŒ', 'í•´ë‹¹ì']
        return any(kw in line for kw in keywords)

    def _is_benefit_line(self, line: str) -> bool:
        """í˜œíƒ ê´€ë ¨ ë¬¸ì¥ì¸ì§€ í™•ì¸"""
        keywords = ['ì§€ì›ë‚´ìš©', 'í˜œíƒ', 'ê¸‰ì—¬', 'ë¬´ë£Œ', 'í• ì¸', 'ê°ë©´', 'ì§€ê¸‰', 'ì œê³µ']
        has_keyword = any(kw in line for kw in keywords)
        # ê¸ˆì•¡ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ìš°ì„ 
        has_amount = bool(re.search(r'\d+[ë§Œì›ì²œë°±ì‹­ì–µì¡°]', line))
        return has_keyword or has_amount

    def _is_application_line(self, line: str) -> bool:
        """ì‹ ì²­ë°©ë²• ê´€ë ¨ ë¬¸ì¥ì¸ì§€ í™•ì¸"""
        keywords = ['ì‹ ì²­ë°©ë²•', 'ì‹ ì²­ì ˆì°¨', 'ì£¼ë¯¼ì„¼í„°', 'êµ¬ì²­', 'ì‹œì²­', 'ìë©´ë™', 'ë™ì‚¬ë¬´ì†Œ', 'ë¬¸ì˜', 'ë‹´ë‹¹', 'ì ‘ìˆ˜']
        has_keyword = any(kw in line for kw in keywords)
        # ì „í™”ë²ˆí˜¸ íŒ¨í„´
        has_phone = bool(re.search(r'\d{2,4}[- ]\d{3,4}[- ]\d{4}', line))
        return has_keyword or has_phone

    def _is_description_line(self, line: str, question_keywords: List[str]) -> bool:
        """ì„¤ëª… ë¬¸ì¥ì¸ì§€ í™•ì¸"""
        # ì§ˆë¬¸ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìš°ì„ 
        if question_keywords and any(kw in line for kw in question_keywords):
            return True

        # ë³µì§€ + ì„¤ëª… í‚¤ì›Œë“œ
        welfare_kw = ['ë…¸ì¸', 'ì–´ë¥´ì‹ ', 'ëŒ€ìƒ', 'í˜œíƒ', 'ë³µì§€', 'ê¸‰ì—¬', 'ì§€ì›', 'ì œê³µ', 'ê³ ë ¹ì']
        desc_kw = ['ì§€ì›', 'ì œê³µ', 'ì‹¤ì‹œ', 'ìš´ì˜', 'ìœ„í•œ', 'ìœ„í•´', 'ëª©ì ', 'ì‚¬ì—…', 'ì„œë¹„ìŠ¤', 'í”„ë¡œê·¸ë¨']

        has_welfare = any(kw in line for kw in welfare_kw)
        has_desc = any(kw in line for kw in desc_kw)

        return has_welfare and has_desc

    def _is_junk(self, line: str) -> bool:
        """ë¬´ìš©í•œ ë©”íƒ€ë°ì´í„°ì¸ì§€ í™•ì¸"""
        junk_patterns = [
            r'^ì œ\d+ì¡°',  # ë²•ì¡°ë¬¸
            r'ë²•ë¥ \s*ì œ\d+í˜¸',
            r'í˜ì´ì§€|ë²•ì œì²˜|êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°',
            r'ë°œê°„ë“±ë¡ë²ˆí˜¸',
            r'Ministry|www\.|http',
            r'^\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼$',  # ë‚ ì§œë§Œ ìˆëŠ” ì¤„
            r'^-{3,}$',  # êµ¬ë¶„ì„ ë§Œ
            r'^[â—‹â—â– â–¡â—‡â—†â–¶â–·]\s*$',  # ë¶ˆë¦¿ë§Œ
        ]

        for pattern in junk_patterns:
            if re.search(pattern, line):
                return True

        return False

    def _is_pure_law_reference(self, line: str) -> bool:
        """ë²•ë¥  ì¡°ë¬¸ ì°¸ì¡°ë§Œ ìˆëŠ” ë¼ì¸ì¸ì§€ í™•ì¸ - ë§¤ìš° ê°•ë ¥í•˜ê²Œ"""
        # 1. ë²•ë¥ ëª…ì´ í¬í•¨ë˜ë©´ ë¬´ì¡°ê±´ ì œì™¸
        if 'ã€Œ' in line and 'ã€' in line:
            return True

        # 2. "ì´í•˜ "ì•½ì¹­"" íŒ¨í„´
        if re.search(r'ì´í•˜\s*["\']', line):
            return True

        # 3. "ì œXì¡°", "ì œXí•­", "ì œXí˜¸" ë“± ì¡°ë¬¸ íŒ¨í„´
        if re.search(r'ì œ\d+ì¡°|ì œ\d+í•­|ì œ\d+í˜¸', line):
            return True

        # 4. ì¡°í•­ ë²ˆí˜¸ë¡œ ì‹œì‘ (â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©)
        if re.match(r'^[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]', line):
            return True

        # 5. ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì¡°í•­ (1. 2. 3. 4. ë“±)
        if re.match(r'^\d+\.\s', line):
            return True

        # 6. "ì´ ë²•ì€", "ì´ ì˜ì€" ë“± ë²•ë ¹ ë¬¸êµ¬
        if re.search(r'ì´\s*ë²•ì€|ì´\s*ì˜ì€|ì´\s*ê·œì¹™ì€', line):
            return True

        # 7. "ê³µí¬", "ì‹œí–‰" ë“± ë²•ë ¹ ì‹œí–‰ì¼ ê´€ë ¨
        if 'ê³µí¬' in line and 'ì‹œí–‰' in line:
            return True

        # 8. "ë‹¤ë§Œ," ë˜ëŠ” "ë‹¨ì„œ" ë“± ë²•ë¥  íŠ¹ìœ  í‘œí˜„
        if re.search(r'ë‹¤ë§Œ,|ë‹¨ì„œ|ë¶€ì¹™|ì‹œí–‰ë ¹|ì‹œí–‰ê·œì¹™', line):
            return True

        # 9. "ê·€í•˜ì˜ ë³´í˜¸ì, ì§€ì›ê¸°ê´€" ë“± ì„œì‹ ë‚´ìš©
        if 'ê·€í•˜ì˜' in line and ('ë³´í˜¸ì' in line or 'ì§€ì›ê¸°ê´€' in line):
            return True

        # 10. "ì§ˆë³‘ê´€ë¦¬ì²­ì¥", "íŠ¹ë³„ìì¹˜ì‹œì¥" ë“± í–‰ì • ìš©ì–´
        if any(kw in line for kw in ['ì§ˆë³‘ê´€ë¦¬ì²­ì¥', 'íŠ¹ë³„ìì¹˜ì‹œì¥', 'íŠ¹ë³„ìì¹˜ë„ì§€ì‚¬', 'ë³´ìƒì²­êµ¬ì„œ', 'ì²¨ë¶€í•˜ì—¬']):
            return True

        # 11. "ë³€ê²½ï¼š", "ì¤‘ì§€ï¼š" ë“± ì•ˆë‚´ë¬¸ íŒ¨í„´
        if re.match(r'^(ë³€ê²½|ì¤‘ì§€|ì •ì§€|ìœ ì˜ì‚¬í•­|ì°¸ê³ |ì•ˆë‚´)[:ï¼š]\s*', line):
            return True

        # 12. "~ì˜ ë³€ê²½ì„ ì´ˆë˜í•˜ëŠ”" ë“± ì ˆì°¨ ì•ˆë‚´
        if re.search(r'ë³€ê²½ì„\s*ì´ˆë˜í•˜ëŠ”|ê²°í˜¼Â·ì´í˜¼|ë°°ìš°ìì˜\s*ì‚¬ë§', line):
            return True

        # 13. ì£¼ì„/ê°ì£¼ íŒ¨í„´ ("*", "â€»" ë“±ìœ¼ë¡œ ì‹œì‘)
        if re.match(r'^[*â€»ï¼Š]\s', line):
            return True

        # 14. "ì˜ˆìƒì—°ê¸ˆì•¡", "ì‹¤ì§€ê¸‰ì•¡" ë“± ì•ˆë‚´ ë¬¸êµ¬
        if re.search(r'ì˜ˆìƒì—°ê¸ˆì•¡|ì‹¤ì§€ê¸‰ì•¡|ë‹¤ë¥¼\s*ìˆ˜\s*ìˆìŠµë‹ˆë‹¤', line):
            return True

        return False

    def _is_government_contact(self, line: str) -> bool:
        """ë¶€ì²˜ ì—°ë½ì²˜ ì •ë³´ë§Œ ìˆëŠ” ë¼ì¸ì¸ì§€ í™•ì¸"""
        # ë³´ê±´ë³µì§€ë¶€ ë“± ë¶€ì²˜ëª… + ì „í™”ë²ˆí˜¸ íŒ¨í„´
        if re.search(r'ë³´ê±´ë³µì§€ë¶€.*?\d{2,4}[-\s]\d{3,4}[-\s]\d{4}', line):
            # "ì´ê´„", "ë‹´ë‹¹", "ê³¼" ë“±ì´ í¬í•¨ë˜ë©´ ë‹¨ìˆœ ì—°ë½ì²˜
            if any(kw in line for kw in ['ì´ê´„', 'ë‹´ë‹¹', 'ì •ì±…ê³¼', 'ì¸ê¶Œêµìœ¡', 'ì·¨ì—…ì œí•œ']):
                return True

        # "â€» ë³´ê±´ë³µì§€ë¶€..." íŒ¨í„´
        if re.match(r'^[â€»â—‹â—â– ]\s*ë³´ê±´ë³µì§€ë¶€', line):
            return True

        return False

    def _score_target_line(self, line: str) -> float:
        """ëŒ€ìƒì ì •ë³´ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0

        # ê¸ì • ì§€í‘œ
        positive_keywords = [
            ('ì§€ì›ëŒ€ìƒ', 3.5), ('ì‹ ì²­ìê²©', 3.5), ('ìˆ˜ê¸‰ê¶Œì', 3.0),
            ('ì„¸ ì´ìƒ', 2.5), ('ì„¸ì´ìƒ', 2.5), ('ì´í•˜ì¸ ì', 2.0), ('í•´ë‹¹í•˜ëŠ” ì', 2.5),
            ('ë…¸ì¸', 1.0), ('ì–´ë¥´ì‹ ', 1.0), ('ê³ ë ¹ì', 1.5),
            ('ì†Œë“ì¸ì •ì•¡', 2.5), ('ê¸°ì¤€ì¤‘ìœ„ì†Œë“', 3.0),
            ('ê°€êµ¬', 1.5), ('ë§Œ', 1.0), ('ì°¨ìƒìœ„', 2.0)
        ]

        for keyword, weight in positive_keywords:
            if keyword in line:
                score += weight

        # ë‚˜ì´ íŒ¨í„´ (ë§Œ XXì„¸)
        if re.search(r'ë§Œ\s*\d+ì„¸', line):
            score += 3.5

        # ë¶€ì • ì§€í‘œ (ì œì™¸í•  íŒ¨í„´) - ë§¤ìš° ê°•ë ¥í•˜ê²Œ
        negative_patterns = [
            (r'ì‹ ì²­ê¶Œì\s*:', -15.0),  # "ì‹ ì²­ê¶Œì: ..." í˜•ì‹
            (r'ì‹ ì²­ê¶Œì\s*ëŠ”', -15.0),  # ì‹ ì²­ ê¶Œí•œë§Œ ì„¤ëª…
            (r'ë²•ë¥ .*?ì œ\d+í˜¸', -15.0),  # ë²•ë¥  ì¡°ë¬¸
            (r'ã€Œ[^ã€]+ã€', -12.0),  # ë²•ë¥ ëª…
            (r'ì´í•˜\s*["\'][^"\']+["\']', -12.0),  # "ì´í•˜ "ì•½ì¹­""
            (r'\d{3}[-\s]\d{3,4}[-\s]\d{4}', -15.0),  # ì „í™”ë²ˆí˜¸
            (r'ë³´ê±´ë³µì§€ë¶€', -10.0),  # ë¶€ì²˜ëª…
            (r'^[â€»â—‹â—â– ]\s*', -5.0),  # ë¶ˆë¦¿ìœ¼ë¡œ ì‹œì‘
        ]

        for pattern, weight in negative_patterns:
            if re.search(pattern, line):
                score += weight

        # ë„ˆë¬´ ì§§ìœ¼ë©´ ê°ì 
        if len(line) < 30:
            score -= 3.0

        return score

    def _score_benefit_line(self, line: str) -> float:
        """í˜œíƒ ì •ë³´ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0

        # ê¸ì • ì§€í‘œ
        positive_keywords = [
            ('ì§€ì›ë‚´ìš©', 3.5), ('ì§€ì›ê¸ˆì•¡', 3.5), ('ê¸‰ì—¬ë‚´ìš©', 3.5),
            ('ì§€ì›ê¸ˆ', 3.0), ('ê¸‰ì—¬ì•¡', 3.0),
            ('ì›”', 1.5), ('ì›', 1.5), ('ë§Œì›', 3.0),
            ('ë¬´ë£Œ', 3.0), ('í• ì¸', 3.0), ('ê°ë©´', 3.0),
            ('ì œê³µ', 1.0), ('ì§€ì›', 1.0), ('ì§€ê¸‰', 2.5),
            ('ì„œë¹„ìŠ¤', 1.5), ('í”„ë¡œê·¸ë¨', 1.5), ('ë³´ì¡°ê¸°ê¸°', 2.0)
        ]

        for keyword, weight in positive_keywords:
            if keyword in line:
                score += weight

        # ê¸ˆì•¡ íŒ¨í„´ ì¡´ì¬ ì‹œ ê°€ì‚°ì  (ë” êµ¬ì²´ì ìœ¼ë¡œ)
        if re.search(r'\d+[,\d]*\s*[ë§Œì›ì²œë°±ì‹­ì–µì¡°]', line):
            score += 3.5

        # í¼ì„¼íŠ¸ í• ì¸ìœ¨
        if re.search(r'\d+\s*%', line):
            score += 2.0

        # ë¶€ì • ì§€í‘œ - ë§¤ìš° ê°•ë ¥í•˜ê²Œ
        negative_patterns = [
            (r'ë²•ë¥ .*?ì œ\d+í˜¸', -15.0),
            (r'ã€Œ[^ã€]+ã€', -12.0),  # ë²•ë¥ ëª…
            (r'ì´í•˜\s*["\'][^"\']+["\']', -12.0),  # "ì´í•˜ "ì•½ì¹­""
            (r'\d{3}[-\s]\d{3,4}[-\s]\d{4}', -15.0),  # ì „í™”ë²ˆí˜¸
            (r'ë³´ê±´ë³µì§€ë¶€', -10.0),
            (r'ê³ ê¶.*?ëŠ¥ì›.*?ë°•ë¬¼ê´€', -10.0),  # ì‹œì„¤ ë‚˜ì—´
            (r'ì²´ì˜\s*ìˆ˜ì†¡ì‹œì„¤', -10.0),  # ì´ìƒí•œ í‘œí˜„
            (r'^[â€»â—‹â—â– ]\s*', -5.0),
            (r'ì‚¬ì—….*?ì´ê´„', -15.0),  # "ì‚¬ì—… ì´ê´„ ë° ì§€ì›"
            (r'ì •ì„œì \s*ì§€ì›\s*ë“±\s*í•„ìš”í•œ\s*ì„œë¹„ìŠ¤', -10.0),  # ë„ˆë¬´ ì¼ë°˜ì 
        ]

        for pattern, weight in negative_patterns:
            if re.search(pattern, line):
                score += weight

        # ë„ˆë¬´ ì§§ìœ¼ë©´ ê°ì 
        if len(line) < 25:
            score -= 3.0

        return score

    def _score_application_line(self, line: str) -> float:
        """ì‹ ì²­ë°©ë²• ì •ë³´ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0

        # ê¸ì • ì§€í‘œ
        positive_keywords = [
            ('ì‹ ì²­ë°©ë²•', 3.5), ('ì‹ ì²­ì ˆì°¨', 3.5), ('ì‹ ì²­ì„œ', 3.0),
            ('ì£¼ë¯¼ì„¼í„°', 3.0), ('êµ¬ì²­', 3.0), ('ì‹œì²­', 3.0), ('êµ°ì²­', 3.0),
            ('ìë©´ë™', 3.0), ('ë™ì‚¬ë¬´ì†Œ', 3.0), ('í–‰ì •ë³µì§€ì„¼í„°', 3.0),
            ('ì˜¨ë¼ì¸', 2.5), ('ë°©ë¬¸', 2.5), ('ìš°í¸', 2.5),
            ('ì œì¶œ', 2.0), ('ì ‘ìˆ˜', 2.5), ('ì‹ ì²­', 1.0)
        ]

        for keyword, weight in positive_keywords:
            if keyword in line:
                score += weight

        # ì „í™”ë²ˆí˜¸ ì¡´ì¬ ì‹œ - ë¬¸ë§¥ í™•ì¸ í›„ ê°€ì‚°ì 
        if re.search(r'\d{2,4}[-\s]\d{3,4}[-\s]\d{4}', line):
            # "ë¬¸ì˜", "ìƒë‹´" ë“±ì´ ìˆìœ¼ë©´ ì—°ë½ì²˜ì¼ ê°€ëŠ¥ì„±
            if any(kw in line for kw in ['ë¬¸ì˜', 'ìƒë‹´', 'ì½œì„¼í„°', 'ì•ˆë‚´', 'ì „í™”']):
                score += 2.5
            # "ì´ê´„", "ë‹´ë‹¹" ë“±ì´ ìˆìœ¼ë©´ ë¶€ì²˜ ì—°ë½ì²˜ (ê°ì )
            elif any(kw in line for kw in ['ì´ê´„', 'ë‹´ë‹¹', 'ì •ì±…ê³¼']):
                score -= 10.0

        # ë¶€ì • ì§€í‘œ - ë§¤ìš° ê°•ë ¥í•˜ê²Œ
        negative_patterns = [
            (r'ë²•ë¥ .*?ì œ\d+í˜¸', -15.0),
            (r'ã€Œ[^ã€]+ã€', -12.0),
            (r'ë³´ê±´ë³µì§€ë¶€.*?\(.*?ì´ê´„', -20.0),  # ë¶€ì²˜ ì´ê´„ ì—°ë½ì²˜
            (r'^[â€»â—‹â—â– ]\s*ë³´ê±´ë³µì§€ë¶€', -20.0),  # ë¶€ì²˜ëª…ìœ¼ë¡œ ì‹œì‘
            (r'ì‚¬ë¡€ê´€ë¦¬ì‚¬ì—….*?ìœ ê´€ê¸°ê´€', -10.0),  # ì˜ë¯¸ ì—†ëŠ” ë‚˜ì—´
            (r'ìë©´ë™í–‰ì •ë³µì§€ì„¼í„°\s*ë°\s*ìœ ê´€ê¸°ê´€', -10.0),
        ]

        for pattern, weight in negative_patterns:
            if re.search(pattern, line):
                score += weight

        # ë„ˆë¬´ ì§§ìœ¼ë©´ ê°ì 
        if len(line) < 25:
            score -= 3.0

        return score

    def _score_description_line(self, line: str, question_keywords: List[str]) -> float:
        """ì„¤ëª… ì •ë³´ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0

        # ì§ˆë¬¸ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ê°€ì‚°ì 
        if question_keywords:
            for keyword in question_keywords:
                if keyword in line:
                    score += 2.5

        # ê¸ì • ì§€í‘œ
        positive_keywords = [
            ('ì‚¬ì—…', 1.5), ('ì •ì±…', 2.5), ('ì œë„', 2.5),
            ('ëª©ì ', 3.5), ('ìœ„í•˜ì—¬', 2.5), ('ìœ„í•´', 2.5),
            ('ì§€ì›í•˜ëŠ”', 2.5), ('ì œê³µí•˜ëŠ”', 2.5),
            ('ì„œë¹„ìŠ¤', 1.5), ('ë³µì§€', 1.5), ('í”„ë¡œê·¸ë¨', 1.5),
            ('ë…¸ì¸', 1.0), ('ì–´ë¥´ì‹ ', 1.0), ('ê³ ë ¹ì', 1.0),
            ('ëŒ€ìƒìœ¼ë¡œ', 2.0), ('í†µí•˜ì—¬', 2.0)
        ]

        for keyword, weight in positive_keywords:
            if keyword in line:
                score += weight

        # ì„¤ëª… íŒ¨í„´ ì¡´ì¬ ì‹œ ê°€ì‚°ì 
        description_patterns = [
            (r'[ì´ë€ì€ëŠ”]\s+.*?[í•˜ìœ„].*?[ëŠ”ë‹¤ì œ]', 2.5),  # "~ì´ë€ ~í•˜ëŠ” ì œë„"
            (r'ëª©ì .*?[í•˜ìœ„].*?[ë‹¤ë©°]', 3.5),  # "ëª©ì ìœ¼ë¡œ í•˜ëŠ”"
            (r'í†µí•´.*?ì§€ì›', 2.5),  # "~ë¥¼ í†µí•´ ì§€ì›"
            (r'ëŒ€ìƒìœ¼ë¡œ.*?ì§€ì›', 3.0),  # "~ëŒ€ìƒìœ¼ë¡œ ì§€ì›"
        ]

        for pattern, weight in description_patterns:
            if re.search(pattern, line):
                score += weight

        # ë¶€ì • ì§€í‘œ (ë²•ë¥  ì¡°ë¬¸ë§Œ ìˆëŠ” ê²½ìš°) - ë§¤ìš° ê°•ë ¥í•˜ê²Œ
        negative_patterns = [
            (r'^ã€Œ[^ã€]+ã€.*?ì œ\d+ì¡°', -20.0),  # ë²•ë¥  ì¡°ë¬¸ìœ¼ë¡œ ì‹œì‘
            (r'^ã€Œ[^ã€]+ë²•[^ã€]*ã€', -15.0),  # ë²•ë¥ ëª…ìœ¼ë¡œ ì‹œì‘
            (r'ì´í•˜\s*["\'][^"\']+["\'].*?ì œ\d+ì¡°', -20.0),
            (r'\d{3}[-\s]\d{3,4}[-\s]\d{4}', -15.0),  # ì „í™”ë²ˆí˜¸
            (r'^[â€»â—‹â—â– ]\s*ë³´ê±´ë³µì§€ë¶€', -20.0),  # ë¶€ì²˜ ì—°ë½ì²˜
            (r'ì‚¬ì—…\s*ì´ê´„.*?ì§€ì›', -15.0),  # "ì‚¬ì—… ì´ê´„ ë° ì§€ì›"
            (r'^[ê°€-í£\s]*ì‚¬ì—….*?ì§€ì›$', -10.0),  # ë„ˆë¬´ ê°„ëµí•œ ì„¤ëª…
            (r'ì¸ê¶Œêµìœ¡.*?ì·¨ì—…ì œí•œ', -15.0),  # ë‹´ë‹¹ ì—…ë¬´ ë‚˜ì—´
            (r'ì¹˜ë§¤ì˜ˆë°©.*?ë¬¼ë¦¬ì¹˜ë£Œ', -10.0),  # í”„ë¡œê·¸ë¨ ë‚˜ì—´ë§Œ
        ]

        for pattern, weight in negative_patterns:
            if re.search(pattern, line):
                score += weight

        # ì ì ˆí•œ ê¸¸ì´ (50ì ì´ìƒì´ë©´ ê°€ì‚°ì )
        if len(line) >= 50:
            score += 2.5
        elif len(line) >= 40:
            score += 1.5
        elif len(line) < 30:
            score -= 2.0

        return score

    def _clean_sentence(self, sentence: str) -> str:
        """ë¬¸ì¥ ì •ë¦¬"""
        # ì•ë’¤ ë¶ˆë¦¿ ì œê±°
        sentence = re.sub(r'^[â—‹â—â– â–¡â—‡â—†â–¶â–·â€¢\-â€»]\s*', '', sentence)
        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        sentence = re.sub(r'[ã†]', ' ', sentence)
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        sentence = re.sub(r'\s+', ' ', sentence)
        return sentence.strip()


class EnhancedPolicyFormatter:
    """í–¥ìƒëœ ì •ì±… ì •ë³´ í¬ë§·í„°"""

    def __init__(self):
        self.extractor = SimplePolicyExtractor()

    def _is_policy_relevant(self, policy_name: str, question: str) -> bool:
        """ì •ì±…ëª…ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ”ì§€ í™•ì¸"""
        if not question:
            return True  # ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ëª¨ë‘ í—ˆìš©

        # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        question_lower = question.lower()
        policy_lower = policy_name.lower()

        # ì§ì ‘ì ì¸ í‚¤ì›Œë“œ ë§¤ì¹­
        question_keywords = re.findall(r'[ê°€-í£]{2,}', question)

        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = ['ëˆ„ê°€', 'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì–´ë””', 'ì–¸ì œ', 'ì™œ', 'ìˆë‚˜ìš”', 'ìˆì–´ìš”', 'ì•Œë ¤ì£¼ì„¸ìš”', 'ë­ì•¼', 'ì–´ë–¤', 'ê²ƒë“¤', 'ëŒ€í•´', 'ì •ì±…', 'ë³µì§€']
        question_keywords = [kw for kw in question_keywords if kw not in stopwords]

        # ì§ˆë¬¸ í‚¤ì›Œë“œê°€ ì •ì±…ëª…ì— í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ê´€ë ¨ ìˆìŒ
        if question_keywords:
            for keyword in question_keywords:
                if keyword in policy_name:
                    return True

        # ìœ ì‚¬ í‚¤ì›Œë“œ ë§¤í•‘ (ë™ì˜ì–´ ì²´í¬)
        synonym_map = {
            'ê¸°ì´ˆì—°ê¸ˆ': ['ê¸°ì´ˆì—°ê¸ˆ', 'ë…¸ë ¹ì—°ê¸ˆ'],
            'ì˜ë£Œê¸‰ì—¬': ['ì˜ë£Œê¸‰ì—¬', 'ì˜ë£Œì§€ì›', 'ì˜ë£Œë¹„'],
            'ì¥ê¸°ìš”ì–‘': ['ì¥ê¸°ìš”ì–‘', 'ìš”ì–‘', 'ëŒë´„'],
            'ì¼ìë¦¬': ['ì¼ìë¦¬', 'ì·¨ì—…', 'ê·¼ë¡œ'],
            'ë³´í›ˆ': ['ë³´í›ˆ', 'ìœ ê³µì', 'ì°¸ì „'],
            'ê±´ê°•': ['ê±´ê°•', 'ì˜ë£Œ', 'ì§„ë£Œ'],
        }

        # ì§ˆë¬¸ì— í¬í•¨ëœ í‚¤ì›Œë“œë¡œ ë™ì˜ì–´ ì²´í¬
        for main_keyword, synonyms in synonym_map.items():
            if main_keyword in question_lower:
                # ì •ì±…ëª…ì— ë™ì˜ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
                if any(syn in policy_lower for syn in synonyms):
                    return True
                # ì •ì±…ëª…ì— ë©”ì¸ í‚¤ì›Œë“œë‚˜ ë™ì˜ì–´ê°€ ì—†ìœ¼ë©´ ê´€ë ¨ ì—†ìŒ
                if not any(syn in policy_name for syn in synonyms):
                    return False

        # ì¼ë°˜ì ì¸ ë³µì§€ í‚¤ì›Œë“œëŠ” í—ˆìš©
        general_keywords = ['ë…¸ì¸', 'ì–´ë¥´ì‹ ', 'ë³µì§€', 'ì§€ì›', 'ì„œë¹„ìŠ¤']
        if any(kw in question for kw in general_keywords):
            return True

        return True  # ê¸°ë³¸ì ìœ¼ë¡œ í—ˆìš©

    def format_document(self, doc: Dict[str, Any], question: str = "") -> Optional[Dict[str, Any]]:
        """
        ë¬¸ì„œë¥¼ í¬ë§·íŒ…í•˜ì—¬ ì •ì±… ì •ë³´ë¡œ ë³€í™˜

        Returns:
            {
                'formatted_text': í¬ë§·ëœ í…ìŠ¤íŠ¸,
                'has_content': ë‚´ìš© ìœ ë¬´,
                'filename': íŒŒì¼ëª…,
                'region': ì§€ì—­,
                'policy_url': ì •ì±… URL
            }
        """
        content = doc.get('content', '')
        metadata = doc.get('metadata', {})
        filename = metadata.get('filename', 'ì •ì±…ë¬¸ì„œ.pdf')
        region = metadata.get('region', 'ì§€ì—­ë¯¸ìƒ')

        # ì •ì±… ë©”íƒ€ë°ì´í„° ì°¾ê¸° (ì •ì±…ëª…, URL)
        policy_meta = find_policy_metadata(content, filename)

        # ì •ì±… ì •ë³´ ì¶”ì¶œ
        policy = self.extractor.extract_from_text(content, question)

        # ì •ì±…ëª…ì„ ë©”íƒ€ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ì¶”ì¶œí•œ ê²ƒ ì‚¬ìš©)
        policy_name = policy_meta.get('name') or policy.get('name') or 'ë³µì§€ ì •ì±…'
        policy_url = policy_meta.get('url', 'https://www.bokjiro.go.kr')

        # ì§ˆë¬¸ê³¼ ì •ì±…ëª…ì˜ ê´€ë ¨ì„± ì²´í¬
        if question and not self._is_policy_relevant(policy_name, question):
            logger.info(f"âŒ ì •ì±… '{policy_name}'ì€ ì§ˆë¬¸ '{question}'ê³¼ ë¬´ê´€í•˜ì—¬ í•„í„°ë§ë¨")
            return None

        # ìµœì†Œí•œ í•˜ë‚˜ë¼ë„ ì¶”ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
        has_any_info = any([
            policy.get('description'),
            policy.get('target'),
            policy.get('benefits'),
            policy.get('application')
        ]) or policy_meta.get('name')  # ë©”íƒ€ë°ì´í„°ì—ì„œ ì •ì±…ëª…ì„ ì°¾ì•˜ìœ¼ë©´ OK

        if not has_any_info:
            return None

        # ì¤‘ë³µ ë‚´ìš© ì œê±° - ì„¤ëª…ê³¼ í˜œíƒì´ ê°™ìœ¼ë©´ í•˜ë‚˜ë§Œ í‘œì‹œ
        description = policy.get('description', '')
        target = policy.get('target', '')
        benefits = policy.get('benefits', '')
        application = policy.get('application', '')

        # ì„¤ëª…ê³¼ í˜œíƒì´ ë„ˆë¬´ ìœ ì‚¬í•˜ë©´ í˜œíƒ ì œê±°
        if description and benefits and (description == benefits or description in benefits or benefits in description):
            benefits = ''

        # í¬ë§·íŒ…
        lines = []

        # ì •ì±…ëª… (ë§í¬ ì œê±° - í…ìŠ¤íŠ¸ë§Œ)
        lines.append(f"**ğŸ“‹ {policy_name}**\n")

        # ì„¤ëª…
        if description:
            lines.append(f"â€¢ **ì„¤ëª…**: {description}\n")

        # ëŒ€ìƒ
        if target:
            lines.append(f"â€¢ **ëŒ€ìƒ**: {target}\n")

        # í˜œíƒ
        if benefits:
            lines.append(f"â€¢ **í˜œíƒ**: {benefits}\n")

        # ì‹ ì²­ë°©ë²•
        if application:
            lines.append(f"â€¢ **ì‹ ì²­**: {application}\n")

        # ì¶œì²˜ (íŒŒì¼ëª… + ë§í¬)
        lines.append(f"â€¢ **ì¶œì²˜**: [{filename}]({policy_url}) ({region})")

        formatted_text = ''.join(lines)

        return {
            'formatted_text': formatted_text,
            'has_content': True,
            'filename': filename,
            'region': region,
            'policy_name': policy_name,
            'policy_url': policy_url
        }
