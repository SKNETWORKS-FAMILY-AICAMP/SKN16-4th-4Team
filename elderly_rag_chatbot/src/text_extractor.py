# =========================================
# ğŸ“„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ëª¨ë“ˆ
# =========================================

import os
import logging
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
import pandas as pd
from datetime import datetime

# PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import PyPDF2
    import pdfplumber
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

# HWP ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import olefile
    HWP_AVAILABLE = True
except ImportError:
    HWP_AVAILABLE = False

# í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¹„êµ ì‹œìŠ¤í…œ
try:
    from .text_extraction_comparison import TextExtractionComparison
    COMPARISON_AVAILABLE = True
except ImportError:
    COMPARISON_AVAILABLE = False

logger = logging.getLogger(__name__)


class WelfareDocumentExtractor:
    """ë…¸ì¸ë³µì§€ ì •ì±… ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 data_directory: str = None, 
                 cache_enabled: bool = True, 
                 cache_directory: str = "./cache"):
        """
        Args:
            data_directory: ë³µì§€ë¡œ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
            cache_enabled: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
            cache_directory: ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        if data_directory is None:
            # ê¸°ë³¸ ê²½ë¡œ: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ data/ë³µì§€ë¡œ
            # í˜„ì¬ ìœ„ì¹˜ì—ì„œ ìƒìœ„ë¡œ ê°€ì„œ data ë””ë ‰í† ë¦¬ë¥¼ ì°¾ìŒ
            current_dir = Path(__file__).parent
            self.data_dir = current_dir.parent / "data" / "ë³µì§€ë¡œ"
        else:
            self.data_dir = Path(data_directory)
        
        self.cache_enabled = cache_enabled
        self.cache_directory = Path(cache_directory)
        
        if self.cache_enabled:
            self.cache_directory.mkdir(exist_ok=True)
        
        self.supported_formats = ['.pdf', '.hwp', '.txt']
        self.extracted_texts = []
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¹„êµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.extraction_comparison = None
        if COMPARISON_AVAILABLE:
            self.extraction_comparison = TextExtractionComparison()
        
    def check_dependencies(self) -> Dict[str, bool]:
        """í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ìƒíƒœ í™•ì¸"""
        dependencies = {
            'PDF': PDF_AVAILABLE,
            'HWP': HWP_AVAILABLE
        }
        
        missing = [name for name, available in dependencies.items() if not available]
        if missing:
            logger.warning(f"ëˆ„ë½ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬: {', '.join(missing)}")
            logger.info("ì„¤ì¹˜ ëª…ë ¹ì–´:")
            if 'PDF' in missing:
                logger.info("  pip install PyPDF2 pdfplumber")
            if 'HWP' in missing:
                logger.info("  pip install olefile")
        
        return dependencies
    
    def extract_text_from_pdf(self, file_path: Path) -> Tuple[str, Dict]:
        """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not PDF_AVAILABLE:
            return "", {"error": "PDF ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ"}
        
        text = ""
        metadata = {
            "file_type": "PDF",
            "pages": 0,
            "extraction_method": "pdfplumber"
        }
        
        try:
            # pdfplumber ìš°ì„  ì‹œë„ (ë” ì •í™•í•¨)
            with pdfplumber.open(file_path) as pdf:
                pages_text = []
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    if page_text:
                        pages_text.append(f"[í˜ì´ì§€ {page_num + 1}]\n{page_text}")
                
                text = "\n\n".join(pages_text)
                metadata["pages"] = len(pdf.pages)
                
        except Exception as e:
            logger.warning(f"pdfplumber ì‹¤íŒ¨, PyPDF2ë¡œ ì¬ì‹œë„: {e}")
            
            # PyPDF2ë¡œ ë°±ì—… ì‹œë„
            try:
                with open(file_path, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    pages_text = []
                    
                    for page_num, page in enumerate(pdf_reader.pages):
                        page_text = page.extract_text()
                        if page_text:
                            pages_text.append(f"[í˜ì´ì§€ {page_num + 1}]\n{page_text}")
                    
                    text = "\n\n".join(pages_text)
                    metadata["pages"] = len(pdf_reader.pages)
                    metadata["extraction_method"] = "PyPDF2"
                    
            except Exception as e2:
                logger.error(f"PDF ì¶”ì¶œ ì‹¤íŒ¨ {file_path}: {e2}")
                metadata["error"] = str(e2)
        
        return text, metadata
    
    def extract_text_from_hwp(self, file_path: Path) -> Tuple[str, Dict]:
        """HWP íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê¸°ë³¸ êµ¬í˜„)"""
        if not HWP_AVAILABLE:
            return "", {"error": "HWP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ"}
        
        metadata = {
            "file_type": "HWP",
            "extraction_method": "olefile"
        }
        
        try:
            # HWP íŒŒì¼ì€ ë³µí•© ë¬¸ì„œ í˜•íƒœì´ë¯€ë¡œ olefileë¡œ êµ¬ì¡° ë¶„ì„
            if olefile.isOleFile(file_path):
                with olefile.OleFileIO(file_path) as ole:
                    # HWP íŒŒì¼ êµ¬ì¡°ì—ì„œ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì°¾ê¸°
                    text = self._extract_hwp_text_streams(ole)
                    metadata["streams_found"] = True
            else:
                logger.warning(f"ì˜¬ë°”ë¥¸ HWP íŒŒì¼ì´ ì•„ë‹˜: {file_path}")
                text = ""
                metadata["error"] = "ì˜¬ë°”ë¥¸ HWP íŒŒì¼ í˜•ì‹ì´ ì•„ë‹˜"
                
        except Exception as e:
            logger.error(f"HWP ì¶”ì¶œ ì‹¤íŒ¨ {file_path}: {e}")
            # HWP íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ë¡œ ì½ì–´ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            text = self._extract_hwp_fallback(file_path)
            metadata["error"] = str(e)
            metadata["extraction_method"] = "fallback"
        
        return text, metadata
    
    def _extract_hwp_text_streams(self, ole) -> str:
        """HWP OLE íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì¶”ì¶œ"""
        text_parts = []
        
        try:
            # HWP íŒŒì¼ì˜ ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ë“¤
            text_streams = [
                'PrvText',
                'DocInfo/HwpSummaryInformation',
                'BodyText/Section0',
                'ViewText/Section0'
            ]
            
            for stream_name in text_streams:
                try:
                    if ole._olestream_size.get(stream_name, 0) > 0:
                        stream = ole.opendir(stream_name)
                        data = stream.read()
                        # í•œê¸€ ë¬¸ì ì¸ì½”ë”© ì²˜ë¦¬
                        text_part = self._decode_hwp_text(data)
                        if text_part:
                            text_parts.append(text_part)
                except:
                    continue
        
        except Exception as e:
            logger.debug(f"HWP ìŠ¤íŠ¸ë¦¼ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return "\n\n".join(text_parts) if text_parts else ""
    
    def _decode_hwp_text(self, data: bytes) -> str:
        """HWP ë°”ì´ë„ˆë¦¬ ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ë””ì½”ë”©"""
        # HWP íŒŒì¼ì˜ í…ìŠ¤íŠ¸ëŠ” UTF-16LE ë˜ëŠ” CP949ë¡œ ì¸ì½”ë”©ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ
        encodings = ['utf-16le', 'cp949', 'utf-8', 'euc-kr']
        
        for encoding in encodings:
            try:
                text = data.decode(encoding, errors='ignore')
                # ì˜ë¯¸ìˆëŠ” í•œê¸€ í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if any(ord(c) >= 0xAC00 and ord(c) <= 0xD7A3 for c in text):
                    return text
            except:
                continue
        
        return ""
    
    def _extract_hwp_fallback(self, file_path: Path) -> str:
        """HWP íŒŒì¼ í´ë°± í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¨ìˆœ ë°”ì´ë„ˆë¦¬ ì½ê¸°)"""
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
                # ë°”ì´ë„ˆë¦¬ì—ì„œ í•œê¸€ í…ìŠ¤íŠ¸ íŒ¨í„´ ì°¾ê¸°
                text = self._decode_hwp_text(data)
                # ë¶ˆí•„ìš”í•œ ì œì–´ ë¬¸ì ì œê±°
                text = ''.join(c for c in text if c.isprintable() or c in '\n\t ')
                return text
        except Exception as e:
            logger.error(f"HWP í´ë°± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def extract_text_from_txt(self, file_path: Path) -> Tuple[str, Dict]:
        """TXT íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        metadata = {
            "file_type": "TXT",
            "extraction_method": "direct"
        }
        
        encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-16']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    text = f.read()
                    metadata["encoding"] = encoding
                    return text, metadata
            except UnicodeDecodeError:
                continue
        
        # ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨ì‹œ ë°”ì´ë„ˆë¦¬ë¡œ ì½ê³  ì—ëŸ¬ ë¬´ì‹œ
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
                text = data.decode('utf-8', errors='ignore')
                metadata["encoding"] = "utf-8 (errors ignored)"
                return text, metadata
        except Exception as e:
            logger.error(f"TXT íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {file_path}: {e}")
            return "", {"error": str(e)}
    
    def extract_from_file(self, file_path: Path) -> Dict:
        """ë‹¨ì¼ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        file_path = Path(file_path)
        
        if not file_path.exists():
            return {
                "file_path": str(file_path),
                "error": "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ",
                "text": "",
                "metadata": {}
            }
        
        suffix = file_path.suffix.lower()
        
        # íŒŒì¼ í˜•ì‹ë³„ ì²˜ë¦¬
        if suffix == '.pdf':
            text, metadata = self.extract_text_from_pdf(file_path)
        elif suffix == '.hwp':
            text, metadata = self.extract_text_from_hwp(file_path)
        elif suffix == '.txt':
            text, metadata = self.extract_text_from_txt(file_path)
        else:
            return {
                "file_path": str(file_path),
                "error": f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {suffix}",
                "text": "",
                "metadata": {}
            }
        
        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        metadata.update({
            "file_name": file_path.name,
            "file_size": file_path.stat().st_size,
            "extraction_time": datetime.now().isoformat(),
            "text_length": len(text)
        })
        
        return {
            "file_path": str(file_path),
            "text": text,
            "metadata": metadata,
            "success": len(text) > 0
        }
    
    def scan_welfare_directory(self) -> List[Path]:
        """ë³µì§€ë¡œ ë””ë ‰í† ë¦¬ì—ì„œ ì§€ì›ë˜ëŠ” íŒŒì¼ë“¤ ìŠ¤ìº”"""
        files = []
        
        if not self.data_dir.exists():
            logger.error(f"ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {self.data_dir}")
            return files
        
        # ì¬ê·€ì ìœ¼ë¡œ ì§€ì› íŒŒì¼ í˜•ì‹ ì°¾ê¸°
        for suffix in self.supported_formats:
            pattern = f"**/*{suffix}"
            found_files = list(self.data_dir.glob(pattern))
            files.extend(found_files)
            logger.info(f"{suffix} íŒŒì¼ {len(found_files)}ê°œ ë°œê²¬")
        
        logger.info(f"ì´ {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
        return files
    
    def compare_extraction_methods(self, sample_files: List[str] = None, max_files: int = 5) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ì„±ëŠ¥ ë¹„êµ"""
        
        if not COMPARISON_AVAILABLE:
            logger.warning("í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¹„êµ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return {"error": "comparison system not available"}
        
        logger.info("ğŸ“Š í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ì„±ëŠ¥ ë¹„êµ ì‹œì‘")
        
        # ìƒ˜í”Œ íŒŒì¼ ì¤€ë¹„
        if sample_files is None:
            files = self.scan_welfare_directory()
            pdf_files = [str(f) for f in files if f.suffix.lower() == '.pdf'][:max_files]
            hwp_files = [str(f) for f in files if f.suffix.lower() == '.hwp'][:max_files]
        else:
            pdf_files = [f for f in sample_files if f.endswith('.pdf')]
            hwp_files = [f for f in sample_files if f.endswith('.hwp')]
        
        comparison_results = {}
        
        # PDF ì¶”ì¶œê¸° ë¹„êµ
        if pdf_files:
            logger.info(f"PDF ì¶”ì¶œ ë°©ë²• ë¹„êµ ({len(pdf_files)}ê°œ íŒŒì¼)")
            pdf_comparison = self.extraction_comparison.compare_pdf_extractors(pdf_files)
            comparison_results["pdf_comparison"] = pdf_comparison
        
        # HWP ì¶”ì¶œê¸° ë¹„êµ
        if hwp_files:
            logger.info(f"HWP ì¶”ì¶œ ë°©ë²• ë¹„êµ ({len(hwp_files)}ê°œ íŒŒì¼)")
            hwp_comparison = self.extraction_comparison.compare_hwp_extractors(hwp_files)
            comparison_results["hwp_comparison"] = hwp_comparison
        
        # ì¶”ì²œ ì¶”ì¶œê¸° ì„¤ì •
        recommended_extractors = {}
        
        if "pdf_comparison" in comparison_results and "best_extractor" in comparison_results["pdf_comparison"]:
            recommended_extractors["pdf"] = comparison_results["pdf_comparison"]["best_extractor"]["name"]
        
        if "hwp_comparison" in comparison_results and "best_extractor" in comparison_results["hwp_comparison"]:
            recommended_extractors["hwp"] = comparison_results["hwp_comparison"]["best_extractor"]["name"]
        
        comparison_results["recommended_extractors"] = recommended_extractors
        comparison_results["comparison_summary"] = self._generate_comparison_summary(comparison_results)
        
        logger.info("âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ë¹„êµ ì™„ë£Œ")
        return comparison_results
    
    def _generate_comparison_summary(self, comparison_results: Dict[str, Any]) -> str:
        """ë¹„êµ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        
        summary_lines = ["ğŸ“Š í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ë¹„êµ ê²°ê³¼", "=" * 40]
        
        if "pdf_comparison" in comparison_results:
            pdf_result = comparison_results["pdf_comparison"]
            if "best_extractor" in pdf_result:
                best_pdf = pdf_result["best_extractor"]
                summary_lines.extend([
                    "",
                    f"ğŸ† ìµœì  PDF ì¶”ì¶œê¸°: {best_pdf['name']}",
                    f"  - ì„±ëŠ¥ ì ìˆ˜: {best_pdf['score']:.3f}",
                    f"  - ì„±ê³µë¥ : {best_pdf['metrics']['success_rate']:.1%}",
                    f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {best_pdf['metrics']['avg_extraction_time']:.2f}ì´ˆ"
                ])
        
        if "hwp_comparison" in comparison_results:
            hwp_result = comparison_results["hwp_comparison"]
            if "best_extractor" in hwp_result:
                best_hwp = hwp_result["best_extractor"]
                summary_lines.extend([
                    "",
                    f"ğŸ† ìµœì  HWP ì¶”ì¶œê¸°: {best_hwp['name']}",
                    f"  - ì„±ëŠ¥ ì ìˆ˜: {best_hwp['score']:.3f}",
                    f"  - ì„±ê³µë¥ : {best_hwp['metrics']['success_rate']:.1%}",
                    f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {best_hwp['metrics']['avg_extraction_time']:.2f}ì´ˆ"
                ])
        
        if comparison_results.get("recommended_extractors"):
            summary_lines.extend([
                "",
                "ğŸ’¡ ì¶”ì²œ ì„¤ì •:",
                f"  - PDF: {comparison_results['recommended_extractors'].get('pdf', 'N/A')}",
                f"  - HWP: {comparison_results['recommended_extractors'].get('hwp', 'N/A')}"
            ])
        
        return "\n".join(summary_lines)
    
    def extract_all_documents(self, max_files: Optional[int] = None, use_best_extractor: bool = False) -> List[Dict]:
        """ëª¨ë“  ë³µì§€ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        logger.info("ë³µì§€ë¡œ ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘")
        
        # ìµœì  ì¶”ì¶œê¸° ì‚¬ìš© ì˜µì…˜
        best_extractors = {}
        if use_best_extractor and self.extraction_comparison:
            logger.info("ìµœì  ì¶”ì¶œê¸° ê²°ì •ì„ ìœ„í•œ ìƒ˜í”Œ ë¹„êµ ì‹¤í–‰...")
            comparison_result = self.compare_extraction_methods(max_files=3)
            best_extractors = comparison_result.get("recommended_extractors", {})
            logger.info(f"ì„ íƒëœ ìµœì  ì¶”ì¶œê¸°: {best_extractors}")
        
        files = self.scan_welfare_directory()
        
        if max_files:
            files = files[:max_files]
            logger.info(f"ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜ë¥¼ {max_files}ê°œë¡œ ì œí•œ")
        
        results = []
        
        for i, file_path in enumerate(files, 1):
            logger.info(f"[{i}/{len(files)}] ì²˜ë¦¬ ì¤‘: {file_path.name}")
            
            try:
                # ìµœì  ì¶”ì¶œê¸° ì‚¬ìš©
                if use_best_extractor and best_extractors:
                    result = self._extract_with_best_method(file_path, best_extractors)
                else:
                    result = self.extract_from_file(file_path)
                
                # ì§€ì—­ ì •ë³´ ì¶”ì¶œ (íŒŒì¼ ê²½ë¡œì—ì„œ)
                region_info = self._extract_region_from_path(file_path)
                result["metadata"].update(region_info)
                
                results.append(result)
                
                if result["success"]:
                    logger.debug(f"  âœ… ì„±ê³µ: {result['metadata']['text_length']} ê¸€ì")
                else:
                    logger.warning(f"  âŒ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    
            except Exception as e:
                logger.error(f"  âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                results.append({
                    "file_path": str(file_path),
                    "error": str(e),
                    "text": "",
                    "metadata": {},
                    "success": False
                })
        
        # ê²°ê³¼ ìš”ì•½
        successful = sum(1 for r in results if r["success"])
        logger.info(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {successful}/{len(results)} ì„±ê³µ")
        
        return results
    
    def _extract_with_best_method(self, file_path: Path, best_extractors: Dict[str, str]) -> Dict[str, Any]:
        """ìµœì  ì¶”ì¶œê¸°ë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        
        file_ext = file_path.suffix.lower()
        
        if file_ext == '.pdf' and 'pdf' in best_extractors and self.extraction_comparison:
            # ì§€ì •ëœ ìµœì  PDF ì¶”ì¶œê¸° ì‚¬ìš©
            best_extractor = self.extraction_comparison.get_best_extractor_for_file(str(file_path))
            if best_extractor:
                try:
                    extraction_result = best_extractor.extract_with_metrics(str(file_path))
                    return {
                        "file_path": str(file_path),
                        "content": extraction_result["text"],
                        "source": file_path.name,
                        "metadata": {
                            **extraction_result["metrics"],
                            "extraction_method": f"best_{best_extractor.name}",
                            "text_length": len(extraction_result["text"])
                        },
                        "success": extraction_result["metrics"]["success"]
                    }
                except Exception as e:
                    logger.warning(f"ìµœì  PDF ì¶”ì¶œê¸° ì‹¤íŒ¨, ê¸°ë³¸ ë°©ë²• ì‚¬ìš©: {e}")
        
        elif file_ext == '.hwp' and 'hwp' in best_extractors and self.extraction_comparison:
            # ì§€ì •ëœ ìµœì  HWP ì¶”ì¶œê¸° ì‚¬ìš©
            best_extractor = self.extraction_comparison.get_best_extractor_for_file(str(file_path))
            if best_extractor:
                try:
                    extraction_result = best_extractor.extract_with_metrics(str(file_path))
                    return {
                        "file_path": str(file_path),
                        "content": extraction_result["text"],
                        "source": file_path.name,
                        "metadata": {
                            **extraction_result["metrics"],
                            "extraction_method": f"best_{best_extractor.name}",
                            "text_length": len(extraction_result["text"])
                        },
                        "success": extraction_result["metrics"]["success"]
                    }
                except Exception as e:
                    logger.warning(f"ìµœì  HWP ì¶”ì¶œê¸° ì‹¤íŒ¨, ê¸°ë³¸ ë°©ë²• ì‚¬ìš©: {e}")
        
        # ê¸°ë³¸ ë°©ë²• ì‚¬ìš©
        return self.extract_from_file(file_path)
    
    def _extract_region_from_path(self, file_path: Path) -> Dict[str, str]:
        """íŒŒì¼ ê²½ë¡œì—ì„œ ì§€ì—­ ì •ë³´ ì¶”ì¶œ"""
        path_parts = file_path.parts
        region_info = {}
        
        # ê²½ë¡œì—ì„œ ì§€ì—­ëª… ì°¾ê¸°
        regions = ["ê²½ë¶", "ëŒ€êµ¬", "ë¶€ì‚°", "ì „êµ­", "ì „ë‚¨", "ì „ë¶"]
        for part in path_parts:
            if part in regions:
                region_info["region"] = part
                break
        
        # íŒŒì¼ í˜•ì‹
        if "hwp" in path_parts:
            region_info["file_format"] = "hwp"
        elif "pdf" in path_parts:
            region_info["file_format"] = "pdf"
        
        return region_info
    
    def save_extraction_results(self, results: List[Dict], output_path: str = None) -> str:
        """ì¶”ì¶œ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
        if output_path is None:
            output_path = f"welfare_documents_extracted_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        data = []
        for result in results:
            row = {
                "file_path": result["file_path"],
                "file_name": result.get("metadata", {}).get("file_name", ""),
                "region": result.get("metadata", {}).get("region", ""),
                "file_format": result.get("metadata", {}).get("file_format", ""),
                "file_type": result.get("metadata", {}).get("file_type", ""),
                "text_length": result.get("metadata", {}).get("text_length", 0),
                "success": result["success"],
                "error": result.get("error", ""),
                "text": result["text"]
            }
            data.append(row)
        
        df = pd.DataFrame(data)
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        logger.info(f"ì¶”ì¶œ ê²°ê³¼ ì €ì¥: {output_path}")
        return output_path
    
    def get_extraction_summary(self, results: List[Dict]) -> Dict:
        """ì¶”ì¶œ ê²°ê³¼ ìš”ì•½ í†µê³„"""
        total_files = len(results)
        successful = sum(1 for r in results if r["success"])
        
        # íŒŒì¼ í˜•ì‹ë³„ í†µê³„
        format_stats = {}
        region_stats = {}
        
        for result in results:
            # íŒŒì¼ í˜•ì‹
            file_type = result.get("metadata", {}).get("file_type", "Unknown")
            format_stats[file_type] = format_stats.get(file_type, 0) + 1
            
            # ì§€ì—­ë³„
            region = result.get("metadata", {}).get("region", "Unknown")
            region_stats[region] = region_stats.get(region, 0) + 1
        
        return {
            "total_files": total_files,
            "successful_extractions": successful,
            "success_rate": successful / total_files if total_files > 0 else 0,
            "format_statistics": format_stats,
            "region_statistics": region_stats,
            "total_text_length": sum(r.get("metadata", {}).get("text_length", 0) for r in results)
        }


def main():
    """í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    import sys
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    extractor = WelfareDocumentExtractor()
    
    # ì˜ì¡´ì„± í™•ì¸
    dependencies = extractor.check_dependencies()
    print("ì˜ì¡´ì„± í™•ì¸:", dependencies)
    
    # íŒŒì¼ ìŠ¤ìº”
    files = extractor.scan_welfare_directory()
    print(f"ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(files)}")
    
    if len(files) > 0:
        # ìµœëŒ€ 5ê°œ íŒŒì¼ë§Œ í…ŒìŠ¤íŠ¸
        print("\nìƒ˜í”Œ íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
        results = extractor.extract_all_documents(max_files=5)
        
        # ê²°ê³¼ ì¶œë ¥
        for i, result in enumerate(results, 1):
            print(f"\n[{i}] {result['file_path']}")
            print(f"  ì„±ê³µ: {result['success']}")
            if result['success']:
                text_preview = result['text'][:200] + "..." if len(result['text']) > 200 else result['text']
                print(f"  í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {text_preview}")
            else:
                print(f"  ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
        
        # ìš”ì•½ í†µê³„
        summary = extractor.get_extraction_summary(results)
        print(f"\nğŸ“Š ì¶”ì¶œ ê²°ê³¼ ìš”ì•½:")
        print(f"  ì´ íŒŒì¼ ìˆ˜: {summary['total_files']}")
        print(f"  ì„±ê³µ ì¶”ì¶œ: {summary['successful_extractions']}")
        print(f"  ì„±ê³µë¥ : {summary['success_rate']:.1%}")
        print(f"  ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {summary['total_text_length']:,} ê¸€ì")


if __name__ == "__main__":
    main()