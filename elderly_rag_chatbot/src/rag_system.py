# =========================================
# ğŸ¤– RAG ì‹œìŠ¤í…œ ëª¨ë“ˆ
# =========================================

import os
import logging
import json
import time
from typing import List, Dict, Any, Optional, Union, Tuple
from datetime import datetime
from pathlib import Path

try:
    import numpy as np
except ImportError:
    np = None

# LangChain ì„í¬íŠ¸
try:
    from langchain.chains import ConversationalRetrievalChain, RetrievalQA
    from langchain.memory import ConversationBufferWindowMemory
    from langchain_openai import ChatOpenAI
    from langchain.prompts import PromptTemplate, ChatPromptTemplate
    from langchain.schema import Document, BaseRetriever
    from langchain.schema.runnable import Runnable
    from langchain.callbacks.manager import CallbackManagerForChainRun
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False

logger = logging.getLogger(__name__)


class ElderlyWelfareRAGChain:
    """ë…¸ì¸ë³µì§€ ì •ì±… ì „ìš© RAG ì²´ì¸"""
    
    def __init__(self, 
                 retriever: BaseRetriever,
                 llm: Optional[Any] = None,
                 memory_k: int = 5):
        """
        Args:
            retriever: ë¬¸ì„œ ê²€ìƒ‰ê¸°
            llm: ì–¸ì–´ ëª¨ë¸ (Noneì´ë©´ OpenAI GPT ì‚¬ìš©)
            memory_k: ëŒ€í™” ê¸°ë¡ ì €ì¥ ê°œìˆ˜
        """
        self.retriever = retriever
        self.memory_k = memory_k
        
        # LLM ì„¤ì •
        if llm is None:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                # OpenAI API keyê°€ ìˆì„ ë•Œë§Œ ì‚¬ìš©
                self.llm = ChatOpenAI(
                    model="gpt-4o-mini",
                    temperature=0.1,
                    max_tokens=1500,
                    openai_api_key=api_key
                )
            else:
                # API keyê°€ ì—†ìœ¼ë©´ ë”ë¯¸ LLM ì‚¬ìš©
                self.llm = None
                print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        else:
            self.llm = llm
        
        # ë©”ëª¨ë¦¬ ì„¤ì •
        self.memory = ConversationBufferWindowMemory(
            k=memory_k,
            memory_key="chat_history",
            return_messages=True,
            output_key="answer"
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        self._setup_prompts()
        
        # ì²´ì¸ êµ¬ì„±
        self._setup_chains()
        
        logger.info("ë…¸ì¸ë³µì§€ RAG ì²´ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_prompts(self):
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •"""
        
        # ê¸°ë³¸ QA í”„ë¡¬í”„íŠ¸ (ëŒ€í™” ê¸°ë¡ ì—†ì„ ë•Œ)
        self.qa_prompt = PromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ë…¸ì¸ë³µì§€ ì •ì±… ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ ê·œì¹™:
1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ì œê³µëœ ìë£Œì—ì„œ í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”
3. êµ¬ì²´ì ì¸ ê¸ˆì•¡, ì¡°ê±´, ì ˆì°¨ê°€ ìˆë‹¤ë©´ ì •í™•íˆ ì•ˆë‚´í•˜ì„¸ìš”
4. ì‹ ì²­ ë°©ë²•ì´ë‚˜ ë¬¸ì˜ì²˜ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì•ˆë‚´í•˜ì„¸ìš”
5. ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³  ì¹œê·¼í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”

ì°¸ê³  ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
        )
        
        # ëŒ€í™”í˜• QA í”„ë¡¬í”„íŠ¸ (ëŒ€í™” ê¸°ë¡ ìˆì„ ë•Œ)
        self.conversational_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ë…¸ì¸ë³µì§€ ì •ì±… ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. 
            
ë‹¤ìŒ ì›ì¹™ì„ ì§€ì¼œì£¼ì„¸ìš”:
- ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ì •í™•íˆ ì „ë‹¬í•˜ì„¸ìš”
- ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê³ ë ¤í•˜ì—¬ ì—°ì†ì„± ìˆê²Œ ë‹µë³€í•˜ì„¸ìš”
- ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•˜ì„¸ìš”
- ë³µì§€ í˜œíƒì„ ë°›ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”
- í•­ìƒ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”

ì°¸ê³  ë¬¸ì„œ:
{context}"""),
            ("human", "{question}")
        ])
    
    def _setup_chains(self):
        """RAG ì²´ì¸ êµ¬ì„±"""
        if not LANGCHAIN_AVAILABLE:
            logger.warning("LangChainì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ êµ¬í˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.qa_chain = None
            self.conversational_chain = None
            return
        
        try:
            # ê¸°ë³¸ QA ì²´ì¸
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=self.retriever,
                chain_type_kwargs={
                    "prompt": self.qa_prompt
                },
                return_source_documents=True
            )
            
            # ëŒ€í™”í˜• ê²€ìƒ‰ ì²´ì¸
            self.conversational_chain = ConversationalRetrievalChain.from_llm(
                llm=self.llm,
                retriever=self.retriever,
                memory=self.memory,
                combine_docs_chain_kwargs={
                    "prompt": self.conversational_prompt
                },
                return_source_documents=True,
                verbose=False
            )
            
            logger.info("RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"RAG ì²´ì¸ êµ¬ì„± ì‹¤íŒ¨: {e}")
            self.qa_chain = None
            self.conversational_chain = None
    
    def ask(self, 
            question: str, 
            use_conversation: bool = True,
            include_sources: bool = True) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        
        # LLMì´ ì—†ìœ¼ë©´ ë”ë¯¸ ì‘ë‹µ
        if self.llm is None:
            return {
                "question": question,
                "answer": f"[ë”ë¯¸ ëª¨ë“œ] ì§ˆë¬¸: '{question}'ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ë ¤ë©´ OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "sources": [],
                "conversation_id": None,
                "timestamp": time.time(),
                "metadata": {"mode": "dummy", "llm_available": False}
            }
        
        try:
            if use_conversation and self.conversational_chain:
                # ëŒ€í™”í˜• ì²´ì¸ ì‚¬ìš©
                result = self.conversational_chain({
                    "question": question,
                    "chat_history": self.memory.chat_memory.messages
                })
            elif self.qa_chain:
                # ê¸°ë³¸ QA ì²´ì¸ ì‚¬ìš©
                result = self.qa_chain({"query": question})
            else:
                # ì²´ì¸ì´ ì—†ìœ¼ë©´ ì§ì ‘ êµ¬í˜„
                return self._fallback_answer(question)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            answer = result.get("answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            source_docs = result.get("source_documents", [])
            
            # ì†ŒìŠ¤ ì •ë³´ ì •ë¦¬
            sources = []
            if include_sources and source_docs:
                for i, doc in enumerate(source_docs[:3]):  # ìƒìœ„ 3ê°œë§Œ
                    source_info = {
                        "index": i + 1,
                        "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                        "metadata": doc.metadata
                    }
                    sources.append(source_info)
            
            return {
                "answer": answer,
                "sources": sources,
                "question": question,
                "timestamp": datetime.now().isoformat(),
                "success": True
            }
            
        except Exception as e:
            logger.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "sources": [],
                "question": question,
                "timestamp": datetime.now().isoformat(),
                "success": False,
                "error": str(e)
            }
    
    def _fallback_answer(self, question: str) -> Dict[str, Any]:
        """ì²´ì¸ì´ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ë‹µë³€ ìƒì„±"""
        
        try:
            # ë¦¬íŠ¸ë¦¬ë²„ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            docs = self.retriever.get_relevant_documents(question)
            
            if not docs:
                return {
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "question": question,
                    "timestamp": datetime.now().isoformat(),
                    "success": False
                }
            
            # ê°„ë‹¨í•œ ë‹µë³€ ìƒì„± (ë¬¸ì„œ ë‚´ìš© ìš”ì•½)
            context = "\n\n".join([doc.page_content for doc in docs[:3]])
            
            # LLM ì—†ì´ ê¸°ë³¸ ë‹µë³€
            answer = f"ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì„¸ìš”:\n\n{context[:500]}..."
            
            sources = [
                {
                    "index": i + 1,
                    "content": doc.page_content[:200] + "...",
                    "metadata": doc.metadata
                }
                for i, doc in enumerate(docs[:3])
            ]
            
            return {
                "answer": answer,
                "sources": sources,
                "question": question,
                "timestamp": datetime.now().isoformat(),
                "success": True
            }
            
        except Exception as e:
            logger.error(f"Fallback ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "answer": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": [],
                "question": question,
                "timestamp": datetime.now().isoformat(),
                "success": False,
                "error": str(e)
            }
    
    def clear_memory(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        if self.memory:
            self.memory.clear()
            logger.info("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
        if not self.memory:
            return []
        
        history = []
        messages = self.memory.chat_memory.messages
        
        for i in range(0, len(messages), 2):
            if i + 1 < len(messages):
                human_msg = messages[i]
                ai_msg = messages[i + 1]
                
                history.append({
                    "question": human_msg.content,
                    "answer": ai_msg.content,
                    "timestamp": getattr(human_msg, 'timestamp', '')
                })
        
        return history
    
    def save_conversation(self, file_path: str = None) -> str:
        """ëŒ€í™” ê¸°ë¡ ì €ì¥"""
        if file_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_path = f"conversation_history_{timestamp}.json"
        
        history = self.get_conversation_history()
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "conversation_history": history,
                    "saved_at": datetime.now().isoformat(),
                    "total_exchanges": len(history)
                }, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ëŒ€í™” ê¸°ë¡ ì €ì¥ ì™„ë£Œ: {file_path}")
            return file_path
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise


class MultiRAGSystem:
    """ë‹¤ì¤‘ RAG ì‹œìŠ¤í…œ (ì—¬ëŸ¬ ë¦¬íŠ¸ë¦¬ë²„ ì¡°í•©)"""
    
    def __init__(self):
        self.rag_chains = {}
        self.default_chain = None
    
    def register_rag_chain(self, name: str, rag_chain: ElderlyWelfareRAGChain, is_default: bool = False):
        """RAG ì²´ì¸ ë“±ë¡"""
        self.rag_chains[name] = rag_chain
        
        if is_default or self.default_chain is None:
            self.default_chain = name
        
        logger.info(f"RAG ì²´ì¸ ë“±ë¡: {name} (ê¸°ë³¸: {is_default})")
    
    def ask_all(self, question: str) -> Dict[str, Dict[str, Any]]:
        """ëª¨ë“  RAG ì²´ì¸ì—ì„œ ë‹µë³€ ìƒì„±"""
        results = {}
        
        for name, chain in self.rag_chains.items():
            try:
                result = chain.ask(question)
                results[name] = result
            except Exception as e:
                logger.error(f"{name} ì²´ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                results[name] = {
                    "answer": f"ì˜¤ë¥˜: {str(e)}",
                    "success": False,
                    "error": str(e)
                }
        
        return results
    
    def ask_best(self, question: str) -> Dict[str, Any]:
        """ìµœì  RAG ì²´ì¸ ì„ íƒí•˜ì—¬ ë‹µë³€"""
        # ëª¨ë“  ì²´ì¸ì—ì„œ ë‹µë³€ ìƒì„±
        all_results = self.ask_all(question)
        
        # ì„±ê³µí•œ ê²°ê³¼ë“¤ë§Œ í•„í„°ë§
        successful_results = {
            name: result for name, result in all_results.items() 
            if result.get('success', False)
        }
        
        if not successful_results:
            return {
                "answer": "ëª¨ë“  ì‹œìŠ¤í…œì—ì„œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "success": False,
                "all_results": all_results
            }
        
        # ì†ŒìŠ¤ê°€ ë§ì€ ê²°ê³¼ ì„ íƒ (ì •ë³´ê°€ í’ë¶€í•œ ë‹µë³€)
        best_name = max(
            successful_results.keys(), 
            key=lambda name: len(successful_results[name].get('sources', []))
        )
        
        best_result = successful_results[best_name]
        best_result['selected_chain'] = best_name
        best_result['all_results'] = all_results
        
        return best_result
    
    def ask(self, question: str, chain_name: str = None) -> Dict[str, Any]:
        """ì§€ì •ëœ ì²´ì¸ ë˜ëŠ” ê¸°ë³¸ ì²´ì¸ìœ¼ë¡œ ë‹µë³€"""
        target_chain = chain_name or self.default_chain
        
        if target_chain not in self.rag_chains:
            return {
                "answer": f"ì§€ì •ëœ RAG ì²´ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target_chain}",
                "success": False,
                "available_chains": list(self.rag_chains.keys())
            }
        
        return self.rag_chains[target_chain].ask(question)


class RAGEvaluator:
    """RAG ì‹œìŠ¤í…œ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.test_questions = [
            "65ì„¸ ì´ìƒ ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì› ì œë„ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì¹˜ë§¤ í™˜ìë¥¼ ìœ„í•œ ëŒë´„ ì„œë¹„ìŠ¤ëŠ” ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”?",
            "ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì ë…¸ì¸ì´ ë°›ì„ ìˆ˜ ìˆëŠ” í˜œíƒì€?",
            "ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ë…ê±°ë…¸ì¸ì„ ìœ„í•œ ì•ˆì „í™•ì¸ ì„œë¹„ìŠ¤ê°€ ìˆë‚˜ìš”?"
        ]
    
    def evaluate_rag_chain(self, rag_chain: ElderlyWelfareRAGChain, 
                          custom_questions: List[str] = None) -> Dict[str, Any]:
        """RAG ì²´ì¸ ì„±ëŠ¥ í‰ê°€"""
        
        questions = custom_questions or self.test_questions
        results = []
        
        for question in questions:
            try:
                result = rag_chain.ask(question)
                
                # í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°
                metrics = self._calculate_metrics(question, result)
                
                evaluation = {
                    "question": question,
                    "answer_length": len(result.get("answer", "")),
                    "source_count": len(result.get("sources", [])),
                    "success": result.get("success", False),
                    "response_time": metrics.get("response_time", 0),
                    "relevance_score": metrics.get("relevance_score", 0)
                }
                
                results.append(evaluation)
                
            except Exception as e:
                logger.error(f"í‰ê°€ ì‹¤íŒ¨ - {question}: {e}")
                results.append({
                    "question": question,
                    "success": False,
                    "error": str(e)
                })
        
        # ì „ì²´ í†µê³„
        successful_results = [r for r in results if r.get("success", False)]
        
        summary = {
            "total_questions": len(questions),
            "successful_answers": len(successful_results),
            "success_rate": len(successful_results) / len(questions) if questions else 0,
            "avg_answer_length": sum([r["answer_length"] for r in successful_results]) / len(successful_results) if successful_results else 0,
            "avg_source_count": sum([r["source_count"] for r in successful_results]) / len(successful_results) if successful_results else 0,
            "results": results
        }
        
        return summary
    
    def _calculate_metrics(self, question: str, result: Dict[str, Any]) -> Dict[str, float]:
        """ë‹µë³€ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        metrics = {}
        
        # ì‘ë‹µ ì‹œê°„ (ì‹¤ì œ ì¸¡ì •ì€ ë³„ë„ êµ¬í˜„ í•„ìš”)
        metrics["response_time"] = 1.0
        
        # ê´€ë ¨ì„± ì ìˆ˜ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜)
        answer = result.get("answer", "")
        question_words = set(question.lower().split())
        answer_words = set(answer.lower().split())
        
        if question_words and answer_words:
            intersection = len(question_words.intersection(answer_words))
            union = len(question_words.union(answer_words))
            metrics["relevance_score"] = intersection / union if union > 0 else 0
        else:
            metrics["relevance_score"] = 0
        
        return metrics
    
    def compare_rag_systems(self, rag_systems: Dict[str, ElderlyWelfareRAGChain]) -> Dict[str, Any]:
        """ì—¬ëŸ¬ RAG ì‹œìŠ¤í…œ ë¹„êµ í‰ê°€"""
        
        comparison_results = {}
        
        for name, rag_chain in rag_systems.items():
            logger.info(f"RAG ì‹œìŠ¤í…œ í‰ê°€: {name}")
            evaluation = self.evaluate_rag_chain(rag_chain)
            comparison_results[name] = evaluation
        
        # ì „ì²´ ë¹„êµ ìš”ì•½
        summary = {
            "system_count": len(rag_systems),
            "systems": {}
        }
        
        for name, eval_result in comparison_results.items():
            summary["systems"][name] = {
                "success_rate": eval_result["success_rate"],
                "avg_answer_length": eval_result["avg_answer_length"],
                "avg_source_count": eval_result["avg_source_count"]
            }
        
        # ìµœê³  ì„±ëŠ¥ ì‹œìŠ¤í…œ ì„ íƒ
        if comparison_results:
            best_system = max(
                comparison_results.keys(),
                key=lambda name: comparison_results[name]["success_rate"]
            )
            summary["best_system"] = best_system
        
        summary["detailed_results"] = comparison_results
        
        return summary


def main():
    """RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸ¤– RAG ì‹œìŠ¤í…œ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë¦¬íŠ¸ë¦¬ë²„
        class DummyRetriever:
            def get_relevant_documents(self, query):
                return [
                    Document(
                        page_content="ë§Œ 65ì„¸ ì´ìƒ ë…¸ì¸ì„ ëŒ€ìƒìœ¼ë¡œ ì˜ë£Œë¹„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.",
                        metadata={"source": "ì˜ë£Œë¹„ì§€ì›.pdf"}
                    )
                ]
        
        dummy_retriever = DummyRetriever()
        
        # RAG ì²´ì¸ ìƒì„± (LLM ì—†ì´)
        print("ğŸ“ RAG ì²´ì¸ ìƒì„±...")
        rag_chain = ElderlyWelfareRAGChain(
            retriever=dummy_retriever,
            llm=None  # OpenAI API ì—†ì´ í…ŒìŠ¤íŠ¸
        )
        
        # ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
        print("â“ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸...")
        question = "ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì›ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
        result = rag_chain.ask(question)
        
        print(f"ì§ˆë¬¸: {result['question']}")
        print(f"ë‹µë³€: {result['answer'][:200]}...")
        print(f"ì„±ê³µ: {result['success']}")
        print(f"ì†ŒìŠ¤ ê°œìˆ˜: {len(result['sources'])}")
        
        # ë‹¤ì¤‘ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ”„ ë‹¤ì¤‘ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸...")
        multi_rag = MultiRAGSystem()
        multi_rag.register_rag_chain("default", rag_chain, is_default=True)
        
        result = multi_rag.ask("ë…¸ì¸ë³µì§€ ì œë„ëŠ”?")
        print(f"ë‹¤ì¤‘ RAG ë‹µë³€: {result['answer'][:100]}...")
        
        print(f"\nâœ… RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()