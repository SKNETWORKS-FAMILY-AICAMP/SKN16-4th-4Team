# =========================================
# âœ‚ï¸ ì²­í‚¹ ì „ëµ ëª¨ë“ˆ
# =========================================

import re
import logging
from typing import List, Dict, Any, Optional, Tuple
from abc import ABC, abstractmethod
from dataclasses import dataclass
import pandas as pd

# LangChain í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„°
try:
    from langchain.text_splitter import (
        RecursiveCharacterTextSplitter,
        CharacterTextSplitter,
        TokenTextSplitter,
    )
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False

logger = logging.getLogger(__name__)


@dataclass
class ChunkMetadata:
    """ì²­í¬ ë©”íƒ€ë°ì´í„°"""
    chunk_id: str
    chunk_index: int
    chunk_size: int
    source_file: str
    chunk_strategy: str
    overlap_size: int = 0
    parent_section: str = ""
    
    
class BaseChunkStrategy(ABC):
    """ì²­í‚¹ ì „ëµ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str):
        self.name = name
    
    @abstractmethod
    def chunk_text(self, text: str, metadata: Dict = None) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í‚¹í•˜ëŠ” ì¶”ìƒ ë©”ì†Œë“œ"""
        pass
    
    def _create_chunk_dict(self, text: str, index: int, metadata: Dict = None) -> Dict[str, Any]:
        """ì²­í¬ ë”•ì…”ë„ˆë¦¬ ìƒì„± í—¬í¼"""
        chunk_metadata = ChunkMetadata(
            chunk_id=f"{metadata.get('file_name', 'unknown')}_{self.name}_{index}",
            chunk_index=index,
            chunk_size=len(text),
            source_file=metadata.get('file_name', ''),
            chunk_strategy=self.name,
            parent_section=metadata.get('section', '')
        )
        
        return {
            'text': text.strip(),
            'metadata': chunk_metadata.__dict__,
            'chunk_size': len(text.strip())
        }


class RecursiveChunkStrategy(BaseChunkStrategy):
    """ì¬ê·€ì  ë¬¸ì ë¶„í•  ì „ëµ (LangChain ê¸°ë°˜)"""
    
    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200, 
                 separators: List[str] = None):
        super().__init__("recursive_character")
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        
        if separators is None:
            # í•œêµ­ì–´ ë¬¸ì„œì— ìµœì í™”ëœ êµ¬ë¶„ì
            self.separators = [
                "\n\n",  # ë¬¸ë‹¨ êµ¬ë¶„
                "\n",    # ì¤„ë°”ê¿ˆ
                "ã€‚",    # í•œêµ­ì–´ ë§ˆì¹¨í‘œ
                ".",     # ì˜ì–´ ë§ˆì¹¨í‘œ
                "!",     # ëŠë‚Œí‘œ
                "?",     # ë¬¼ìŒí‘œ
                "ï¼›",    # ì„¸ë¯¸ì½œë¡ 
                ";",
                "ï¼š",    # ì½œë¡ 
                ":",
                " ",     # ê³µë°±
                ""       # ë§ˆì§€ë§‰ ëŒ€ì•ˆ
            ]
        else:
            self.separators = separators
        
        if LANGCHAIN_AVAILABLE:
            self.splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap,
                separators=self.separators,
                length_function=len
            )
        else:
            logger.warning("LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ìì²´ êµ¬í˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.splitter = None
    
    def chunk_text(self, text: str, metadata: Dict = None) -> List[Dict[str, Any]]:
        if metadata is None:
            metadata = {}
        
        if self.splitter:
            # LangChain ìŠ¤í”Œë¦¬í„° ì‚¬ìš©
            chunks = self.splitter.split_text(text)
        else:
            # ìì²´ êµ¬í˜„ ì‚¬ìš©
            chunks = self._manual_recursive_split(text)
        
        results = []
        for i, chunk_text in enumerate(chunks):
            if chunk_text.strip():  # ë¹ˆ ì²­í¬ ì œì™¸
                chunk_dict = self._create_chunk_dict(chunk_text, i, metadata)
                chunk_dict['metadata']['overlap_size'] = self.chunk_overlap
                results.append(chunk_dict)
        
        return results
    
    def _manual_recursive_split(self, text: str) -> List[str]:
        """ìˆ˜ë™ ì¬ê·€ ë¶„í•  êµ¬í˜„"""
        chunks = []
        
        def split_by_separator(text: str, separators: List[str]) -> List[str]:
            if not separators or len(text) <= self.chunk_size:
                return [text]
            
            separator = separators[0]
            if separator in text:
                parts = text.split(separator)
                result = []
                current_chunk = ""
                
                for part in parts:
                    if len(current_chunk) + len(part) + len(separator) <= self.chunk_size:
                        current_chunk += part + separator
                    else:
                        if current_chunk:
                            result.append(current_chunk.rstrip(separator))
                        current_chunk = part + separator
                
                if current_chunk:
                    result.append(current_chunk.rstrip(separator))
                
                return result
            else:
                return split_by_separator(text, separators[1:])
        
        return split_by_separator(text, self.separators)


class ParagraphChunkStrategy(BaseChunkStrategy):
    """ë¬¸ë‹¨ ê¸°ë°˜ ì²­í‚¹ ì „ëµ"""
    
    def __init__(self, min_paragraph_size: int = 50, max_paragraph_size: int = 2000):
        super().__init__("paragraph_based")
        self.min_paragraph_size = min_paragraph_size
        self.max_paragraph_size = max_paragraph_size
    
    def chunk_text(self, text: str, metadata: Dict = None) -> List[Dict[str, Any]]:
        if metadata is None:
            metadata = {}
        
        # ë¬¸ë‹¨ êµ¬ë¶„ (ì´ì¤‘ ì¤„ë°”ê¿ˆ ë˜ëŠ” íŠ¹ì • íŒ¨í„´)
        paragraphs = re.split(r'\n\s*\n|(?<=[.ã€‚!?])\s*\n(?=\s*[ê°€-í£A-Z])', text)
        
        results = []
        chunk_index = 0
        
        current_chunk = ""
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
            
            # ë¬¸ë‹¨ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ëˆ„ì 
            if len(paragraph) < self.min_paragraph_size:
                current_chunk += "\n\n" + paragraph if current_chunk else paragraph
            else:
                # í˜„ì¬ ëˆ„ì ëœ ì²­í¬ê°€ ìˆìœ¼ë©´ ë¨¼ì € ì²˜ë¦¬
                if current_chunk:
                    chunk_dict = self._create_chunk_dict(current_chunk, chunk_index, metadata)
                    results.append(chunk_dict)
                    chunk_index += 1
                    current_chunk = ""
                
                # ë¬¸ë‹¨ì´ ë„ˆë¬´ í¬ë©´ ë¶„í• 
                if len(paragraph) > self.max_paragraph_size:
                    sub_chunks = self._split_large_paragraph(paragraph)
                    for sub_chunk in sub_chunks:
                        chunk_dict = self._create_chunk_dict(sub_chunk, chunk_index, metadata)
                        results.append(chunk_dict)
                        chunk_index += 1
                else:
                    chunk_dict = self._create_chunk_dict(paragraph, chunk_index, metadata)
                    results.append(chunk_dict)
                    chunk_index += 1
        
        # ë§ˆì§€ë§‰ ëˆ„ì  ì²­í¬ ì²˜ë¦¬
        if current_chunk:
            chunk_dict = self._create_chunk_dict(current_chunk, chunk_index, metadata)
            results.append(chunk_dict)
        
        return results
    
    def _split_large_paragraph(self, paragraph: str) -> List[str]:
        """í° ë¬¸ë‹¨ì„ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• """
        sentences = re.split(r'(?<=[.ã€‚!?])\s+', paragraph)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk) + len(sentence) <= self.max_paragraph_size:
                current_chunk += " " + sentence if current_chunk else sentence
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = sentence
        
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks


class SentenceChunkStrategy(BaseChunkStrategy):
    """ë¬¸ì¥ ê¸°ë°˜ ì²­í‚¹ ì „ëµ"""
    
    def __init__(self, sentences_per_chunk: int = 3, min_chunk_size: int = 100):
        super().__init__("sentence_based")
        self.sentences_per_chunk = sentences_per_chunk
        self.min_chunk_size = min_chunk_size
    
    def chunk_text(self, text: str, metadata: Dict = None) -> List[Dict[str, Any]]:
        if metadata is None:
            metadata = {}
        
        # ë¬¸ì¥ ë¶„í•  (í•œêµ­ì–´ì™€ ì˜ì–´ ëª¨ë‘ ê³ ë ¤)
        sentences = self._split_sentences(text)
        
        results = []
        chunk_index = 0
        
        for i in range(0, len(sentences), self.sentences_per_chunk):
            chunk_sentences = sentences[i:i + self.sentences_per_chunk]
            chunk_text = " ".join(chunk_sentences).strip()
            
            # ìµœì†Œ í¬ê¸° í™•ì¸
            if len(chunk_text) >= self.min_chunk_size:
                chunk_dict = self._create_chunk_dict(chunk_text, chunk_index, metadata)
                results.append(chunk_dict)
                chunk_index += 1
        
        return results
    
    def _split_sentences(self, text: str) -> List[str]:
        """í•œêµ­ì–´/ì˜ì–´ ë¬¸ì¥ ë¶„í• """
        # í•œêµ­ì–´ì™€ ì˜ì–´ ë¬¸ì¥ ì¢…ê²° íŒ¨í„´
        sentence_endings = r'[.ã€‚!?ï¼ï¼Ÿ]\s*'
        sentences = re.split(sentence_endings, text)
        
        # ë¹ˆ ë¬¸ì¥ ì œê±° ë° ì •ë¦¬
        sentences = [s.strip() for s in sentences if s.strip()]
        return sentences


class SemanticChunkStrategy(BaseChunkStrategy):
    """ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹ ì „ëµ (ì •ì±… ë¬¸ì„œ íŠ¹í™”)"""
    
    def __init__(self, chunk_size: int = 800, policy_keywords: List[str] = None):
        super().__init__("semantic_policy")
        self.chunk_size = chunk_size
        
        if policy_keywords is None:
            # ë…¸ì¸ë³µì§€ ì •ì±… í‚¤ì›Œë“œ
            self.policy_keywords = [
                "ì§€ì›", "í˜œíƒ", "ëŒ€ìƒ", "ìê²©", "ì¡°ê±´", "ì‹ ì²­", "ë°©ë²•",
                "ê¸°ì¤€", "ë²”ìœ„", "í•œë„", "ê¸°ê°„", "ì ˆì°¨", "ì„œë¥˜", "ì œì¶œ",
                "ë…¸ì¸", "ì–´ë¥´ì‹ ", "ê³ ë ¹ì", "ë³µì§€", "ë³´ì¡°ê¸ˆ", "ìˆ˜ë‹¹",
                "ì˜ë£Œë¹„", "ê°„ë³‘", "ìš”ì–‘", "ëŒë´„", "ìƒí™œì§€ì›"
            ]
        else:
            self.policy_keywords = policy_keywords
    
    def chunk_text(self, text: str, metadata: Dict = None) -> List[Dict[str, Any]]:
        if metadata is None:
            metadata = {}
        
        # ì •ì±… ì„¹ì…˜ íƒì§€ ë° ë¶„í• 
        sections = self._detect_policy_sections(text)
        
        results = []
        chunk_index = 0
        
        for section_title, section_text in sections:
            # ì„¹ì…˜ì´ ë„ˆë¬´ í¬ë©´ ì¶”ê°€ ë¶„í• 
            if len(section_text) > self.chunk_size * 1.5:
                sub_chunks = self._split_semantic_section(section_text)
                for sub_chunk in sub_chunks:
                    chunk_dict = self._create_chunk_dict(sub_chunk, chunk_index, metadata)
                    chunk_dict['metadata']['parent_section'] = section_title
                    results.append(chunk_dict)
                    chunk_index += 1
            else:
                chunk_dict = self._create_chunk_dict(section_text, chunk_index, metadata)
                chunk_dict['metadata']['parent_section'] = section_title
                results.append(chunk_dict)
                chunk_index += 1
        
        return results
    
    def _detect_policy_sections(self, text: str) -> List[Tuple[str, str]]:
        """ì •ì±… ë¬¸ì„œì˜ ì˜ë¯¸ì  ì„¹ì…˜ íƒì§€"""
        sections = []
        
        # ì„¹ì…˜ ì œëª© íŒ¨í„´ (ìˆ«ì, í•œê¸€, íŠ¹ìˆ˜ë¬¸ì ì¡°í•©)
        section_patterns = [
            r'^[0-9]+\.\s*[ê°€-í£\s]+',  # "1. ì§€ì›ëŒ€ìƒ"
            r'^[ê°€-í£]+\s*[:ï¼š]\s*',      # "ì§€ì›ë‚´ìš©:"
            r'^â€»\s*[ê°€-í£\s]+',         # "â€» ì‹ ì²­ë°©ë²•"
            r'^[â–¶â–·â– â–¡â—‹â—]\s*[ê°€-í£\s]+', # "â–¶ ì§€ì›ë²”ìœ„"
            r'^[ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\.\s*[ê°€-í£\s]+' # "ê°€. ëŒ€ìƒì"
        ]
        
        lines = text.split('\n')
        current_section = "ê¸°íƒ€"
        current_content = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ì„¹ì…˜ ì œëª©ì¸ì§€ í™•ì¸
            is_section_title = False
            for pattern in section_patterns:
                if re.match(pattern, line):
                    # ì´ì „ ì„¹ì…˜ ì €ì¥
                    if current_content:
                        sections.append((current_section, '\n'.join(current_content)))
                    
                    # ìƒˆ ì„¹ì…˜ ì‹œì‘
                    current_section = line
                    current_content = []
                    is_section_title = True
                    break
            
            if not is_section_title:
                current_content.append(line)
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_content:
            sections.append((current_section, '\n'.join(current_content)))
        
        return sections
    
    def _split_semantic_section(self, text: str) -> List[str]:
        """ì˜ë¯¸ì  ì„¹ì…˜ì„ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í• """
        # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë¶„í• ì  ì°¾ê¸°
        sentences = re.split(r'(?<=[.ã€‚!?])\s+', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ì—ì„œ ìš°ì„ ì ìœ¼ë¡œ ë¶„í• 
            has_keyword = any(keyword in sentence for keyword in self.policy_keywords)
            
            if len(current_chunk) + len(sentence) <= self.chunk_size:
                current_chunk += " " + sentence if current_chunk else sentence
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = sentence
        
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks


class ChunkStrategyComparator:
    """ì²­í‚¹ ì „ëµ ë¹„êµ ë° í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.strategies = {
            'recursive': RecursiveChunkStrategy(),
            'paragraph': ParagraphChunkStrategy(),
            'sentence': SentenceChunkStrategy(),
            'semantic': SemanticChunkStrategy()
        }
    
    def compare_strategies(self, text: str, metadata: Dict = None) -> Dict[str, Any]:
        """ëª¨ë“  ì „ëµìœ¼ë¡œ ì²­í‚¹í•˜ê³  ê²°ê³¼ ë¹„êµ"""
        if metadata is None:
            metadata = {'file_name': 'sample_text'}
        
        results = {}
        
        for strategy_name, strategy in self.strategies.items():
            try:
                chunks = strategy.chunk_text(text, metadata)
                
                # í†µê³„ ê³„ì‚°
                chunk_sizes = [chunk['chunk_size'] for chunk in chunks]
                
                stats = {
                    'total_chunks': len(chunks),
                    'avg_chunk_size': sum(chunk_sizes) / len(chunk_sizes) if chunk_sizes else 0,
                    'min_chunk_size': min(chunk_sizes) if chunk_sizes else 0,
                    'max_chunk_size': max(chunk_sizes) if chunk_sizes else 0,
                    'total_characters': sum(chunk_sizes),
                    'coverage_ratio': sum(chunk_sizes) / len(text) if text else 0,
                    'chunks': chunks[:3]  # ì²˜ìŒ 3ê°œ ì²­í¬ë§Œ ì €ì¥
                }
                
                results[strategy_name] = stats
                
            except Exception as e:
                logger.error(f"ì „ëµ {strategy_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                results[strategy_name] = {'error': str(e)}
        
        return results
    
    def evaluate_chunking_quality(self, text: str, metadata: Dict = None) -> pd.DataFrame:
        """ì²­í‚¹ í’ˆì§ˆ í‰ê°€ ë° ì¶”ì²œ"""
        comparison = self.compare_strategies(text, metadata)
        
        evaluation_data = []
        
        for strategy_name, stats in comparison.items():
            if 'error' in stats:
                continue
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_scores = self._calculate_quality_scores(stats, len(text))
            
            row = {
                'strategy': strategy_name,
                'total_chunks': stats['total_chunks'],
                'avg_chunk_size': round(stats['avg_chunk_size'], 1),
                'size_consistency': quality_scores['size_consistency'],
                'coverage_ratio': round(stats['coverage_ratio'], 3),
                'overall_score': quality_scores['overall_score']
            }
            
            evaluation_data.append(row)
        
        df = pd.DataFrame(evaluation_data)
        
        if not df.empty:
            # ì ìˆ˜ìˆœ ì •ë ¬
            df = df.sort_values('overall_score', ascending=False)
        
        return df
    
    def _calculate_quality_scores(self, stats: Dict, original_length: int) -> Dict[str, float]:
        """ì²­í‚¹ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        # í¬ê¸° ì¼ê´€ì„± (í‘œì¤€í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
        avg_size = stats['avg_chunk_size']
        min_size = stats['min_chunk_size']
        max_size = stats['max_chunk_size']
        
        if avg_size > 0:
            size_variance = ((max_size - avg_size) ** 2 + (min_size - avg_size) ** 2) / 2
            size_consistency = 1 / (1 + size_variance / (avg_size ** 2))
        else:
            size_consistency = 0
        
        # ì ì ˆí•œ ì²­í¬ ìˆ˜ (ë„ˆë¬´ ë§ê±°ë‚˜ ì ìœ¼ë©´ ê°ì )
        optimal_chunks = original_length / 800  # 800ìë‹¹ 1ì²­í¬ê°€ ì ì ˆ
        chunk_count_score = 1 / (1 + abs(stats['total_chunks'] - optimal_chunks) / optimal_chunks)
        
        # ì»¤ë²„ë¦¬ì§€ ì ìˆ˜
        coverage_score = min(stats['coverage_ratio'], 1.0)
        
        # ì „ì²´ ì ìˆ˜ (ê°€ì¤‘í‰ê· )
        overall_score = (
            size_consistency * 0.3 +
            chunk_count_score * 0.3 +
            coverage_score * 0.4
        )
        
        return {
            'size_consistency': round(size_consistency, 3),
            'chunk_count_score': round(chunk_count_score, 3),
            'coverage_score': round(coverage_score, 3),
            'overall_score': round(overall_score, 3)
        }
    
    def get_strategy_recommendation(self, text: str, metadata: Dict = None) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì— ìµœì í™”ëœ ì²­í‚¹ ì „ëµ ì¶”ì²œ"""
        evaluation_df = self.evaluate_chunking_quality(text, metadata)
        
        if evaluation_df.empty:
            return {
                'recommended_strategy': 'recursive',
                'reason': 'ê¸°ë³¸ ì „ëµ',
                'evaluation': None
            }
        
        best_strategy = evaluation_df.iloc[0]
        
        # ì¶”ì²œ ì´ìœ  ìƒì„±
        reasons = []
        if best_strategy['overall_score'] > 0.8:
            reasons.append("ë†’ì€ ì „ì²´ í’ˆì§ˆ ì ìˆ˜")
        if best_strategy['size_consistency'] > 0.8:
            reasons.append("ì¼ê´€ëœ ì²­í¬ í¬ê¸°")
        if best_strategy['coverage_ratio'] > 0.95:
            reasons.append("ë†’ì€ í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€")
        
        return {
            'recommended_strategy': best_strategy['strategy'],
            'score': best_strategy['overall_score'],
            'reason': ', '.join(reasons) if reasons else 'ìµœì  ì„±ëŠ¥',
            'evaluation': evaluation_df
        }


def main():
    """ì²­í‚¹ ì „ëµ í…ŒìŠ¤íŠ¸ ë° ë¹„êµ"""
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ (ë…¸ì¸ë³µì§€ ì •ì±… ì˜ˆì‹œ)
    sample_text = """
    ë…¸ì¸ë³µì§€ë²•ì— ë”°ë¥¸ ìƒí™œì§€ì› ì„œë¹„ìŠ¤ ì•ˆë‚´
    
    1. ì§€ì›ëŒ€ìƒ
    ë§Œ 65ì„¸ ì´ìƒ ë…¸ì¸ ì¤‘ ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì ë° ì°¨ìƒìœ„ ê³„ì¸µì— í•´ë‹¹í•˜ëŠ” ë¶„ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤.
    
    2. ì§€ì›ë‚´ìš©
    ê°€. ìƒí™œë¹„ ì§€ì›: ì›” ìµœëŒ€ 30ë§Œì›ê¹Œì§€ ì§€ì›
    ë‚˜. ì˜ë£Œë¹„ ì§€ì›: ì—°ê°„ 200ë§Œì› í•œë„ ë‚´ì—ì„œ ë³¸ì¸ë¶€ë‹´ê¸ˆ ì§€ì›
    ë‹¤. ëŒë´„ì„œë¹„ìŠ¤: ì£¼ 3íšŒ, íšŒë‹¹ 4ì‹œê°„ ëŒë´„ì„œë¹„ìŠ¤ ì œê³µ
    
    3. ì‹ ì²­ë°©ë²•
    ê±°ì£¼ì§€ ê´€í•  ì£¼ë¯¼ì„¼í„° ë˜ëŠ” ë³µì§€ê´€ì— ì‹ ì²­ì„œë¥˜ë¥¼ ì œì¶œí•˜ì‹œë©´ ë©ë‹ˆë‹¤.
    
    â–¶ í•„ìš”ì„œë¥˜
    - ì‹ ì²­ì„œ (ì£¼ë¯¼ì„¼í„° ë¹„ì¹˜)
    - ì†Œë“ì¦ëª…ì„œ
    - ê±´ê°•ë³´í—˜ë£Œ ë‚©ë¶€í™•ì¸ì„œ
    - ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ
    
    â€» ì‹ ì²­ í›„ 7ì¼ ì´ë‚´ì— ê²°ê³¼ í†µë³´
    ì‹¬ì‚¬ ê¸°ê°„ ì¤‘ ì¶”ê°€ ì„œë¥˜ ìš”ì²­ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    
    print("ğŸ” ì²­í‚¹ ì „ëµ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    comparator = ChunkStrategyComparator()
    
    # ì „ëµë³„ ë¹„êµ
    results = comparator.compare_strategies(sample_text)
    
    print("\nğŸ“Š ì „ëµë³„ ì²­í‚¹ ê²°ê³¼:")
    for strategy, stats in results.items():
        if 'error' not in stats:
            print(f"\n[{strategy.upper()}]")
            print(f"  ì´ ì²­í¬ ìˆ˜: {stats['total_chunks']}")
            print(f"  í‰ê·  ì²­í¬ í¬ê¸°: {stats['avg_chunk_size']:.1f}ì")
            print(f"  í¬ê¸° ë²”ìœ„: {stats['min_chunk_size']}-{stats['max_chunk_size']}ì")
            print(f"  ì»¤ë²„ë¦¬ì§€: {stats['coverage_ratio']:.1%}")
            
            # ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°
            if stats['chunks']:
                preview = stats['chunks'][0]['text'][:100] + "..."
                print(f"  ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: {preview}")
    
    # í’ˆì§ˆ í‰ê°€
    evaluation_df = comparator.evaluate_chunking_quality(sample_text)
    
    print(f"\nğŸ† ì²­í‚¹ í’ˆì§ˆ í‰ê°€:")
    print(evaluation_df.to_string(index=False))
    
    # ìµœì  ì „ëµ ì¶”ì²œ
    recommendation = comparator.get_strategy_recommendation(sample_text)
    
    print(f"\nâœ… ì¶”ì²œ ì „ëµ: {recommendation['recommended_strategy'].upper()}")
    print(f"   ì ìˆ˜: {recommendation['score']}")
    print(f"   ì´ìœ : {recommendation['reason']}")


class ChunkStrategyManager:
    """ì²­í‚¹ ì „ëµ ê´€ë¦¬ í´ë˜ìŠ¤ (í†µí•© ë¹„êµí‰ê°€ìš©)"""
    
    def __init__(self):
        """ì²­í‚¹ ì „ëµ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.comparator = ChunkStrategyComparator()
        logger.info("ì²­í‚¹ ì „ëµ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
    
    def chunk_text(self, text: str, strategy: str = "recursive") -> List[str]:
        """
        ì§€ì •ëœ ì „ëµìœ¼ë¡œ í…ìŠ¤íŠ¸ ì²­í‚¹
        
        Args:
            text: ì²­í‚¹í•  í…ìŠ¤íŠ¸
            strategy: ì²­í‚¹ ì „ëµ ('recursive', 'semantic', 'fixed_size', 'sentence')
            
        Returns:
            List[str]: ì²­í‚¹ëœ í…ìŠ¤íŠ¸ ì¡°ê°ë“¤
        """
        try:
            # ì „ëµ ë§¤í•‘
            strategy_mapping = {
                'recursive': 'recursive',
                'semantic': 'semantic', 
                'fixed_size': 'fixed_size',
                'sentence': 'sentence'
            }
            
            actual_strategy = strategy_mapping.get(strategy, 'recursive')
            
            # ì²­í‚¹ ì‹¤í–‰
            results = self.comparator.compare_strategies(text)
            
            if actual_strategy in results and 'chunks' in results[actual_strategy]:
                chunks = results[actual_strategy]['chunks']
                return [chunk['text'] for chunk in chunks]
            else:
                # ê¸°ë³¸ ì²­í‚¹ (ë¬¸ì¥ ë‹¨ìœ„)
                sentences = re.split(r'[.!?]+\s*', text)
                return [s.strip() for s in sentences if s.strip()]
                
        except Exception as e:
            logger.error(f"ì²­í‚¹ ì‹¤í–‰ ì‹¤íŒ¨ ({strategy}): {e}")
            # ê¸°ë³¸ ì²­í‚¹
            return [text[i:i+500] for i in range(0, len(text), 500)]
    
    def get_available_strategies(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì²­í‚¹ ì „ëµ ëª©ë¡ ë°˜í™˜"""
        return ['recursive', 'semantic', 'fixed_size', 'sentence']
    
    def evaluate_strategy_performance(self, text: str, strategy: str) -> Dict[str, Any]:
        """
        íŠ¹ì • ì „ëµì˜ ì„±ëŠ¥ í‰ê°€
        
        Args:
            text: í‰ê°€í•  í…ìŠ¤íŠ¸
            strategy: ì²­í‚¹ ì „ëµ
            
        Returns:
            Dict[str, Any]: ì„±ëŠ¥ í‰ê°€ ê²°ê³¼
        """
        try:
            results = self.comparator.compare_strategies(text)
            
            if strategy in results and 'error' not in results[strategy]:
                stats = results[strategy]
                
                return {
                    'strategy': strategy,
                    'chunk_count': stats['total_chunks'],
                    'avg_chunk_size': stats['avg_chunk_size'],
                    'coverage_ratio': stats['coverage_ratio'],
                    'processing_time': stats.get('processing_time', 0),
                    'success': True
                }
            else:
                return {
                    'strategy': strategy,
                    'chunk_count': 0,
                    'avg_chunk_size': 0,
                    'coverage_ratio': 0,
                    'processing_time': 0,
                    'success': False,
                    'error': results.get(strategy, {}).get('error', 'Unknown error')
                }
                
        except Exception as e:
            return {
                'strategy': strategy,
                'chunk_count': 0,
                'avg_chunk_size': 0,
                'coverage_ratio': 0,
                'processing_time': 0,
                'success': False,
                'error': str(e)
            }


if __name__ == "__main__":
    main()