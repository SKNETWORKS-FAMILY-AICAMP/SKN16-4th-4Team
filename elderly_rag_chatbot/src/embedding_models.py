# =========================================
# ðŸ§  ìž„ë² ë”© ëª¨ë¸ ë¹„êµ ëª¨ë“ˆ
# =========================================

import os
import logging
import time
import numpy as np
from typing import List, Dict, Any, Optional, Tuple, Union
from abc import ABC, abstractmethod
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns

# ìž„ë² ë”© ëª¨ë¸ ìž„í¬íŠ¸
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

try:
    from langchain_openai import OpenAIEmbeddings
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from transformers import AutoTokenizer, AutoModel
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

logger = logging.getLogger(__name__)


class BaseEmbeddingModel(ABC):
    """ìž„ë² ë”© ëª¨ë¸ ê¸°ë³¸ í´ëž˜ìŠ¤"""
    
    def __init__(self, model_name: str, model_type: str):
        self.model_name = model_name
        self.model_type = model_type
        self.is_initialized = False
        self.embedding_dim = None
    
    @abstractmethod
    def initialize(self) -> bool:
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        pass
    
    @abstractmethod
    def embed_texts(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìž„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        pass
    
    @abstractmethod
    def embed_query(self, query: str) -> np.ndarray:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¥¼ ìž„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        pass
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            'model_name': self.model_name,
            'model_type': self.model_type,
            'is_initialized': self.is_initialized,
            'embedding_dim': self.embedding_dim
        }


class OpenAIEmbeddingModel(BaseEmbeddingModel):
    """OpenAI ìž„ë² ë”© ëª¨ë¸"""
    
    def __init__(self, model_name: str = "text-embedding-ada-002"):
        super().__init__(model_name, "OpenAI")
        self.client = None
    
    def initialize(self) -> bool:
        """OpenAI ìž„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        if not OPENAI_AVAILABLE:
            logger.error("OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            logger.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            self.client = OpenAIEmbeddings(
                model=self.model_name,
                openai_api_key=api_key
            )
            
            # í…ŒìŠ¤íŠ¸ ìž„ë² ë”©ìœ¼ë¡œ ì°¨ì› í™•ì¸
            test_embedding = self.client.embed_query("í…ŒìŠ¤íŠ¸")
            self.embedding_dim = len(test_embedding)
            self.is_initialized = True
            
            logger.info(f"OpenAI ìž„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.model_name} (dim: {self.embedding_dim})")
            return True
            
        except Exception as e:
            logger.error(f"OpenAI ìž„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def embed_texts(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìž„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if not self.is_initialized:
            raise RuntimeError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            embeddings = self.client.embed_documents(texts)
            return np.array(embeddings)
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def embed_query(self, query: str) -> np.ndarray:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¥¼ ìž„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if not self.is_initialized:
            raise RuntimeError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            embedding = self.client.embed_query(query)
            return np.array(embedding)
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise


class SentenceTransformerModel(BaseEmbeddingModel):
    """SentenceTransformer ê¸°ë°˜ ìž„ë² ë”© ëª¨ë¸"""
    
    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        super().__init__(model_name, "SentenceTransformer")
        self.model = None
    
    def initialize(self) -> bool:
        """SentenceTransformer ëª¨ë¸ ì´ˆê¸°í™”"""
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            logger.error("sentence-transformers íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            self.model = SentenceTransformer(self.model_name)
            
            # í…ŒìŠ¤íŠ¸ ìž„ë² ë”©ìœ¼ë¡œ ì°¨ì› í™•ì¸
            test_embedding = self.model.encode("í…ŒìŠ¤íŠ¸")
            self.embedding_dim = len(test_embedding)
            self.is_initialized = True
            
            logger.info(f"SentenceTransformer ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.model_name} (dim: {self.embedding_dim})")
            return True
            
        except Exception as e:
            logger.error(f"SentenceTransformer ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def embed_texts(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìž„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if not self.is_initialized:
            raise RuntimeError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            embeddings = self.model.encode(texts, convert_to_numpy=True)
            return embeddings
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def embed_query(self, query: str) -> np.ndarray:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¥¼ ìž„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if not self.is_initialized:
            raise RuntimeError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            embedding = self.model.encode(query, convert_to_numpy=True)
            return embedding
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise


class KoBERTEmbeddingModel(BaseEmbeddingModel):
    """í•œêµ­ì–´ BERT ìž„ë² ë”© ëª¨ë¸ (Transformers ê¸°ë°˜)"""
    
    def __init__(self, model_name: str = "klue/bert-base"):
        super().__init__(model_name, "KoBERT")
        self.tokenizer = None
        self.model = None
        self.device = None
    
    def initialize(self) -> bool:
        """KoBERT ëª¨ë¸ ì´ˆê¸°í™”"""
        if not TRANSFORMERS_AVAILABLE:
            logger.error("transformers íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModel.from_pretrained(self.model_name)
            self.model.to(self.device)
            self.model.eval()
            
            # í…ŒìŠ¤íŠ¸ ìž„ë² ë”©ìœ¼ë¡œ ì°¨ì› í™•ì¸
            test_embedding = self._encode_text("í…ŒìŠ¤íŠ¸")
            self.embedding_dim = len(test_embedding)
            self.is_initialized = True
            
            logger.info(f"KoBERT ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.model_name} (dim: {self.embedding_dim})")
            return True
            
        except Exception as e:
            logger.error(f"KoBERT ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _encode_text(self, text: str) -> np.ndarray:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì¸ì½”ë”©"""
        inputs = self.tokenizer(
            text, 
            return_tensors="pt", 
            truncation=True, 
            padding=True, 
            max_length=512
        )
        
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            # [CLS] í† í°ì˜ ìž„ë² ë”© ì‚¬ìš©
            embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
        
        return embeddings.squeeze()
    
    def embed_texts(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìž„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if not self.is_initialized:
            raise RuntimeError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            embeddings = []
            for text in texts:
                embedding = self._encode_text(text)
                embeddings.append(embedding)
            
            return np.array(embeddings)
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def embed_query(self, query: str) -> np.ndarray:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¥¼ ìž„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if not self.is_initialized:
            raise RuntimeError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            return self._encode_text(query)
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise


class EmbeddingModelComparator:
    """ìž„ë² ë”© ëª¨ë¸ ë¹„êµ ë° í‰ê°€ í´ëž˜ìŠ¤"""
    
    def __init__(self):
        self.models = {}
        self.welfare_keywords = [
            "ë…¸ì¸", "ì–´ë¥´ì‹ ", "ê³ ë ¹ìž", "ë³µì§€", "ì§€ì›", "í˜œíƒ",
            "ì˜ë£Œë¹„", "ê°„ë³‘", "ìš”ì–‘", "ëŒë´„", "ìƒí™œì§€ì›", "ìˆ˜ë‹¹",
            "ì‹ ì²­", "ëŒ€ìƒ", "ìžê²©", "ì¡°ê±´", "ë°©ë²•", "ì ˆì°¨"
        ]
        
        # ë…¸ì¸ë³µì§€ ê´€ë ¨ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        self.test_texts = [
            "ë§Œ 65ì„¸ ì´ìƒ ë…¸ì¸ì„ ëŒ€ìƒìœ¼ë¡œ ì˜ë£Œë¹„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.",
            "ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ìž ì–´ë¥´ì‹ ì—ê²Œ ìƒí™œë¹„ë¥¼ ì§€ì›í•˜ëŠ” ì œë„ìž…ë‹ˆë‹¤.",
            "ìš”ì–‘ë³´í˜¸ì‚¬ê°€ ë°©ë¬¸í•˜ì—¬ ëŒë´„ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
            "ê±°ë™ì´ ë¶ˆíŽ¸í•œ ê³ ë ¹ìžë¥¼ ìœ„í•œ ì´ë™ì§€ì› ì„œë¹„ìŠ¤ìž…ë‹ˆë‹¤.",
            "ì¹˜ë§¤ ì–´ë¥´ì‹ ì„ ìœ„í•œ ì¸ì§€ê¸°ëŠ¥ í–¥ìƒ í”„ë¡œê·¸ëž¨ìž…ë‹ˆë‹¤."
        ]
        
        self.test_queries = [
            "ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì›",
            "ì–´ë¥´ì‹  ëŒë´„ ì„œë¹„ìŠ¤",
            "ê³ ë ¹ìž ë³µì§€ í˜œíƒ",
            "ë…¸ì¸ë³µì§€ ì‹ ì²­ ë°©ë²•"
        ]
    
    def register_model(self, model: BaseEmbeddingModel, alias: str = None) -> bool:
        """ìž„ë² ë”© ëª¨ë¸ ë“±ë¡"""
        if alias is None:
            alias = model.model_type.lower()
        
        if model.initialize():
            self.models[alias] = model
            logger.info(f"ëª¨ë¸ ë“±ë¡ ì™„ë£Œ: {alias}")
            return True
        else:
            logger.error(f"ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨: {alias}")
            return False
    
    def initialize_available_models(self) -> Dict[str, bool]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ ì´ˆê¸°í™”"""
        results = {}
        
        # OpenAI ëª¨ë¸
        try:
            openai_model = OpenAIEmbeddingModel()
            results['openai'] = self.register_model(openai_model, 'openai')
        except Exception as e:
            logger.warning(f"OpenAI ëª¨ë¸ ì´ˆê¸°í™” ê±´ë„ˆëœ€: {e}")
            results['openai'] = False
        
        # SentenceTransformer ëª¨ë¸ë“¤
        sentence_models = [
            ("sentence-transformers/all-MiniLM-L6-v2", "minilm"),
            ("sentence-transformers/all-mpnet-base-v2", "mpnet"),
            ("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "multilingual")
        ]
        
        for model_name, alias in sentence_models:
            try:
                st_model = SentenceTransformerModel(model_name)
                results[alias] = self.register_model(st_model, alias)
            except Exception as e:
                logger.warning(f"{alias} ëª¨ë¸ ì´ˆê¸°í™” ê±´ë„ˆëœ€: {e}")
                results[alias] = False
        
        # KoBERT ëª¨ë¸ë“¤
        kobert_models = [
            ("klue/bert-base", "kobert_klue"),
            ("monologg/kobert", "kobert_mono")
        ]
        
        for model_name, alias in kobert_models:
            try:
                kobert_model = KoBERTEmbeddingModel(model_name)
                results[alias] = self.register_model(kobert_model, alias)
            except Exception as e:
                logger.warning(f"{alias} ëª¨ë¸ ì´ˆê¸°í™” ê±´ë„ˆëœ€: {e}")
                results[alias] = False
        
        logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {sum(results.values())}/{len(results)}")
        return results
    
    def benchmark_models(self, custom_texts: List[str] = None) -> pd.DataFrame:
        """ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        if not self.models:
            logger.error("ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        texts_to_test = custom_texts if custom_texts else self.test_texts
        
        benchmark_results = []
        
        for model_alias, model in self.models.items():
            logger.info(f"ë²¤ì¹˜ë§ˆí‚¹: {model_alias}")
            
            try:
                # ìž„ë² ë”© ìƒì„± ì‹œê°„ ì¸¡ì •
                start_time = time.time()
                embeddings = model.embed_texts(texts_to_test)
                embedding_time = time.time() - start_time
                
                # ì¿¼ë¦¬ ìž„ë² ë”© ì‹œê°„ ì¸¡ì •
                query_times = []
                for query in self.test_queries:
                    start_time = time.time()
                    query_embedding = model.embed_query(query)
                    query_times.append(time.time() - start_time)
                
                avg_query_time = np.mean(query_times)
                
                # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
                quality_metrics = self._calculate_quality_metrics(
                    model, embeddings, texts_to_test
                )
                
                result = {
                    'model': model_alias,
                    'model_type': model.model_type,
                    'embedding_dim': model.embedding_dim,
                    'total_embedding_time': round(embedding_time, 3),
                    'avg_query_time': round(avg_query_time, 3),
                    'texts_per_second': round(len(texts_to_test) / embedding_time, 2),
                    **quality_metrics
                }
                
                benchmark_results.append(result)
                
            except Exception as e:
                logger.error(f"{model_alias} ë²¤ì¹˜ë§ˆí‚¹ ì‹¤íŒ¨: {e}")
                continue
        
        df = pd.DataFrame(benchmark_results)
        
        if not df.empty:
            # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ì†ë„ì™€ í’ˆì§ˆì˜ ê°€ì¤‘í‰ê· )
            df['overall_score'] = (
                df['semantic_coherence'] * 0.4 +
                df['keyword_relevance'] * 0.3 +
                (1 / (df['avg_query_time'] + 0.001)) * 0.2 +  # ì†ë„ ì ìˆ˜
                df['cluster_quality'] * 0.1
            )
            
            # ì •ê·œí™” (0-1 ë²”ìœ„)
            df['overall_score'] = (df['overall_score'] - df['overall_score'].min()) / (
                df['overall_score'].max() - df['overall_score'].min()
            )
        
        return df.sort_values('overall_score', ascending=False) if not df.empty else df
    
    def _calculate_quality_metrics(self, model: BaseEmbeddingModel, 
                                 embeddings: np.ndarray, 
                                 texts: List[str]) -> Dict[str, float]:
        """ìž„ë² ë”© í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        metrics = {}
        
        try:
            # 1. ì˜ë¯¸ì  ì¼ê´€ì„± (ê°™ì€ ì£¼ì œ í…ìŠ¤íŠ¸ë“¤ì˜ ìœ ì‚¬ë„)
            similarity_matrix = cosine_similarity(embeddings)
            # ëŒ€ê°ì„  ì œì™¸í•œ í‰ê·  ìœ ì‚¬ë„
            upper_tri_indices = np.triu_indices_from(similarity_matrix, k=1)
            avg_similarity = np.mean(similarity_matrix[upper_tri_indices])
            metrics['semantic_coherence'] = round(avg_similarity, 3)
            
            # 2. í‚¤ì›Œë“œ ê´€ë ¨ì„± (ë³µì§€ í‚¤ì›Œë“œê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ë“¤ì˜ ìœ ì‚¬ë„)
            keyword_similarities = []
            for i, text1 in enumerate(texts):
                for j, text2 in enumerate(texts[i+1:], i+1):
                    # ë‘˜ ë‹¤ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°
                    if (any(kw in text1 for kw in self.welfare_keywords) and 
                        any(kw in text2 for kw in self.welfare_keywords)):
                        keyword_similarities.append(similarity_matrix[i, j])
            
            metrics['keyword_relevance'] = round(
                np.mean(keyword_similarities) if keyword_similarities else 0, 3
            )
            
            # 3. í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ (ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´)
            if len(embeddings) >= 3:
                try:
                    n_clusters = min(3, len(embeddings) - 1)
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                    cluster_labels = kmeans.fit_predict(embeddings)
                    
                    from sklearn.metrics import silhouette_score
                    silhouette = silhouette_score(embeddings, cluster_labels)
                    metrics['cluster_quality'] = round(silhouette, 3)
                except:
                    metrics['cluster_quality'] = 0.0
            else:
                metrics['cluster_quality'] = 0.0
            
            # 4. ì°¨ì› ë‹¤ì–‘ì„± (PCA ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨)
            if embeddings.shape[1] > 1:
                pca = PCA(n_components=min(5, embeddings.shape[1]))
                pca.fit(embeddings)
                explained_variance_ratio = np.sum(pca.explained_variance_ratio_[:3])
                metrics['dimension_diversity'] = round(explained_variance_ratio, 3)
            else:
                metrics['dimension_diversity'] = 0.0
            
        except Exception as e:
            logger.warning(f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            metrics = {
                'semantic_coherence': 0.0,
                'keyword_relevance': 0.0,
                'cluster_quality': 0.0,
                'dimension_diversity': 0.0
            }
        
        return metrics
    
    def compare_retrieval_performance(self, documents: List[str], 
                                    queries: List[str]) -> pd.DataFrame:
        """ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ"""
        if not self.models:
            logger.error("ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        results = []
        
        for model_alias, model in self.models.items():
            logger.info(f"ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: {model_alias}")
            
            try:
                # ë¬¸ì„œ ìž„ë² ë”© ìƒì„±
                doc_embeddings = model.embed_texts(documents)
                
                # ê° ì¿¼ë¦¬ì— ëŒ€í•œ ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
                precision_scores = []
                recall_scores = []
                
                for query in queries:
                    query_embedding = model.embed_query(query)
                    
                    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                    similarities = cosine_similarity(
                        query_embedding.reshape(1, -1), 
                        doc_embeddings
                    )[0]
                    
                    # ìƒìœ„ 3ê°œ ë¬¸ì„œ ì„ íƒ
                    top_3_indices = np.argsort(similarities)[-3:][::-1]
                    top_3_scores = similarities[top_3_indices]
                    
                    # ê´€ë ¨ì„± íŒë‹¨ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
                    relevant_docs = []
                    query_keywords = [kw for kw in self.welfare_keywords if kw in query]
                    
                    for idx in top_3_indices:
                        doc = documents[idx]
                        if any(kw in doc for kw in query_keywords):
                            relevant_docs.append(idx)
                    
                    # Precision@3 ê³„ì‚°
                    precision = len(relevant_docs) / 3
                    precision_scores.append(precision)
                
                avg_precision = np.mean(precision_scores)
                
                result = {
                    'model': model_alias,
                    'avg_precision_at_3': round(avg_precision, 3),
                    'avg_similarity_score': round(np.mean([
                        np.max(cosine_similarity(
                            model.embed_query(q).reshape(1, -1), 
                            doc_embeddings
                        )) for q in queries
                    ]), 3)
                }
                
                results.append(result)
                
            except Exception as e:
                logger.error(f"{model_alias} ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                continue
        
        return pd.DataFrame(results)
    
    def get_model_recommendation(self, 
                               custom_texts: List[str] = None,
                               priority: str = "balanced") -> Dict[str, Any]:
        """
        ëª¨ë¸ ì¶”ì²œ
        
        Args:
            custom_texts: ì»¤ìŠ¤í…€ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
            priority: "speed", "quality", "balanced"
        """
        benchmark_df = self.benchmark_models(custom_texts)
        
        if benchmark_df.empty:
            return {
                'recommended_model': None,
                'reason': 'ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ',
                'benchmark_results': benchmark_df
            }
        
        if priority == "speed":
            # ì†ë„ ìš°ì„ 
            best_model = benchmark_df.loc[benchmark_df['texts_per_second'].idxmax()]
            reason = f"ê°€ìž¥ ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ ({best_model['texts_per_second']:.1f} texts/sec)"
        
        elif priority == "quality":
            # í’ˆì§ˆ ìš°ì„ 
            quality_score = (
                benchmark_df['semantic_coherence'] * 0.4 +
                benchmark_df['keyword_relevance'] * 0.6
            )
            best_idx = quality_score.idxmax()
            best_model = benchmark_df.loc[best_idx]
            reason = f"ìµœê³  í’ˆì§ˆ ì ìˆ˜ (ì˜ë¯¸ ì¼ê´€ì„±: {best_model['semantic_coherence']:.3f})"
        
        else:
            # ê· í˜• (ê¸°ë³¸)
            best_model = benchmark_df.iloc[0]  # overall_scoreë¡œ ì •ë ¬ë˜ì–´ ìžˆìŒ
            reason = f"ìµœê³  ì¢…í•© ì ìˆ˜ ({best_model['overall_score']:.3f})"
        
        return {
            'recommended_model': best_model['model'],
            'model_info': best_model.to_dict(),
            'reason': reason,
            'benchmark_results': benchmark_df
        }
    
    def visualize_model_comparison(self, benchmark_df: pd.DataFrame, 
                                 save_path: str = None) -> None:
        """ëª¨ë¸ ë¹„êµ ê²°ê³¼ ì‹œê°í™”"""
        if benchmark_df.empty:
            logger.warning("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ìž„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ', fontsize=16, fontweight='bold')
        
        # 1. ì¢…í•© ì ìˆ˜
        axes[0, 0].bar(benchmark_df['model'], benchmark_df['overall_score'])
        axes[0, 0].set_title('ì¢…í•© ì ìˆ˜')
        axes[0, 0].set_ylabel('ì ìˆ˜')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # 2. ì†ë„ ë¹„êµ
        axes[0, 1].bar(benchmark_df['model'], benchmark_df['texts_per_second'], 
                      color='orange')
        axes[0, 1].set_title('ì²˜ë¦¬ ì†ë„ (texts/second)')
        axes[0, 1].set_ylabel('ì†ë„')
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # 3. í’ˆì§ˆ ë©”íŠ¸ë¦­
        quality_metrics = ['semantic_coherence', 'keyword_relevance', 'cluster_quality']
        quality_data = benchmark_df[['model'] + quality_metrics].set_index('model')
        quality_data.plot(kind='bar', ax=axes[1, 0])
        axes[1, 0].set_title('í’ˆì§ˆ ë©”íŠ¸ë¦­')
        axes[1, 0].set_ylabel('ì ìˆ˜')
        axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # 4. ìž„ë² ë”© ì°¨ì› vs ì¿¼ë¦¬ ì‹œê°„
        scatter = axes[1, 1].scatter(benchmark_df['embedding_dim'], 
                                   benchmark_df['avg_query_time'],
                                   c=benchmark_df['overall_score'], 
                                   cmap='viridis', s=100, alpha=0.7)
        axes[1, 1].set_xlabel('ìž„ë² ë”© ì°¨ì›')
        axes[1, 1].set_ylabel('í‰ê·  ì¿¼ë¦¬ ì‹œê°„ (ì´ˆ)')
        axes[1, 1].set_title('ì°¨ì› vs ì†ë„ (ìƒ‰ìƒ: ì¢…í•©ì ìˆ˜)')
        
        # ê° ì ì— ëª¨ë¸ëª… í‘œì‹œ
        for i, model in enumerate(benchmark_df['model']):
            axes[1, 1].annotate(model, 
                               (benchmark_df.iloc[i]['embedding_dim'], 
                                benchmark_df.iloc[i]['avg_query_time']),
                               xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        plt.colorbar(scatter, ax=axes[1, 1])
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"ì°¨íŠ¸ ì €ìž¥: {save_path}")
        
        plt.show()


def main():
    """ìž„ë² ë”© ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    print("ðŸ§  ìž„ë² ë”© ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    comparator = EmbeddingModelComparator()
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ˆê¸°í™”
    print("\nðŸ“¥ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    model_status = comparator.initialize_available_models()
    
    for model, status in model_status.items():
        status_icon = "âœ…" if status else "âŒ"
        print(f"  {status_icon} {model}")
    
    if not any(model_status.values()):
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    print(f"\nðŸ”¬ ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹...")
    benchmark_df = comparator.benchmark_models()
    
    if not benchmark_df.empty:
        print(f"\nðŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
        print(benchmark_df.to_string(index=False))
        
        # ëª¨ë¸ ì¶”ì²œ
        print(f"\nðŸ† ëª¨ë¸ ì¶”ì²œ:")
        for priority in ["balanced", "speed", "quality"]:
            recommendation = comparator.get_model_recommendation(priority=priority)
            print(f"  {priority.title()}: {recommendation['recommended_model']} "
                  f"({recommendation['reason']})")
        
        # ì‹œê°í™” (ì„ íƒì )
        try:
            comparator.visualize_model_comparison(benchmark_df)
        except Exception as e:
            print(f"ì‹œê°í™” ê±´ë„ˆëœ€: {e}")
    
    else:
        print("âŒ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")


class EmbeddingModelManager:
    """ìž„ë² ë”© ëª¨ë¸ ê´€ë¦¬ í´ëž˜ìŠ¤ (í†µí•© ë¹„êµí‰ê°€ìš©)"""
    
    def __init__(self):
        """ìž„ë² ë”© ëª¨ë¸ ê´€ë¦¬ìž ì´ˆê¸°í™”"""
        self.comparator = EmbeddingModelComparator()
        self.models = {}
        logger.info("ìž„ë² ë”© ëª¨ë¸ ê´€ë¦¬ìž ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_embedding(self, text: str, model_name: str = "sentence-transformers") -> Optional[List[float]]:
        """
        ì§€ì •ëœ ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìž„ë² ë”© ìƒì„±
        
        Args:
            text: ìž„ë² ë”©í•  í…ìŠ¤íŠ¸
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
            
        Returns:
            Optional[List[float]]: ìž„ë² ë”© ë²¡í„° (ì‹¤íŒ¨ì‹œ None)
        """
        try:
            # ëª¨ë¸ ë§¤í•‘
            model_mapping = {
                'sentence-transformers': 'sentence_transformers',
                'openai': 'openai',
                'huggingface': 'huggingface'
            }
            
            actual_model = model_mapping.get(model_name, 'sentence_transformers')
            
            # ëª¨ë¸ì´ ì—†ë‹¤ë©´ ìƒì„± ë° ì´ˆê¸°í™” ì‹œë„
            if actual_model not in self.models:
                if actual_model == 'sentence_transformers' and SENTENCE_TRANSFORMERS_AVAILABLE:
                    model = SentenceTransformerModel()
                    if model.initialize():
                        self.models[actual_model] = model
                    else:
                        logger.warning(f"SentenceTransformer ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
                        return None
                elif actual_model == 'openai' and OPENAI_AVAILABLE:
                    model = OpenAIEmbeddingModel()
                    if model.initialize():
                        self.models[actual_model] = model
                    else:
                        logger.warning(f"OpenAI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
                        return None
                elif actual_model == 'huggingface' and TRANSFORMERS_AVAILABLE:
                    model = KoBERTEmbeddingModel()
                    if model.initialize():
                        self.models[actual_model] = model
                    else:
                        logger.warning(f"HuggingFace ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
                        return None
                else:
                    logger.warning(f"ëª¨ë¸ {actual_model}ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return None
            
            # ìž„ë² ë”© ìƒì„±
            model = self.models[actual_model]
            embeddings = model.embed_texts([text])
            
            if embeddings is not None and len(embeddings) > 0:
                return embeddings[0]
            else:
                return None
            
        except Exception as e:
            logger.error(f"ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨ ({model_name}): {e}")
            return None
    
    def get_available_models(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìž„ë² ë”© ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        available = []
        
        if SENTENCE_TRANSFORMERS_AVAILABLE:
            available.append('sentence-transformers')
        if OPENAI_AVAILABLE and os.getenv('OPENAI_API_KEY'):
            available.append('openai')
        if TRANSFORMERS_AVAILABLE:
            available.append('huggingface')
            
        return available
    
    def evaluate_model_performance(self, texts: List[str], model_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€
        
        Args:
            texts: í‰ê°€í•  í…ìŠ¤íŠ¸ ëª©ë¡
            model_name: í‰ê°€í•  ëª¨ë¸ ì´ë¦„
            
        Returns:
            Dict[str, Any]: ì„±ëŠ¥ í‰ê°€ ê²°ê³¼
        """
        try:
            start_time = time.time()
            
            # ìž„ë² ë”© ìƒì„±
            embeddings = []
            success_count = 0
            
            for text in texts:
                embedding = self.get_embedding(text, model_name)
                if embedding is not None:
                    embeddings.append(embedding)
                    success_count += 1
            
            processing_time = time.time() - start_time
            
            return {
                'model': model_name,
                'total_texts': len(texts),
                'successful_embeddings': success_count,
                'success_rate': success_count / len(texts) if texts else 0,
                'processing_time': processing_time,
                'avg_time_per_text': processing_time / len(texts) if texts else 0,
                'embedding_dimension': len(embeddings[0]) if embeddings is not None and len(embeddings) > 0 else 0,
                'success': success_count > 0
            }
            
        except Exception as e:
            return {
                'model': model_name,
                'total_texts': len(texts),
                'successful_embeddings': 0,
                'success_rate': 0,
                'processing_time': 0,
                'avg_time_per_text': 0,
                'embedding_dimension': 0,
                'success': False,
                'error': str(e)
            }


if __name__ == "__main__":
    main()