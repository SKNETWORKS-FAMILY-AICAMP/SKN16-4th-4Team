"""
RAG íŒŒì´í”„ë¼ì¸ ë¦¬ëª¨ì»¨ (RAG Remote Control)
============================================

ëª¨ë“  RAG êµ¬ì„±ìš”ì†Œë¥¼ ë¦¬ëª¨ì»¨ì²˜ëŸ¼ ê°„ë‹¨í•˜ê²Œ ì¡°ì‘í•  ìˆ˜ ìˆëŠ” í†µí•© ì œì–´ ì‹œìŠ¤í…œ
- ì›í´ë¦­ ë¹„êµí‰ê°€
- ëª¨ë“ˆë³„ ë…ë¦½ ì œì–´
- AutoRAG ìë™í™”
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional, Union, Callable
from dataclasses import dataclass, asdict
from abc import ABC, abstractmethod
from pathlib import Path
import time
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =========================================
# ì½”ì–´ ì¸í„°í˜ì´ìŠ¤ (Core Interfaces)
# =========================================

@dataclass
class RemoteResult:
    """ë¦¬ëª¨ì»¨ ì‹¤í–‰ ê²°ê³¼"""
    success: bool
    component: str
    action: str
    data: Any = None
    error: Optional[str] = None
    execution_time: float = 0.0
    timestamp: str = ""
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()

class ComponentRemote(ABC):
    """êµ¬ì„±ìš”ì†Œ ë¦¬ëª¨ì»¨ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str):
        self.name = name
        self.is_available = False
        self.status = "uninitialized"
        self._last_result = None
    
    @abstractmethod
    def initialize(self) -> RemoteResult:
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        pass
    
    @abstractmethod
    def compare(self, **kwargs) -> RemoteResult:
        """ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰"""
        pass
    
    @abstractmethod
    def benchmark(self, **kwargs) -> RemoteResult:
        """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        pass
    
    def get_status(self) -> Dict[str, Any]:
        """ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            'name': self.name,
            'available': self.is_available,
            'status': self.status,
            'last_result': self._last_result
        }
    
    def _execute_safely(self, func: Callable, action: str, **kwargs) -> RemoteResult:
        """ì•ˆì „í•œ ì‹¤í–‰ ë˜í¼"""
        start_time = time.time()
        try:
            result_data = func(**kwargs)
            execution_time = time.time() - start_time
            
            result = RemoteResult(
                success=True,
                component=self.name,
                action=action,
                data=result_data,
                execution_time=execution_time
            )
            self._last_result = result
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"{self.name} {action} ì‹¤íŒ¨: {e}")
            
            result = RemoteResult(
                success=False,
                component=self.name,
                action=action,
                error=str(e),
                execution_time=execution_time
            )
            self._last_result = result
            return result

# =========================================
# í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¦¬ëª¨ì»¨
# =========================================

class TextExtractionRemote(ComponentRemote):
    """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¦¬ëª¨ì»¨"""
    
    def __init__(self):
        super().__init__("text_extraction")
        self._extractor = None
    
    def initialize(self) -> RemoteResult:
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ ëª¨ë“ˆ ì´ˆê¸°í™”"""
        def _init():
            try:
                from src.text_extraction_comparison import TextExtractionComparison
                self._extractor = TextExtractionComparison()
                self.is_available = True
                self.status = "ready"
                
                return {
                    'pdf_extractors': len(self._extractor.available_pdf_extractors),
                    'hwp_extractors': len(self._extractor.available_hwp_extractors)
                }
            except ImportError as e:
                self.is_available = False
                self.status = "module_not_found"
                raise e
        
        return self._execute_safely(_init, "initialize")
    
    def compare(self, file_path: str = None, **kwargs) -> RemoteResult:
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ë¹„êµ - ì•ˆì •ì ì¸ ë²„ì „"""
        def _compare():
            if not self._extractor:
                raise RuntimeError("ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ì•ˆì •ì ì¸ simple_compare ì‚¬ìš©
            return self._extractor.simple_compare(file_path)
        
        return self._execute_safely(_compare, "compare", **kwargs)
    
    def benchmark(self, test_files: List[str] = None, **kwargs) -> RemoteResult:
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë²¤ì¹˜ë§ˆí¬"""
        def _benchmark():
            if not self._extractor:
                raise RuntimeError("ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìë™ ê²€ìƒ‰ ë˜ëŠ” ì œê³µëœ íŒŒì¼ ì‚¬ìš©
            final_test_files = test_files
            if not final_test_files:
                data_dir = Path("../data")
                found_files = []
                if data_dir.exists():
                    found_files.extend(list(data_dir.glob("**/*.pdf"))[:3])
                    found_files.extend(list(data_dir.glob("**/*.hwp"))[:2])
                final_test_files = [str(f) for f in found_files]
            
            benchmark_results = {}
            for file_path in final_test_files[:5]:  # ìµœëŒ€ 5ê°œ íŒŒì¼
                if Path(file_path).exists():
                    file_path_obj = Path(file_path)
                    file_ext = file_path_obj.suffix.lower()
                    
                    try:
                        # ê°„ë‹¨í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ìœ„í•´ ì§ì ‘ ì¶”ì¶œê¸°ë“¤ì„ í…ŒìŠ¤íŠ¸
                        file_results = {}
                        
                        if file_ext == '.pdf':
                            extractors = self._extractor.available_pdf_extractors
                        elif file_ext == '.hwp':
                            extractors = self._extractor.available_hwp_extractors
                        else:
                            continue  # ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ ê±´ë„ˆë›°ê¸°
                        
                        for extractor in extractors:
                            try:
                                result = extractor.extract_with_metrics(file_path)
                                if "metrics" in result:
                                    metrics = result["metrics"]
                                    file_results[extractor.name] = {
                                        "execution_time": metrics.get("extraction_time", 0),
                                        "text_length": metrics.get("text_length", 0),
                                        "success": metrics.get("success", False),
                                        "error": metrics.get("error", None) if not metrics.get("success", False) else None
                                    }
                                else:
                                    # í˜¸í™˜ì„± ì²˜ë¦¬
                                    file_results[extractor.name] = {
                                        "execution_time": result.get("extraction_time", 0),
                                        "text_length": result.get("text_length", 0),
                                        "success": result.get("success", False),
                                        "error": result.get("error", None)
                                    }
                            except Exception as e:
                                file_results[extractor.name] = {
                                    "execution_time": 0,
                                    "text_length": 0,
                                    "success": False,
                                    "error": str(e)
                                }
                        
                        benchmark_results[file_path] = file_results
                    except Exception as e:
                        benchmark_results[file_path] = {'error': str(e)}
            
            return {
                'tested_files': len(benchmark_results),
                'results': benchmark_results
            }
        
        return self._execute_safely(_benchmark, "benchmark", **kwargs)

# =========================================
# ì²­í‚¹ ì „ëµ ë¦¬ëª¨ì»¨
# =========================================

class ChunkingRemote(ComponentRemote):
    """ì²­í‚¹ ì „ëµ ë¦¬ëª¨ì»¨"""
    
    def __init__(self):
        super().__init__("chunking")
        self._manager = None
    
    def initialize(self) -> RemoteResult:
        """ì²­í‚¹ ì „ëµ ëª¨ë“ˆ ì´ˆê¸°í™”"""
        def _init():
            try:
                from src.chunk_strategy import ChunkStrategyManager
                self._manager = ChunkStrategyManager()
                self.is_available = True
                self.status = "ready"
                
                return {
                    'available_strategies': self._manager.get_available_strategies()
                }
            except ImportError as e:
                self.is_available = False
                self.status = "module_not_found"
                raise e
        
        return self._execute_safely(_init, "initialize")
    
    def compare(self, text: str = None, strategies: List[str] = None, **kwargs) -> RemoteResult:
        """ì²­í‚¹ ì „ëµ ë¹„êµ"""
        def _compare():
            if not self._manager:
                raise RuntimeError("ì²­í‚¹ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ê¸°ë³¸ í…ìŠ¤íŠ¸
            test_text = text or """
                ë…¸ì¸ë³µì§€ë²•ì— ë”°ë¥¸ 65ì„¸ ì´ìƒ ë…¸ì¸ì˜ ì˜ë£Œë¹„ ì§€ì› ì •ì±…ì…ë‹ˆë‹¤.
                ì €ì†Œë“ì¸µ ë…¸ì¸ì˜ ê²½ìš° ì˜ë£Œë¹„ì˜ 80%ë¥¼ êµ­ê°€ì—ì„œ ì§€ì›í•˜ë©°,
                ì¼ë°˜ ë…¸ì¸ì˜ ê²½ìš° 50%ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
                ì‹ ì²­ì€ ì£¼ë¯¼ì„¼í„°ì—ì„œ í•  ìˆ˜ ìˆìœ¼ë©°,
                í•„ìš” ì„œë¥˜ë¡œëŠ” ì£¼ë¯¼ë“±ë¡ë“±ë³¸, ì†Œë“ì¦ëª…ì„œ, ì˜ë£Œë¹„ ì˜ìˆ˜ì¦ì´ ìˆìŠµë‹ˆë‹¤.
                """
            
            # ê¸°ë³¸ ì „ëµ
            test_strategies = strategies or self._manager.get_available_strategies()
            
            results = {}
            for strategy in test_strategies:
                performance = self._manager.evaluate_strategy_performance(test_text, strategy)
                results[strategy] = performance
            
            return {'strategies_tested': len(results), 'results': results}
        
        return self._execute_safely(_compare, "compare", **kwargs)
    
    def benchmark(self, test_texts: List[str] = None, **kwargs) -> RemoteResult:
        """ì²­í‚¹ ì „ëµ ë²¤ì¹˜ë§ˆí¬"""
        def _benchmark():
            if not self._manager:
                raise RuntimeError("ì²­í‚¹ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
            final_test_texts = test_texts or [
                "ë…¸ì¸ë³µì§€ ì •ì±…ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì…ë‹ˆë‹¤. " * 20,
                "ì¥ì• ì¸ ì§€ì› ì„œë¹„ìŠ¤ ì•ˆë‚´ë¬¸ì…ë‹ˆë‹¤. " * 15,
                "ì €ì†Œë“ì¸µ ì£¼ê±° ì§€ì› ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. " * 25
            ]
            
            strategies = self._manager.get_available_strategies()
            benchmark_results = {}
            
            for i, text in enumerate(final_test_texts[:3]):  # ìµœëŒ€ 3ê°œ í…ìŠ¤íŠ¸
                text_results = {}
                for strategy in strategies:
                    performance = self._manager.evaluate_strategy_performance(text, strategy)
                    text_results[strategy] = performance
                benchmark_results[f'text_{i+1}'] = text_results
            
            return {
                'tested_texts': len(benchmark_results),
                'tested_strategies': len(strategies),
                'results': benchmark_results
            }
        
        return self._execute_safely(_benchmark, "benchmark", **kwargs)

# =========================================
# ğŸ”¢ ì„ë² ë”© ëª¨ë¸ ë¦¬ëª¨ì»¨
# =========================================

class EmbeddingRemote(ComponentRemote):
    """ì„ë² ë”© ëª¨ë¸ ë¦¬ëª¨ì»¨"""
    
    def __init__(self):
        super().__init__("embedding")
        self._manager = None
    
    def initialize(self) -> RemoteResult:
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        def _init():
            try:
                from src.embedding_models import EmbeddingModelManager
                self._manager = EmbeddingModelManager()
                self.is_available = True
                self.status = "ready"
                
                return {
                    'available_models': self._manager.get_available_models()
                }
            except ImportError as e:
                self.is_available = False
                self.status = "module_not_found"
                raise e
        
        return self._execute_safely(_init, "initialize")
    
    def compare(self, texts: List[str] = None, models: List[str] = None, **kwargs) -> RemoteResult:
        """ì„ë² ë”© ëª¨ë¸ ë¹„êµ"""
        def _compare():
            if not self._manager:
                raise RuntimeError("ì„ë² ë”© ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ê¸°ë³¸ í…ìŠ¤íŠ¸
            test_texts = texts or [
                "65ì„¸ ì´ìƒ ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì›",
                "ì¥ì• ì¸ ë³µì§€ ì„œë¹„ìŠ¤",
                "ì €ì†Œë“ì¸µ ì£¼ê±° ì§€ì›"
            ]
            
            # ê¸°ë³¸ ëª¨ë¸
            test_models = models or self._manager.get_available_models()
            
            results = {}
            for model in test_models:
                performance = self._manager.evaluate_model_performance(test_texts, model)
                results[model] = performance
            
            return {'models_tested': len(results), 'results': results}
        
        return self._execute_safely(_compare, "compare", **kwargs)
    
    def benchmark(self, test_datasets: List[List[str]] = None, **kwargs) -> RemoteResult:
        """ì„ë² ë”© ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬"""
        def _benchmark():
            if not self._manager:
                raise RuntimeError("ì„ë² ë”© ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
            final_test_datasets = test_datasets or [
                ["ë…¸ì¸ë³µì§€ ì •ì±…", "ì˜ë£Œë¹„ ì§€ì›", "ê±´ê°•ë³´í—˜"],
                ["ì¥ì• ì¸ ì„œë¹„ìŠ¤", "ë³µì§€ í˜œíƒ", "ì§€ì› í”„ë¡œê·¸ë¨"],
                ["ì£¼ê±° ì§€ì›", "ì„ëŒ€ë£Œ ë³´ì¡°", "ì£¼íƒ ì •ì±…"]
            ]
            
            models = self._manager.get_available_models()
            benchmark_results = {}
            
            for i, dataset in enumerate(final_test_datasets[:3]):  # ìµœëŒ€ 3ê°œ ë°ì´í„°ì…‹
                dataset_results = {}
                for model in models:
                    performance = self._manager.evaluate_model_performance(dataset, model)
                    dataset_results[model] = performance
                benchmark_results[f'dataset_{i+1}'] = dataset_results
            
            return {
                'tested_datasets': len(benchmark_results),
                'tested_models': len(models),
                'results': benchmark_results
            }
        
        return self._execute_safely(_benchmark, "benchmark", **kwargs)

# =========================================
# ê²€ìƒ‰ ì „ëµ ë¦¬ëª¨ì»¨
# =========================================

class RetrievalRemote(ComponentRemote):
    """ê²€ìƒ‰ ì „ëµ ë¦¬ëª¨ì»¨"""
    
    def __init__(self):
        super().__init__("retrieval")
        self._manager = None
    
    def initialize(self) -> RemoteResult:
        """ê²€ìƒ‰ ì „ëµ ì´ˆê¸°í™”"""
        def _init():
            try:
                from src.retrieval_strategies import RetrievalStrategyManager
                self._manager = RetrievalStrategyManager()
                self.is_available = True
                self.status = "ready"
                
                return {
                    'available_strategies': self._manager.get_available_strategies()
                }
            except ImportError as e:
                self.is_available = False
                self.status = "module_not_found"
                raise e
        
        return self._execute_safely(_init, "initialize")
    
    def compare(self, query: str = None, documents: List[Dict] = None, strategies: List[str] = None, **kwargs) -> RemoteResult:
        """ê²€ìƒ‰ ì „ëµ ë¹„êµ"""
        def _compare():
            if not self._manager:
                raise RuntimeError("ê²€ìƒ‰ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ê¸°ë³¸ ì¿¼ë¦¬
            test_query = query or "ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì›ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
            
            # ê¸°ë³¸ ë¬¸ì„œ
            test_documents = documents or [
                {'id': 1, 'content': 'ë…¸ì¸ë³µì§€ë²•ì— ë”°ë¥¸ ì˜ë£Œë¹„ ì§€ì›', 'source': 'doc1'},
                {'id': 2, 'content': 'ì¥ì• ì¸ ë³µì§€ ì„œë¹„ìŠ¤ ì‹ ì²­ ë°©ë²•', 'source': 'doc2'},
                {'id': 3, 'content': 'ì €ì†Œë“ì¸µ ì£¼ê±° ì§€ì› ì •ì±…', 'source': 'doc3'},
                {'id': 4, 'content': 'ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì í˜œíƒ ì•ˆë‚´', 'source': 'doc4'},
                {'id': 5, 'content': 'ë…ê±°ë…¸ì¸ ëŒë´„ ì„œë¹„ìŠ¤', 'source': 'doc5'}
            ]
            
            # ê¸°ë³¸ ì „ëµ
            test_strategies = strategies or self._manager.get_available_strategies()
            
            results = {}
            for strategy in test_strategies:
                performance = self._manager.evaluate_strategy_performance(test_query, test_documents, strategy)
                results[strategy] = performance
            
            return {'strategies_tested': len(results), 'results': results}
        
        return self._execute_safely(_compare, "compare", **kwargs)
    
    def benchmark(self, test_queries: List[str] = None, **kwargs) -> RemoteResult:
        """ê²€ìƒ‰ ì „ëµ ë²¤ì¹˜ë§ˆí¬"""
        def _benchmark():
            if not self._manager:
                raise RuntimeError("ê²€ìƒ‰ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
            final_test_queries = test_queries or [
                "65ì„¸ ì´ìƒ ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì›",
                "ì¥ì• ì¸ ë³µì§€ ì„œë¹„ìŠ¤ ì‹ ì²­",
                "ì €ì†Œë“ì¸µ ì£¼ê±° ì§€ì› ë°©ë²•"
            ]
            
            # ë”ë¯¸ ë¬¸ì„œ ì…‹
            documents = [
                {'id': i, 'content': f'ë³µì§€ ì •ì±… ë¬¸ì„œ {i}', 'source': f'doc{i}'}
                for i in range(1, 11)
            ]
            
            strategies = self._manager.get_available_strategies()
            benchmark_results = {}
            
            for i, query in enumerate(final_test_queries[:3]):  # ìµœëŒ€ 3ê°œ ì¿¼ë¦¬
                query_results = {}
                for strategy in strategies:
                    performance = self._manager.evaluate_strategy_performance(query, documents, strategy)
                    query_results[strategy] = performance
                benchmark_results[f'query_{i+1}'] = query_results
            
            return {
                'tested_queries': len(benchmark_results),
                'tested_strategies': len(strategies),
                'results': benchmark_results
            }
        
        return self._execute_safely(_benchmark, "benchmark", **kwargs)

# =========================================
# ë§ˆìŠ¤í„° ë¦¬ëª¨ì»¨ (Master Remote Control)
# =========================================

class RAGMasterRemote:
    """RAG íŒŒì´í”„ë¼ì¸ ë§ˆìŠ¤í„° ë¦¬ëª¨ì»¨"""
    
    def __init__(self):
        self.remotes = {
            'text_extraction': TextExtractionRemote(),
            'chunking': ChunkingRemote(),
            'embedding': EmbeddingRemote(),
            'retrieval': RetrievalRemote()
        }
        self.results_history = []
        self.config = self._load_config()
        logger.info("RAG ë§ˆìŠ¤í„° ë¦¬ëª¨ì»¨ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_config(self) -> Dict:
        """ì„¤ì • ë¡œë“œ"""
        config_path = Path("config/remote_config.json")
        
        default_config = {
            "auto_initialize": True,
            "parallel_execution": False,
            "result_storage": True,
            "benchmark_settings": {
                "max_files": 5,
                "max_texts": 3,
                "timeout": 30
            }
        }
        
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    loaded_config = json.load(f)
                    default_config.update(loaded_config)
            except Exception as e:
                logger.warning(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return default_config
    
    def initialize_all(self) -> Dict[str, RemoteResult]:
        """ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        logger.info("ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œì‘")
        results = {}
        
        for name, remote in self.remotes.items():
            logger.info(f"   ì´ˆê¸°í™” ì¤‘: {name}")
            result = remote.initialize()
            results[name] = result
            
            if result.success:
                logger.info(f"   {name} ì´ˆê¸°í™” ì„±ê³µ")
            else:
                logger.warning(f"   {name} ì´ˆê¸°í™” ì‹¤íŒ¨: {result.error}")
        
        self.results_history.append({
            'action': 'initialize_all',
            'timestamp': datetime.now().isoformat(),
            'results': results
        })
        
        return results
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        status = {
            'master_remote': {
                'total_components': len(self.remotes),
                'available_components': sum(1 for r in self.remotes.values() if r.is_available),
                'history_count': len(self.results_history)
            },
            'components': {}
        }
        
        for name, remote in self.remotes.items():
            status['components'][name] = remote.get_status()
        
        return status
    
    def run_quick_comparison(self) -> Dict[str, RemoteResult]:
        """ë¹ ë¥¸ ë¹„êµ ì‹¤í–‰ (ëª¨ë“  ì»´í¬ë„ŒíŠ¸)"""
        logger.info("ë¹ ë¥¸ ë¹„êµ ì‹¤í–‰")
        results = {}
        
        for name, remote in self.remotes.items():
            if remote.is_available:
                logger.info(f"   ì‹¤í–‰ ì¤‘: {name} ë¹„êµ")
                result = remote.compare()
                results[name] = result
                
                if result.success:
                    logger.info(f"   {name} ë¹„êµ ì™„ë£Œ")
                else:
                    logger.warning(f"   {name} ë¹„êµ ì‹¤íŒ¨: {result.error}")
            else:
                logger.warning(f"   {name} ì‚¬ìš© ë¶ˆê°€")
        
        self.results_history.append({
            'action': 'quick_comparison',
            'timestamp': datetime.now().isoformat(),
            'results': results
        })
        
        return results
    
    def run_full_benchmark(self) -> Dict[str, RemoteResult]:
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        logger.info("ğŸ† ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰")
        results = {}
        
        for name, remote in self.remotes.items():
            if remote.is_available:
                logger.info(f"   ë²¤ì¹˜ë§ˆí¬ ì¤‘: {name}")
                result = remote.benchmark()
                results[name] = result
                
                if result.success:
                    logger.info(f"   {name} ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
                else:
                    logger.warning(f"   {name} ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {result.error}")
            else:
                logger.warning(f"   {name} ì‚¬ìš© ë¶ˆê°€")
        
        self.results_history.append({
            'action': 'full_benchmark',
            'timestamp': datetime.now().isoformat(),
            'results': results
        })
        
        return results
    
    def auto_rag_optimization(self) -> Dict[str, Any]:
        """AutoRAG ìŠ¤íƒ€ì¼ ìë™ ìµœì í™”"""
        logger.info("ğŸ¤– AutoRAG ìë™ ìµœì í™” ì‹œì‘")
        
        # 1ë‹¨ê³„: ì´ˆê¸°í™”
        init_results = self.initialize_all()
        
        # 2ë‹¨ê³„: ë¹ ë¥¸ ë¹„êµ
        comparison_results = self.run_quick_comparison()
        
        # 3ë‹¨ê³„: ë²¤ì¹˜ë§ˆí¬
        benchmark_results = self.run_full_benchmark()
        
        # 4ë‹¨ê³„: ìµœì  êµ¬ì„± ê²°ì •
        best_config = self._determine_best_configuration(comparison_results, benchmark_results)
        
        optimization_result = {
            'optimization_complete': True,
            'initialization': init_results,
            'comparison': comparison_results,
            'benchmark': benchmark_results,
            'best_configuration': best_config,
            'timestamp': datetime.now().isoformat()
        }
        
        self.results_history.append({
            'action': 'auto_rag_optimization',
            'timestamp': datetime.now().isoformat(),
            'results': optimization_result
        })
        
        logger.info("AutoRAG ìµœì í™” ì™„ë£Œ")
        return optimization_result
    
    def _determine_best_configuration(self, comparison_results: Dict, benchmark_results: Dict) -> Dict[str, str]:
        """ìµœì  êµ¬ì„± ê²°ì •"""
        best_config = {}
        
        for component, result in comparison_results.items():
            if result.success and result.data:
                # ê° ì»´í¬ë„ŒíŠ¸ë³„ ìµœê³  ì„±ëŠ¥ ë°©ë²• ì„ íƒ
                if component == 'text_extraction':
                    # PDF ì¶”ì¶œê¸° ê°œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì„ íƒ
                    best_config['text_extractor'] = 'multi_extractor'
                elif component == 'chunking':
                    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì „ëµ ì„ íƒ
                    strategies = result.data.get('results', {})
                    best_strategy = max(strategies.keys(), 
                                      key=lambda k: strategies[k].get('success', False))
                    best_config['chunking_strategy'] = best_strategy
                elif component == 'embedding':
                    # ê°€ì¥ ë†’ì€ ì„±ê³µë¥ ì˜ ëª¨ë¸ ì„ íƒ
                    models = result.data.get('results', {})
                    best_model = max(models.keys(),
                                   key=lambda k: models[k].get('success_rate', 0))
                    best_config['embedding_model'] = best_model
                elif component == 'retrieval':
                    # ê°€ì¥ ë†’ì€ í‰ê·  ì ìˆ˜ì˜ ì „ëµ ì„ íƒ
                    strategies = result.data.get('results', {})
                    best_strategy = max(strategies.keys(),
                                      key=lambda k: strategies[k].get('avg_score', 0))
                    best_config['retrieval_strategy'] = best_strategy
        
        return best_config
    
    def save_results(self, file_path: str = None) -> str:
        """ê²°ê³¼ ì €ì¥"""
        if not file_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_path = f"results/rag_remote_results_{timestamp}.json"
        
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        save_data = {
            'system_status': self.get_system_status(),
            'results_history': self.results_history,
            'config': self.config
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {file_path}")
        return file_path

# =========================================
# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
# =========================================

def main():
    """ë¦¬ëª¨ì»¨ ì‹œìŠ¤í…œ ë°ëª¨"""
    print("RAG íŒŒì´í”„ë¼ì¸ ë§ˆìŠ¤í„° ë¦¬ëª¨ì»¨ ë°ëª¨")
    print("=" * 50)
    
    # ë§ˆìŠ¤í„° ë¦¬ëª¨ì»¨ ìƒì„±
    master = RAGMasterRemote()
    
    try:
        # 1. ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("\nì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        init_results = master.initialize_all()
        
        # 2. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        print("\nì‹œìŠ¤í…œ ìƒíƒœ:")
        status = master.get_system_status()
        available = status['master_remote']['available_components']
        total = status['master_remote']['total_components']
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸: {available}/{total}")
        
        # 3. ë¹ ë¥¸ ë¹„êµ ì‹¤í–‰
        print(f"\nâš¡ ë¹ ë¥¸ ë¹„êµ ì‹¤í–‰...")
        comparison_results = master.run_quick_comparison()
        
        # 4. AutoRAG ìµœì í™” (ì„ íƒì )
        print(f"\nğŸ¤– AutoRAG ìµœì í™” ì‹¤í–‰...")
        optimization_results = master.auto_rag_optimization()
        
        # 5. ê²°ê³¼ ì €ì¥
        result_file = master.save_results()
        print(f"\nê²°ê³¼ ì €ì¥: {result_file}")
        
        print(f"\në¦¬ëª¨ì»¨ ë°ëª¨ ì™„ë£Œ!")
        
    except KeyboardInterrupt:
        print(f"\nì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()