# =========================================
# âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì • íŒŒì¼
# =========================================

import os
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field

# í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •
def get_env_or_default(key: str, default: Any = None) -> str:
    """í™˜ê²½ ë³€ìˆ˜ ê°’ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ í¬í•¨)"""
    return os.getenv(key, default)


@dataclass
class EmbeddingConfig:
    """ì„ë² ë”© ëª¨ë¸ ì„¤ì •"""
    
    # OpenAI ì„¤ì •
    openai_api_key: str = field(default_factory=lambda: get_env_or_default("OPENAI_API_KEY", ""))
    openai_model: str = "text-embedding-ada-002"
    openai_timeout: int = 30
    
    # SentenceTransformer ì„¤ì •
    sentence_transformer_models: List[str] = field(default_factory=lambda: [
        "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        "jhgan/ko-sroberta-multitask",
        "snunlp/KR-SBERT-V40K-klueNLI-augSTS"
    ])
    
    # KoBERT ì„¤ì •
    kobert_model: str = "skt/kobert-base-v1"
    
    # ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸
    default_model: str = "sentence_transformer"
    
    # ì°¨ì› ì„¤ì •
    embedding_dimensions: Dict[str, int] = field(default_factory=lambda: {
        "openai": 1536,
        "sentence_transformer": 384,
        "kobert": 768
    })


@dataclass
class VectorStoreConfig:
    """ë²¡í„° ì €ì¥ì†Œ ì„¤ì •"""
    
    # ChromaDB ì„¤ì •
    persist_directory: str = "./data/chroma_db"
    collection_name: str = "elderly_welfare_policies"
    
    # ê²€ìƒ‰ ì„¤ì •
    similarity_top_k: int = 5
    similarity_threshold: float = 0.7
    
    # ë©”íƒ€ë°ì´í„° í•„í„°
    enable_metadata_filter: bool = True
    default_filters: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ChunkingConfig:
    """ë¬¸ì„œ ì²­í‚¹ ì„¤ì •"""
    
    # ê¸°ë³¸ ì²­í‚¹ ì„¤ì •
    default_strategy: str = "recursive"
    chunk_size: int = 1000
    chunk_overlap: int = 200
    
    # ì „ëµë³„ ì„¤ì •
    recursive_separators: List[str] = field(default_factory=lambda: ["\n\n", "\n", ". ", " ", ""])
    
    # ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹
    semantic_threshold: float = 0.75
    semantic_min_chunk_size: int = 300
    
    # ë¬¸ë‹¨ ê¸°ë°˜ ì²­í‚¹
    paragraph_min_length: int = 100


@dataclass
class RetrieverConfig:
    """ê²€ìƒ‰ê¸° ì„¤ì •"""
    
    # í‚¤ì›Œë“œ ê²€ìƒ‰
    keyword_analyzer: str = "korean"
    keyword_top_k: int = 5
    
    # ì˜ë¯¸ ê²€ìƒ‰
    semantic_top_k: int = 5
    semantic_score_threshold: float = 0.7
    
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    hybrid_alpha: float = 0.5  # í‚¤ì›Œë“œ:ì˜ë¯¸ ë¹„ìœ¨
    hybrid_top_k: int = 10
    
    # ì¬ìˆœìœ„í™”
    enable_reranking: bool = True
    rerank_top_k: int = 3


@dataclass
class RAGConfig:
    """RAG ì‹œìŠ¤í…œ ì„¤ì •"""
    
    # ì–¸ì–´ ëª¨ë¸ ì„¤ì •
    llm_provider: str = "openai"  # "openai", "huggingface", "local"
    llm_model: str = "gpt-3.5-turbo"
    llm_temperature: float = 0.1
    llm_max_tokens: int = 1000
    
    # ëŒ€í™” ë©”ëª¨ë¦¬
    memory_type: str = "buffer_window"  # "buffer", "buffer_window", "summary"
    memory_k: int = 10
    
    # ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
    max_context_length: int = 4000
    context_overlap: int = 200
    
    # ë‹µë³€ í’ˆì§ˆ ì œì–´
    min_confidence_threshold: float = 0.6
    enable_source_citation: bool = True
    max_sources: int = 5


@dataclass
class WorkflowConfig:
    """LangGraph ì›Œí¬í”Œë¡œìš° ì„¤ì •"""
    
    # ì˜ë„ ë¶„ë¥˜
    enable_intent_classification: bool = True
    intent_confidence_threshold: float = 0.8
    
    # ê´€ë ¨ì„± í‰ê°€
    enable_relevance_evaluation: bool = True
    relevance_threshold: float = 0.7
    
    # í›„ì† ì§ˆë¬¸ ìƒì„±
    enable_followup_generation: bool = True
    max_followup_questions: int = 3
    
    # ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ë³„ ì„¤ì •
    max_retries: int = 2
    timeout_seconds: int = 30


@dataclass
class InterfaceConfig:
    """ì¸í„°í˜ì´ìŠ¤ ì„¤ì •"""
    
    # Gradio ì„¤ì •
    gradio_server_name: str = "0.0.0.0"
    gradio_server_port: int = 7860
    gradio_share: bool = False
    gradio_debug: bool = False
    
    # Streamlit ì„¤ì •
    streamlit_port: int = 8501
    
    # ëŒ€í™” ì„¤ì •
    max_conversation_history: int = 20
    enable_conversation_export: bool = True
    
    # í”¼ë“œë°± ì„¤ì •
    enable_user_feedback: bool = True
    feedback_scale: tuple = (1, 5)


@dataclass
class DataConfig:
    """ë°ì´í„° ì„¤ì •"""
    
    # ë¬¸ì„œ ê²½ë¡œ
    data_directory: str = "./data/ë³µì§€ë¡œ"
    supported_formats: List[str] = field(default_factory=lambda: [".pdf", ".hwp", ".txt"])
    
    # ì „ì²˜ë¦¬ ì„¤ì •
    enable_preprocessing: bool = True
    remove_special_chars: bool = True
    normalize_spacing: bool = True
    
    # ìºì‹œ ì„¤ì •
    enable_document_cache: bool = True
    cache_directory: str = "./cache"
    cache_ttl_hours: int = 24


@dataclass
class EvaluationConfig:
    """í‰ê°€ ì„¤ì •"""
    
    # ìë™ í‰ê°€
    enable_auto_evaluation: bool = True
    evaluation_metrics: List[str] = field(default_factory=lambda: [
        "relevance", "faithfulness", "answer_correctness", "context_precision"
    ])
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    enable_performance_monitoring: bool = True
    log_response_times: bool = True
    
    # ì‚¬ìš©ì ë§Œì¡±ë„
    target_satisfaction_score: float = 4.0
    min_feedback_count: int = 10


@dataclass
class LoggingConfig:
    """ë¡œê¹… ì„¤ì •"""
    
    # ë¡œê·¸ ë ˆë²¨
    log_level: str = "INFO"
    
    # ë¡œê·¸ íŒŒì¼
    log_directory: str = "./logs"
    log_file_name: str = "elderly_rag_chatbot.log"
    max_log_file_size: int = 10_000_000  # 10MB
    backup_count: int = 5
    
    # ë¡œê·¸ í¬ë§·
    log_format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    date_format: str = "%Y-%m-%d %H:%M:%S"
    
    # íŠ¹ë³„ ë¡œê¹…
    log_user_interactions: bool = True
    log_system_errors: bool = True
    log_performance_metrics: bool = True


class SystemSettings:
    """ì „ì²´ ì‹œìŠ¤í…œ ì„¤ì • ê´€ë¦¬"""
    
    def __init__(self):
        """ì„¤ì • ì´ˆê¸°í™”"""
        
        # ê° ëª¨ë“ˆë³„ ì„¤ì •
        self.embedding = EmbeddingConfig()
        self.vector_store = VectorStoreConfig()
        self.chunking = ChunkingConfig()
        self.retriever = RetrieverConfig()
        self.rag = RAGConfig()
        self.workflow = WorkflowConfig()
        self.interface = InterfaceConfig()
        self.data = DataConfig()
        self.evaluation = EvaluationConfig()
        self.logging = LoggingConfig()
        
        # í™˜ê²½ë³„ ì„¤ì • ì ìš©
        self._apply_environment_settings()
    
    def _apply_environment_settings(self):
        """í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì • ì ìš©"""
        
        # ê°œë°œ/ìš´ì˜ í™˜ê²½ êµ¬ë¶„
        env = get_env_or_default("ELDERLY_RAG_ENV", "development")
        
        if env == "production":
            # ìš´ì˜ í™˜ê²½ ì„¤ì •
            self.rag.llm_temperature = 0.0
            self.interface.gradio_debug = False
            self.logging.log_level = "WARNING"
            
        elif env == "development":
            # ê°œë°œ í™˜ê²½ ì„¤ì •
            self.interface.gradio_debug = True
            self.logging.log_level = "DEBUG"
            
        # API í‚¤ ì„¤ì •
        if self.embedding.openai_api_key:
            self.rag.llm_provider = "openai"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self._ensure_directories()
    
    def _ensure_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        
        directories = [
            self.vector_store.persist_directory,
            self.data.cache_directory,
            self.logging.log_directory
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    def get_config_dict(self) -> Dict[str, Any]:
        """ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
        
        return {
            "embedding": self.embedding.__dict__,
            "vector_store": self.vector_store.__dict__,
            "chunking": self.chunking.__dict__,
            "retriever": self.retriever.__dict__,
            "rag": self.rag.__dict__,
            "workflow": self.workflow.__dict__,
            "interface": self.interface.__dict__,
            "data": self.data.__dict__,
            "evaluation": self.evaluation.__dict__,
            "logging": self.logging.__dict__
        }
    
    def update_config(self, config_dict: Dict[str, Any]):
        """ì„¤ì • ì—…ë°ì´íŠ¸"""
        
        for section, settings in config_dict.items():
            if hasattr(self, section):
                config_obj = getattr(self, section)
                for key, value in settings.items():
                    if hasattr(config_obj, key):
                        setattr(config_obj, key, value)
    
    def save_config(self, file_path: str = "config/settings.json"):
        """ì„¤ì •ì„ íŒŒì¼ë¡œ ì €ì¥"""
        
        import json
        
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(self.get_config_dict(), f, ensure_ascii=False, indent=2)
    
    def load_config(self, file_path: str = "config/settings.json"):
        """íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
        
        import json
        
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                config_dict = json.load(f)
                self.update_config(config_dict)


# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
settings = SystemSettings()


# í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿ (ì˜ˆì‹œ)
ENV_TEMPLATE = """
# =========================================
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜ˆì‹œ (.env íŒŒì¼)
# =========================================

# ì‹¤í–‰ í™˜ê²½
ELDERLY_RAG_ENV=development

# OpenAI API í‚¤
OPENAI_API_KEY=your_openai_api_key_here

# ë°ì´í„° ë””ë ‰í† ë¦¬
DATA_DIRECTORY=./data/ë³µì§€ë¡œ

# ë¡œê·¸ ë ˆë²¨
LOG_LEVEL=INFO

# ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
GRADIO_PORT=7860
STREAMLIT_PORT=8501

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
CHROMA_PERSIST_DIR=./data/chroma_db
"""


def main():
    """ì„¤ì • íŒŒì¼ í…ŒìŠ¤íŠ¸"""
    
    print("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì • í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    config = SystemSettings()
    
    # ì„¤ì • ì¶œë ¥
    print("ì„ë² ë”© ì„¤ì •:")
    print(f"  ê¸°ë³¸ ëª¨ë¸: {config.embedding.default_model}")
    print(f"  OpenAI ëª¨ë¸: {config.embedding.openai_model}")
    
    print(f"\nRAG ì„¤ì •:")
    print(f"  LLM ëª¨ë¸: {config.rag.llm_model}")
    print(f"  ì˜¨ë„: {config.rag.llm_temperature}")
    print(f"  ìµœëŒ€ í† í°: {config.rag.llm_max_tokens}")
    
    print(f"\nì¸í„°í˜ì´ìŠ¤ ì„¤ì •:")
    print(f"  Gradio í¬íŠ¸: {config.interface.gradio_server_port}")
    print(f"  ëŒ€í™” ê¸°ë¡ ìµœëŒ€ ìˆ˜: {config.interface.max_conversation_history}")
    
    # ì„¤ì • ì €ì¥ í…ŒìŠ¤íŠ¸
    try:
        config.save_config("config/test_settings.json")
        print(f"\nâœ… ì„¤ì • íŒŒì¼ ì €ì¥ ì„±ê³µ")
    except Exception as e:
        print(f"\nâŒ ì„¤ì • íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    # í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿ ì¶œë ¥
    print(f"\nğŸ“„ í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿:")
    print(ENV_TEMPLATE)


if __name__ == "__main__":
    main()