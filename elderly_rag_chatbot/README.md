# ğŸ¥ ë…¸ì¸ë³µì§€ ì •ì±… RAG ì±—ë´‡ ì‹œìŠ¤í…œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

ë…¸ì¸ë³µì§€ ê´€ë ¨ ì •ì±… ë¬¸ì„œë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” **Retrieval-Augmented Generation (RAG)** ê¸°ë°˜ ì±—ë´‡ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

- **ğŸ“„ ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹ ì§€ì›**: PDF, HWP, TXT íŒŒì¼ ì²˜ë¦¬
- **ğŸ”§ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ë¹„êµ**: PyPDF2, pdfplumber, PyMuPDF, pdfminer ë“± ë‹¤ì–‘í•œ ì¶”ì¶œê¸° ì„±ëŠ¥ ë¹„êµ
- **âœ‚ï¸ ì§€ëŠ¥í˜• ë¬¸ì„œ ì²­í‚¹**: ì—¬ëŸ¬ ì²­í‚¹ ì „ëµ ë¹„êµ ë° ìµœì í™”
- **ğŸ”¢ ì„ë² ë”© ëª¨ë¸ ìµœì í™”**: OpenAI, SentenceTransformer, KoBERT ëª¨ë¸ ë¹„êµ
- **ğŸ—„ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**: ChromaDB ê¸°ë°˜ íš¨ìœ¨ì  ë¬¸ì„œ ê²€ìƒ‰
- **ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: í‚¤ì›Œë“œ, ì˜ë¯¸, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°©ì‹
- **ğŸ¤– ê³ ê¸‰ RAG ì‹œìŠ¤í…œ**: LangChain ê¸°ë°˜ ëŒ€í™”í˜• AI
- **ğŸ”„ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬**: LangGraphë¥¼ í™œìš©í•œ ë³µì¡í•œ ì¿¼ë¦¬ ì²˜ë¦¬
- **ğŸ’¬ ì‚¬ìš©ì ì¹œí™”ì  ì¸í„°í˜ì´ìŠ¤**: Gradio/Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤
- **ğŸ¯ AutoRAG ìë™ ìµœì í™”**: ì „ì²´ íŒŒì´í”„ë¼ì¸ ìë™ ìµœì í™” ì‹œìŠ¤í…œ
- **ğŸ“Š ì„±ëŠ¥ í‰ê°€**: ê° ì»´í¬ë„ŒíŠ¸ë³„ ë¹„êµ ë¶„ì„ ë° ìµœì í™”

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
ğŸ“ elderly_rag_chatbot/
â”œâ”€â”€ ğŸ“ src/                           # í•µì‹¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ ğŸ“„ text_extractor.py          # ë¬¸ì„œ ì¶”ì¶œ (PDF/HWP/TXT)
â”‚   â”œâ”€â”€ ğŸ”§ text_extraction_comparison.py # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ë¹„êµ
â”‚   â”œâ”€â”€ âœ‚ï¸ chunk_strategy.py          # ì²­í‚¹ ì „ëµ ë¹„êµ
â”‚   â”œâ”€â”€ ğŸ”¢ embedding_models.py        # ì„ë² ë”© ëª¨ë¸ ë¹„êµ
â”‚   â”œâ”€â”€ ğŸ—„ï¸ vector_store.py            # ChromaDB ë²¡í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ ğŸ” retriever.py               # ë‹¤ì¤‘ ê²€ìƒ‰ê¸° ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ ğŸ¤– rag_system.py              # RAG ì²´ì¸ êµ¬í˜„
â”‚   â”œâ”€â”€ ğŸ”„ langgraph_workflow.py      # ì›Œí¬í”Œë¡œìš° ê´€ë¦¬
â”‚   â”œâ”€â”€ ğŸ¯ autorag_optimizer.py       # AutoRAG ìë™ ìµœì í™”
â”‚   â””â”€â”€ ğŸ’¬ chatbot_interface.py       # ì›¹ ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ ğŸ“ config/                        # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ âš™ï¸ settings.py               # ì‹œìŠ¤í…œ ì„¤ì •
â”œâ”€â”€ ğŸ“ data/                          # ë°ì´í„° ë””ë ‰í† ë¦¬
â”‚   â””â”€â”€ ğŸ“‚ ë³µì§€ë¡œ/                    # ë³µì§€ ì •ì±… ë¬¸ì„œ
â”œâ”€â”€ ğŸ“ logs/                          # ë¡œê·¸ íŒŒì¼
â”œâ”€â”€ ğŸ“„ requirements.txt               # ì˜ì¡´ì„± íŒ¨í‚¤ì§€
â”œâ”€â”€ ğŸš€ main.py                        # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ ğŸ“– README.md                      # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì„¤ì •

### 1. í™˜ê²½ ìš”êµ¬ì‚¬í•­

- Python 3.8+
- ìµœì†Œ 8GB RAM ê¶Œì¥
- 10GB ì´ìƒ ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„

### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository_url>
cd elderly_rag_chatbot

# ê°€ìƒ í™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€:

```bash
# OpenAI API í‚¤ (ì„ íƒì‚¬í•­)
OPENAI_API_KEY=your_openai_api_key_here

# ì‹¤í–‰ í™˜ê²½
ELDERLY_RAG_ENV=development

# ë°ì´í„° ë””ë ‰í† ë¦¬
DATA_DIRECTORY=./data/ë³µì§€ë¡œ

# ë¡œê·¸ ë ˆë²¨
LOG_LEVEL=INFO
```

### 4. ë°ì´í„° ì¤€ë¹„

ë³µì§€ ì •ì±… ë¬¸ì„œë¥¼ `data/ë³µì§€ë¡œ/` ë””ë ‰í† ë¦¬ì— ë°°ì¹˜:

```
data/ë³µì§€ë¡œ/
â”œâ”€â”€ ì „êµ­/
â”œâ”€â”€ ê²½ë¶/
â”œâ”€â”€ ëŒ€êµ¬/
â”œâ”€â”€ ë¶€ì‚°/
â”œâ”€â”€ ì „ë‚¨/
â””â”€â”€ ì „ë¶/
```

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰

```bash
# Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‹¤í–‰
python main.py

# Streamlit ì¸í„°í˜ì´ìŠ¤ë¡œ ì‹¤í–‰
python main.py --interface streamlit

# íŠ¹ì • í¬íŠ¸ë¡œ ì‹¤í–‰
python main.py --port 8080
```

### ğŸ¯ AutoRAG ìë™ ìµœì í™”

```bash
# ì™„ì „ ìë™ ìµœì í™” (ê¶Œì¥)
python main.py --autorag

# ì†ë„ ìš°ì„  ìµœì í™”
python main.py --autorag --autorag-target speed

# í’ˆì§ˆ ìš°ì„  ìµœì í™”  
python main.py --autorag --autorag-target quality

# ê· í˜• ìµœì í™” (ê¸°ë³¸ê°’)
python main.py --autorag --autorag-target balanced
```

### ê³ ê¸‰ ì˜µì…˜

```bash
# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬êµ¬ì„±
python main.py --rebuild

# ì„±ëŠ¥ í‰ê°€ í¬í•¨ ì‹¤í–‰
python main.py --evaluate

# ì»¤ìŠ¤í…€ ì„¤ì • íŒŒì¼ ì‚¬ìš©
python main.py --config config/custom_settings.json

# ì¸í„°í˜ì´ìŠ¤ ì—†ì´ ì‹œìŠ¤í…œë§Œ ì´ˆê¸°í™”
python main.py --interface none

# í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¹„êµ í…ŒìŠ¤íŠ¸
python -m src.text_extraction_comparison

# AutoRAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
python -m src.autorag_optimizer
```

### ëª…ë ¹ì¤„ ì˜µì…˜

| ì˜µì…˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `--config, -c` | ì„¤ì • íŒŒì¼ ê²½ë¡œ | None |
| `--interface, -i` | ì¸í„°í˜ì´ìŠ¤ íƒ€ì… (gradio/streamlit/none) | gradio |
| `--rebuild, -r` | ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬êµ¬ì„± | False |
| `--evaluate, -e` | ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰ | False |
| `--port, -p` | ì¸í„°í˜ì´ìŠ¤ í¬íŠ¸ ë²ˆí˜¸ | 7860 |

## ğŸ“Š ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸

### 1. ë¬¸ì„œ ì¶”ì¶œê¸° (`text_extractor.py`)

- **ì§€ì› í˜•ì‹**: PDF, HWP, TXT
- **íŠ¹ì§•**: ë©”íƒ€ë°ì´í„° ì¶”ì¶œ, ìºì‹±, ì˜¤ë¥˜ ì²˜ë¦¬
- **ì„±ëŠ¥**: ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ë°°ì¹˜ ì²˜ë¦¬
- **ìµœì í™”**: ìë™ ìµœì  ì¶”ì¶œê¸° ì„ íƒ

```python
from src.text_extractor import WelfareDocumentExtractor

extractor = WelfareDocumentExtractor("./data/ë³µì§€ë¡œ")
documents = extractor.extract_all_documents(use_best_extractor=True)
```

### 1-1. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¹„êµ (`text_extraction_comparison.py`)

- **PDF ì¶”ì¶œê¸°**: PyPDF2, pdfplumber, PyMuPDF, pdfminer
- **HWP ì¶”ì¶œê¸°**: olefile, hwp5, pyhwp
- **ì„±ëŠ¥ í‰ê°€**: ì„±ê³µë¥ , ì†ë„, í…ìŠ¤íŠ¸ í’ˆì§ˆ
- **ìë™ ì„ íƒ**: ìµœì  ì¶”ì¶œê¸° ìë™ ì„ ì •

```python
from src.text_extraction_comparison import TextExtractionComparison

comparison = TextExtractionComparison()
pdf_results = comparison.compare_pdf_extractors(pdf_files)
best_pdf_extractor = pdf_results["best_extractor"]
```

### 2. ì²­í‚¹ ì „ëµ (`chunk_strategy.py`)

- **ì „ëµ**: ì¬ê·€ì , ë¬¸ë‹¨, ì˜ë¯¸, í† í° ê¸°ë°˜
- **í‰ê°€**: ì¼ê´€ì„±, ì»¤ë²„ë¦¬ì§€, ë‹¤ì–‘ì„± ë©”íŠ¸ë¦­
- **ìµœì í™”**: ìë™ ìµœì  ì „ëµ ì„ íƒ

```python
from src.chunk_strategy import ChunkStrategyComparison

chunker = ChunkStrategyComparison()
evaluation = chunker.evaluate_strategies(texts)
best_strategy = chunker.get_best_strategy(evaluation)
```

### 3. ì„ë² ë”© ëª¨ë¸ (`embedding_models.py`)

- **ëª¨ë¸**: OpenAI, SentenceTransformer, KoBERT
- **í‰ê°€**: ìœ ì‚¬ë„ í’ˆì§ˆ, ì†ë„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **í•œêµ­ì–´**: íŠ¹í™” ëª¨ë¸ ì§€ì›

```python
from src.embedding_models import EmbeddingModelComparison

embedder = EmbeddingModelComparison()
comparison = embedder.compare_models(texts)
best_model = embedder.get_best_model()
```

### 4. ë²¡í„° ì €ì¥ì†Œ (`vector_store.py`)

- **ë°ì´í„°ë² ì´ìŠ¤**: ChromaDB
- **ê¸°ëŠ¥**: ë©”íƒ€ë°ì´í„° í•„í„°ë§, ë¬¸ì„œ ë¶„ë¥˜
- **ê²€ìƒ‰**: ìœ ì‚¬ë„ ê¸°ë°˜ íš¨ìœ¨ì  ê²€ìƒ‰

```python
from src.vector_store import WelfareVectorStore

vector_store = WelfareVectorStore(
    persist_directory="./data/chroma_db",
    embedding_model=best_embedding_model
)
vector_store.add_documents(documents)
```

### 5. ê²€ìƒ‰ê¸° (`retriever.py`)

- **ë°©ì‹**: í‚¤ì›Œë“œ, ì˜ë¯¸, í•˜ì´ë¸Œë¦¬ë“œ
- **ìµœì í™”**: BM25, TF-IDF, ë²¡í„° ê²€ìƒ‰ ì¡°í•©
- **í‰ê°€**: ì •í™•ë„, ì¬í˜„ìœ¨ ë©”íŠ¸ë¦­

```python
from src.retriever import RetrieverComparison

retriever_comp = RetrieverComparison(vector_store)
evaluation = retriever_comp.evaluate_retrievers(queries)
best_retriever = retriever_comp.get_best_retriever()
```

### 6. RAG ì‹œìŠ¤í…œ (`rag_system.py`)

- **ì²´ì¸**: LangChain ê¸°ë°˜ ëŒ€í™”í˜• ì²´ì¸
- **ë©”ëª¨ë¦¬**: ëŒ€í™” ê¸°ë¡ ìœ ì§€
- **í‰ê°€**: ë‹µë³€ í’ˆì§ˆ, ì‹ ë¢°ë„ ì¸¡ì •

```python
from src.rag_system import ElderlyWelfareRAGChain

rag_chain = ElderlyWelfareRAGChain(
    retriever=best_retriever,
    llm_model="gpt-3.5-turbo"
)
response = rag_chain.ask("ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì› ë°©ë²•ì€?")
```

### 7. ì›Œí¬í”Œë¡œìš° (`langgraph_workflow.py`)

- **ê´€ë¦¬**: LangGraph ìƒíƒœ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°
- **ë‹¨ê³„**: ì˜ë„ ë¶„ë¥˜ â†’ ê²€ìƒ‰ â†’ í‰ê°€ â†’ ë‹µë³€ ìƒì„±
- **ì¡°ê±´ë¶€**: ë³µì¡í•œ ì¿¼ë¦¬ ì²˜ë¦¬ ë¡œì§

```python
from src.langgraph_workflow import ElderlyWelfareWorkflow

workflow = ElderlyWelfareWorkflow(rag_chain)
result = workflow.process_query("ë³µì¡í•œ ì§ˆë¬¸...")
```

### 8. ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ (`chatbot_interface.py`)

- **ì¸í„°í˜ì´ìŠ¤**: Gradio, Streamlit ì§€ì›
- **ê¸°ëŠ¥**: ì‹¤ì‹œê°„ ì±„íŒ…, í”¼ë“œë°± ìˆ˜ì§‘, í†µê³„
- **ì‚¬ìš©ì ê²½í—˜**: ì§ê´€ì  ì›¹ UI

```python
from src.chatbot_interface import ElderlyWelfareChatbot, GradioInterface

chatbot = ElderlyWelfareChatbot(rag_system, workflow_system)
interface = GradioInterface(chatbot)
interface.launch()
```

### 9. AutoRAG ìë™ ìµœì í™” (`autorag_optimizer.py`)

- **ìë™ ìµœì í™”**: ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ ìë™ ì„ íƒ
- **ì„±ëŠ¥ ì§€í–¥**: ì†ë„, í’ˆì§ˆ, ê· í˜• ì¤‘ ëª©í‘œ ì„ íƒ ê°€ëŠ¥
- **ë‹¨ê³„ë³„ í‰ê°€**: ê° ì»´í¬ë„ŒíŠ¸ë³„ ìµœì  ì˜µì…˜ ì„ ì •
- **ê²°ê³¼ ì €ì¥**: ìµœì í™” ê³¼ì •ê³¼ ê²°ê³¼ ìë™ ì €ì¥

```python
from src.autorag_optimizer import AutoRAGInterface, AutoRAGConfig

# ìë™ ìµœì í™” ì„¤ì •
config = AutoRAGConfig(
    evaluation_queries=["ì§ˆë¬¸1", "ì§ˆë¬¸2"],
    optimization_target="balanced"
)

# AutoRAG ì‹¤í–‰
autorag = AutoRAGInterface()
results = await autorag.run_optimization(config)
optimized_chatbot = autorag.get_optimized_chatbot()
```

## âš™ï¸ ì„¤ì • ì˜µì…˜

### ì£¼ìš” ì„¤ì • íŒŒì¼: `config/settings.py`

```python
# ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embedding:
  default_model: "sentence_transformer"
  openai_model: "text-embedding-ada-002"

# RAG ì‹œìŠ¤í…œ ì„¤ì •
rag:
  llm_model: "gpt-3.5-turbo"
  temperature: 0.1
  max_tokens: 1000

# ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
interface:
  gradio_server_port: 7860
  max_conversation_history: 20
```

### í™˜ê²½ë³„ ì„¤ì •

- **ê°œë°œ í™˜ê²½**: ë””ë²„ê·¸ ëª¨ë“œ, ìƒì„¸ ë¡œê¹…
- **ìš´ì˜ í™˜ê²½**: ìµœì í™”ëœ ì„±ëŠ¥, ì—ëŸ¬ ë¡œê¹…

## ğŸ“ˆ ì„±ëŠ¥ í‰ê°€

### ìë™ í‰ê°€ ì‹œìŠ¤í…œ

ì‹œìŠ¤í…œì€ ê° ì»´í¬ë„ŒíŠ¸ë³„ ì„±ëŠ¥ì„ ìë™ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤:

1. **ì²­í‚¹ ì „ëµ**: ì¼ê´€ì„±, ì»¤ë²„ë¦¬ì§€, ë‹¤ì–‘ì„±
2. **ì„ë² ë”© ëª¨ë¸**: ìœ ì‚¬ë„ í’ˆì§ˆ, ì²˜ë¦¬ ì†ë„
3. **ê²€ìƒ‰ê¸°**: ì •í™•ë„, ì¬í˜„ìœ¨, ì‘ë‹µ ì‹œê°„
4. **RAG ì‹œìŠ¤í…œ**: ë‹µë³€ í’ˆì§ˆ, ê´€ë ¨ì„±

### í‰ê°€ ì‹¤í–‰

```bash
# ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€
python main.py --evaluate

# ê°œë³„ ì»´í¬ë„ŒíŠ¸ í‰ê°€
python -m src.chunk_strategy
python -m src.embedding_models
python -m src.retriever
```

## ğŸ”§ ê°œë°œ ë° í™•ì¥

### ìƒˆë¡œìš´ ì»´í¬ë„ŒíŠ¸ ì¶”ê°€

1. **ìƒˆë¡œìš´ ì„ë² ë”© ëª¨ë¸**:
   ```python
   # src/embedding_models.pyì— ìƒˆ í´ë˜ìŠ¤ ì¶”ê°€
   class NewEmbeddingModel(BaseEmbeddingModel):
       def embed_text(self, text: str) -> List[float]:
           # êµ¬í˜„
   ```

2. **ìƒˆë¡œìš´ ì²­í‚¹ ì „ëµ**:
   ```python
   # src/chunk_strategy.pyì— ìƒˆ ì „ëµ ì¶”ê°€
   class NewChunkStrategy(BaseChunkStrategy):
       def chunk_text(self, text: str) -> List[str]:
           # êµ¬í˜„
   ```

3. **ìƒˆë¡œìš´ ê²€ìƒ‰ê¸°**:
   ```python
   # src/retriever.pyì— ìƒˆ ê²€ìƒ‰ê¸° ì¶”ê°€
   class NewRetriever(BaseRetriever):
       def retrieve(self, query: str) -> List[Document]:
           # êµ¬í˜„
   ```

### ì»¤ìŠ¤í„°ë§ˆì´ì§•

- **í”„ë¡¬í”„íŠ¸ ìˆ˜ì •**: `src/rag_system.py`ì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
- **UI ì»¤ìŠ¤í„°ë§ˆì´ì§•**: `src/chatbot_interface.py`ì˜ ì¸í„°í˜ì´ìŠ¤
- **ì„¤ì • ë³€ê²½**: `config/settings.py`ì˜ ê°ì¢… íŒŒë¼ë¯¸í„°

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

1. **ë©”ëª¨ë¦¬ ë¶€ì¡±**:
   - ì²­í¬ í¬ê¸° ê°ì†Œ: `chunk_size=500`
   - ë°°ì¹˜ í¬ê¸° ê°ì†Œ: `batch_size=10`

2. **ëŠë¦° ì‘ë‹µ ì†ë„**:
   - ê²½ëŸ‰ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
   - ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì œí•œ: `top_k=3`

3. **ë‹µë³€ í’ˆì§ˆ ì €í•˜**:
   - ë” í° ì²­í¬ í¬ê¸° ì‚¬ìš©
   - ì„ë² ë”© ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ
   - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§

### ë¡œê·¸ í™•ì¸

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
tail -f logs/elderly_rag_chatbot.log

# ì—ëŸ¬ ë¡œê·¸ë§Œ í™•ì¸
grep "ERROR" logs/elderly_rag_chatbot.log
```

## ğŸ“ API ë¬¸ì„œ

### í”„ë¡œê·¸ë˜ë° ì¸í„°í˜ì´ìŠ¤

```python
from main import ElderlyRAGChatbotSystem

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
system = ElderlyRAGChatbotSystem()
await system.initialize_system()

# ì§ˆë¬¸ ì²˜ë¦¬
response = system.chatbot.process_message("ì§ˆë¬¸...")

# ì„±ëŠ¥ í‰ê°€
evaluation = system.run_evaluation()

# ì‹œìŠ¤í…œ ìƒíƒœ
status = system.get_system_status()
```

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ì œê³µë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“ ì§€ì› ë° ë¬¸ì˜

- **ì´ìŠˆ ë¦¬í¬íŠ¸**: [GitHub Issues](https://github.com/your-repo/issues)
- **ê¸°ëŠ¥ ìš”ì²­**: [GitHub Discussions](https://github.com/your-repo/discussions)
- **ë¬¸ì„œ**: ì´ README íŒŒì¼ê³¼ ê° ëª¨ë“ˆì˜ ë…ìŠ¤íŠ¸ë§

## ğŸ™ ê°ì‚¬ì˜ ë§

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤:

- [LangChain](https://github.com/hwchase17/langchain)
- [LangGraph](https://github.com/langchain-ai/langgraph)
- [ChromaDB](https://github.com/chroma-core/chroma)
- [SentenceTransformers](https://github.com/UKPLab/sentence-transformers)
- [Gradio](https://github.com/gradio-app/gradio)
- [Streamlit](https://github.com/streamlit/streamlit)

---

**ğŸ¥ ë…¸ì¸ë³µì§€ ì •ì±… RAG ì±—ë´‡ ì‹œìŠ¤í…œ** - ë” ë‚˜ì€ ë³µì§€ ì„œë¹„ìŠ¤ ì ‘ê·¼ì„±ì„ ìœ„í•˜ì—¬