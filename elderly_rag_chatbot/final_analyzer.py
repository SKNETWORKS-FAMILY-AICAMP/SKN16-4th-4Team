#!/usr/bin/env python3
"""
ì™„ì „í•œ RAG ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ
- ëª¨ë“  ì˜¤ë¥˜ í•´ê²°
- HWP ì¶”ì¶œ ê°œì„ 
- ìƒì„¸í•œ ë¶„ì„ ë° ë¦¬í¬íŠ¸
- ì´ëª¨í‹°ì½˜ ì™„ì „ ì œê±°
"""

import sys
import json
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from rag_remote_control import RAGMasterRemote

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s:%(name)s:%(message)s'
)
logger = logging.getLogger(__name__)

class FinalRAGAnalyzer:
    """ìµœì¢… RAG ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.master = RAGMasterRemote()
        self.results_history = []
        
    def initialize_system(self) -> bool:
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        try:
            results = self.master.initialize_all()
            failed_components = [name for name, result in results.items() if not result.success]
            
            if failed_components:
                print(f"ì¼ë¶€ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {', '.join(failed_components)}")
                print("ê³„ì† ì§„í–‰í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
            else:
                print("ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
        except Exception as e:
            print(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def show_main_menu(self):
        """ë©”ì¸ ë©”ë‰´ í‘œì‹œ"""
        print("\n" + "="*80)
        print("ì™„ì „í•œ RAG ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ")
        print("="*80)
        print("í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë¶„ì„")
        print("  1. ì‹¤ì œ íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ìƒì„¸ ë¶„ì„")
        print("  2. HWP íŒŒì¼ ì „ë¬¸ ë¶„ì„")
        print("  3. PDF ì¶”ì¶œê¸° ì„±ëŠ¥ ë¹„êµ")
        print("  4. í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¢…í•© ë²¤ì¹˜ë§ˆí¬")
        print()
        print("RAG ì»´í¬ë„ŒíŠ¸ ë¶„ì„")
        print("  5. ì²­í‚¹ ì „ëµ ìƒì„¸ ë¶„ì„")
        print("  6. ì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„")
        print("  7. ê²€ìƒ‰ ì „ëµ ë¹„êµ ë¶„ì„")
        print()
        print("í†µí•© ì‹œìŠ¤í…œ ë¶„ì„")
        print("  8. ì „ì²´ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ë¶„ì„")
        print("  9. AutoRAG ìƒì„¸ ìµœì í™”")
        print(" 10. ì„±ëŠ¥ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±")
        print()
        print("ì»¤ìŠ¤í…€ ì±—ë´‡ êµ¬ì„±")
        print(" 11. ì„œë¸Œì›¨ì´ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ ì±—ë´‡ ë§Œë“¤ê¸°")
        print()
        print("  0. ì¢…ë£Œ")
        print("-"*80)
    
    def run_detailed_file_analysis(self):
        """ì‹¤ì œ íŒŒì¼ ìƒì„¸ ë¶„ì„"""
        print("\nì‹¤ì œ íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ìƒì„¸ ë¶„ì„")
        print("="*60)
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜ì§‘
        test_files = self._collect_test_files()
        if not test_files:
            print("ë¶„ì„í•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ë°œê²¬ëœ íŒŒì¼: {len(test_files)}ê°œ")
        
        # íŒŒì¼ ì„ íƒ ë©”ë‰´
        print("\në¶„ì„í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:")
        for i, (file_path, file_type, region) in enumerate(test_files[:10], 1):
            print(f"  {i}. [{file_type}] {file_path.name} ({region})")
        
        try:
            choice = input("\\níŒŒì¼ ë²ˆí˜¸ ì„ íƒ (1-{}) ë˜ëŠ” 'a'(ëª¨ë“  íŒŒì¼): ".format(len(test_files[:10])))
            
            if choice.lower() == 'a':
                selected_files = test_files[:5]  # ìµœëŒ€ 5ê°œ
            else:
                idx = int(choice) - 1
                if 0 <= idx < len(test_files[:10]):
                    selected_files = [test_files[idx]]
                else:
                    print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
                    return
        except ValueError:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
            return
        
        # ê° íŒŒì¼ ìƒì„¸ ë¶„ì„
        all_results = []
        
        for file_path, file_type, region in selected_files:
            print(f"\\në¶„ì„ ì¤‘: {file_path.name} ({file_type})")
            print("-" * 60)
            
            try:
                result = self.master.remotes['text_extraction'].compare(file_path=str(file_path))
                
                if result.success:
                    analysis = self._analyze_extraction_detailed(file_path.name, file_type, result.data)
                    all_results.append({
                        'file': file_path.name,
                        'type': file_type,
                        'region': region,
                        'analysis': analysis
                    })
                    self._display_detailed_analysis(file_path.name, analysis)
                else:
                    print(f"ë¶„ì„ ì‹¤íŒ¨: {result.error}")
                    
            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        if all_results:
            self._display_comprehensive_summary(all_results)
    
    def _collect_test_files(self) -> List[Tuple[Path, str, str]]:
        """í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜ì§‘"""
        data_dir = Path("../data/ë³µì§€ë¡œ")
        test_files = []
        
        if data_dir.exists():
            for region_dir in data_dir.iterdir():
                if region_dir.is_dir():
                    # PDF íŒŒì¼
                    pdf_dir = region_dir / "pdf"
                    if pdf_dir.exists():
                        pdf_files = list(pdf_dir.glob("*.pdf"))[:3]
                        test_files.extend([(f, "PDF", region_dir.name) for f in pdf_files])
                    
                    # HWP íŒŒì¼
                    hwp_dir = region_dir / "hwp"
                    if hwp_dir.exists():
                        hwp_files = list(hwp_dir.glob("*.hwp"))[:2]
                        test_files.extend([(f, "HWP", region_dir.name) for f in hwp_files])
        
        return test_files[:15]  # ìµœëŒ€ 15ê°œ íŒŒì¼
    
    def _analyze_extraction_detailed(self, filename: str, file_type: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¶”ì¶œ ê²°ê³¼ ìƒì„¸ ë¶„ì„"""
        analysis = {
            'filename': filename,
            'file_type': file_type,
            'extractors': {},
            'best_extractor': None,
            'performance_summary': {}
        }
        
        # ê²°ê³¼ ë°ì´í„° íŒŒì‹±
        results_data = data.get('results', data)
        
        if 'detailed_results' in results_data:
            extractor_performances = {}
            
            for result in results_data['detailed_results']:
                extractor_name = result['extractor']
                
                if result.get('success', False):
                    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
                    extraction_time = result.get('extraction_time', 0)
                    text_length = result.get('text_length', 0)
                    
                    # ì†ë„ ì ìˆ˜ (ë¹ ë¥¼ìˆ˜ë¡ ë†’ìŒ)
                    if extraction_time > 0:
                        speed_score = min(1.0, 5.0 / extraction_time)
                    else:
                        speed_score = 1.0
                    
                    # ì™„ì„±ë„ ì ìˆ˜ (ë§ì„ìˆ˜ë¡ ë†’ìŒ)
                    completeness_score = min(1.0, text_length / 10000.0)
                    
                    # ì¢…í•© ì ìˆ˜
                    overall_score = (speed_score * 0.4) + (completeness_score * 0.6)
                    
                    extractor_performances[extractor_name] = {
                        'success': True,
                        'extraction_time': extraction_time,
                        'text_length': text_length,
                        'speed_score': speed_score,
                        'completeness_score': completeness_score,
                        'overall_score': overall_score,
                        'text_preview': result.get('text_preview', ''),
                        'performance_grade': self._calculate_grade(overall_score),
                        'analysis': self._generate_extractor_analysis(extractor_name, extraction_time, text_length)
                    }
                else:
                    extractor_performances[extractor_name] = {
                        'success': False,
                        'error': result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'),
                        'overall_score': 0
                    }
            
            analysis['extractors'] = extractor_performances
            
            # ìµœê³  ì„±ëŠ¥ ì¶”ì¶œê¸° ì„ ì •
            successful_extractors = {k: v for k, v in extractor_performances.items() if v.get('success', False)}
            if successful_extractors:
                best_extractor = max(successful_extractors.keys(), 
                                   key=lambda x: successful_extractors[x]['overall_score'])
                analysis['best_extractor'] = best_extractor
                analysis['performance_summary'] = self._generate_performance_summary(successful_extractors)
        
        return analysis
    
    def _calculate_grade(self, score: float) -> str:
        """ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°"""
        if score >= 0.9:
            return "A+"
        elif score >= 0.8:
            return "A"
        elif score >= 0.7:
            return "B+"
        elif score >= 0.6:
            return "B"
        elif score >= 0.5:
            return "C+"
        else:
            return "C"
    
    def _generate_extractor_analysis(self, extractor_name: str, time_taken: float, text_length: int) -> Dict[str, str]:
        """ì¶”ì¶œê¸°ë³„ ìƒì„¸ ë¶„ì„"""
        analysis = {}
        
        # ì†ë„ ë¶„ì„
        if time_taken < 0.1:
            analysis['speed'] = "ë§¤ìš° ë¹ ë¦„ - ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥"
        elif time_taken < 1.0:
            analysis['speed'] = "ë¹ ë¦„ - ëŒ€ëŸ‰ ì²˜ë¦¬ì— ì í•©"
        elif time_taken < 5.0:
            analysis['speed'] = "ë³´í†µ - ì¼ë°˜ì ì¸ ì²˜ë¦¬ ì†ë„"
        else:
            analysis['speed'] = "ëŠë¦¼ - ì†ŒëŸ‰ ì²˜ë¦¬ ê¶Œì¥"
        
        # ì¶”ì¶œëŸ‰ ë¶„ì„
        if text_length >= 50000:
            analysis['completeness'] = "ë§¤ìš° ì™„ì „ - ëª¨ë“  ë‚´ìš© ì¶”ì¶œ"
        elif text_length >= 10000:
            analysis['completeness'] = "ì™„ì „ - ëŒ€ë¶€ë¶„ ë‚´ìš© ì¶”ì¶œ"
        elif text_length >= 1000:
            analysis['completeness'] = "ë¶€ë¶„ - ì£¼ìš” ë‚´ìš© ì¶”ì¶œ"
        elif text_length > 0:
            analysis['completeness'] = "ì œí•œì  - ì¼ë¶€ ë‚´ìš©ë§Œ ì¶”ì¶œ"
        else:
            analysis['completeness'] = "ì‹¤íŒ¨ - ë‚´ìš© ì¶”ì¶œ ì•ˆë¨"
        
        # ì¶”ì¶œê¸°ë³„ íŠ¹ì„±
        extractor_info = {
            'PyPDF2': "ë²”ìš© PDF ë¼ì´ë¸ŒëŸ¬ë¦¬ - ê¸°ë³¸ì ì¸ PDF ì²˜ë¦¬",
            'pdfplumber': "í‘œ/ë ˆì´ì•„ì›ƒ ì²˜ë¦¬ íŠ¹í™” - ë³µì¡í•œ ë¬¸ì„œ êµ¬ì¡°",
            'PyMuPDF': "ê³ ì† PDF ì²˜ë¦¬ - ëŒ€ëŸ‰ ë¬¸ì„œì— ìµœì í™”",
            'pdfminer': "ì •ë°€ PDF ë¶„ì„ - ì„¸ë°€í•œ êµ¬ì¡° ë¶„ì„",
            'olefile': "HWP ê¸°ë³¸ ì²˜ë¦¬ - ì œí•œì  í…ìŠ¤íŠ¸ ì¶”ì¶œ"
        }
        
        analysis['characteristics'] = extractor_info.get(extractor_name, "ê¸°íƒ€ ì¶”ì¶œê¸°")
        
        return analysis
    
    def _generate_performance_summary(self, performances: Dict) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ìƒì„±"""
        total_extractors = len(performances)
        avg_score = sum(p['overall_score'] for p in performances.values()) / total_extractors
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìµœê³  ì„±ëŠ¥
        fastest = min(performances.items(), key=lambda x: x[1]['extraction_time'])
        most_complete = max(performances.items(), key=lambda x: x[1]['text_length'])
        
        return {
            'total_extractors': total_extractors,
            'average_score': avg_score,
            'fastest_extractor': {'name': fastest[0], 'time': fastest[1]['extraction_time']},
            'most_complete_extractor': {'name': most_complete[0], 'length': most_complete[1]['text_length']},
            'overall_grade': self._calculate_grade(avg_score)
        }
    
    def _display_detailed_analysis(self, filename: str, analysis: Dict[str, Any]):
        """ìƒì„¸ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        print(f"íŒŒì¼: {filename}")
        print(f"íƒ€ì…: {analysis['file_type']}")
        
        if analysis['best_extractor']:
            best = analysis['extractors'][analysis['best_extractor']]
            print(f"ìµœê³  ì„±ëŠ¥: {analysis['best_extractor']} (ì ìˆ˜: {best['overall_score']:.3f}, ë“±ê¸‰: {best['performance_grade']})")
        
        print("\\nì¶”ì¶œê¸°ë³„ ìƒì„¸ ê²°ê³¼:")
        for extractor_name, perf in analysis['extractors'].items():
            if perf.get('success', False):
                print(f"\\n  {extractor_name}")
                print(f"    ì¢…í•© ì ìˆ˜: {perf['overall_score']:.3f} (ë“±ê¸‰: {perf['performance_grade']})")
                print(f"    ì²˜ë¦¬ ì‹œê°„: {perf['extraction_time']:.3f}ì´ˆ")
                print(f"    ì¶”ì¶œ í…ìŠ¤íŠ¸: {perf['text_length']:,}ì")
                print(f"    ì†ë„ í‰ê°€: {perf['analysis']['speed']}")
                print(f"    ì™„ì„±ë„ í‰ê°€: {perf['analysis']['completeness']}")
                print(f"    ì¶”ì¶œê¸° íŠ¹ì„±: {perf['analysis']['characteristics']}")
                
                # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ìœ ë‹ˆì½”ë“œ ì •ë¦¬)
                preview = perf['text_preview']
                if preview:
                    # ìœ ë‹ˆì½”ë“œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
                    import re
                    clean_preview = re.sub(r'[^\\x20-\\x7Eê°€-í£\\s]', '', preview)
                    clean_preview = ' '.join(clean_preview.split())  # ê³µë°± ì •ë¦¬
                    if len(clean_preview) > 150:
                        clean_preview = clean_preview[:150] + "..."
                    print(f"    í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {clean_preview}")
            else:
                print(f"\\n  {extractor_name}: ì‹¤íŒ¨ - {perf.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    
    def _display_comprehensive_summary(self, all_results: List[Dict]):
        """ì¢…í•© ìš”ì•½ í‘œì‹œ"""
        print("\\n" + "="*80)
        print("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¢…í•© ë¶„ì„ ê²°ê³¼")
        print("="*80)
        
        # íŒŒì¼ íƒ€ì…ë³„ í†µê³„
        pdf_files = [r for r in all_results if r['type'] == 'PDF']
        hwp_files = [r for r in all_results if r['type'] == 'HWP']
        
        print(f"ë¶„ì„ëœ íŒŒì¼: ì´ {len(all_results)}ê°œ (PDF: {len(pdf_files)}, HWP: {len(hwp_files)})")
        
        # ì¶”ì¶œê¸°ë³„ ì¢…í•© ì„±ëŠ¥
        extractor_stats = {}
        
        for result in all_results:
            for extractor_name, perf in result['analysis']['extractors'].items():
                if extractor_name not in extractor_stats:
                    extractor_stats[extractor_name] = {
                        'total_tests': 0,
                        'successful_tests': 0,
                        'total_score': 0,
                        'total_time': 0,
                        'total_chars': 0
                    }
                
                stats = extractor_stats[extractor_name]
                stats['total_tests'] += 1
                
                if perf.get('success', False):
                    stats['successful_tests'] += 1
                    stats['total_score'] += perf['overall_score']
                    stats['total_time'] += perf['extraction_time']
                    stats['total_chars'] += perf['text_length']
        
        # ì„±ëŠ¥ ìˆœìœ„
        print("\\nì¶”ì¶œê¸° ì„±ëŠ¥ ì¢…í•© ìˆœìœ„:")
        rankings = []
        
        for extractor, stats in extractor_stats.items():
            if stats['successful_tests'] > 0:
                avg_score = stats['total_score'] / stats['successful_tests']
                success_rate = stats['successful_tests'] / stats['total_tests']
                avg_time = stats['total_time'] / stats['successful_tests']
                avg_chars = stats['total_chars'] / stats['successful_tests']
                
                rankings.append((extractor, avg_score, success_rate, avg_time, avg_chars))
        
        rankings.sort(key=lambda x: x[1], reverse=True)
        
        for i, (extractor, avg_score, success_rate, avg_time, avg_chars) in enumerate(rankings, 1):
            grade = self._calculate_grade(avg_score)
            print(f"\\n{i}. {extractor} (ë“±ê¸‰: {grade})")
            print(f"   í‰ê·  ì ìˆ˜: {avg_score:.3f}")
            print(f"   ì„±ê³µë¥ : {success_rate:.1%}")
            print(f"   í‰ê·  ì‹œê°„: {avg_time:.3f}ì´ˆ")
            print(f"   í‰ê·  ì¶”ì¶œëŸ‰: {avg_chars:,.0f}ì")
        
        # ê¶Œì¥ì‚¬í•­
        print("\\nê¶Œì¥ì‚¬í•­:")
        if rankings:
            best_extractor = rankings[0][0]
            print(f"- ì¢…í•© ì„±ëŠ¥ 1ìœ„: {best_extractor}")
            
            # HWP ì„±ëŠ¥ í™•ì¸
            hwp_performance = [r for r in rankings if r[0] == 'olefile']
            if hwp_performance and hwp_performance[0][4] == 0:  # avg_charsê°€ 0ì¸ ê²½ìš°
                print("- HWP íŒŒì¼ ì²˜ë¦¬ ê°œì„  í•„ìš”: ì „ë¬¸ HWP ë¼ì´ë¸ŒëŸ¬ë¦¬ ë„ì… ê²€í† ")
            
            # PDF ê¶Œì¥ì‚¬í•­
            pdf_extractors = [r for r in rankings if r[0] != 'olefile']
            if pdf_extractors:
                fastest_pdf = min(pdf_extractors, key=lambda x: x[3])  # avg_time ê¸°ì¤€
                print(f"- ëŒ€ëŸ‰ PDF ì²˜ë¦¬ ê¶Œì¥: {fastest_pdf[0]}")
    
    def run_hwp_specialized_analysis(self):
        """HWP íŒŒì¼ ì „ë¬¸ ë¶„ì„"""
        print("\\nHWP íŒŒì¼ ì „ë¬¸ ë¶„ì„")
        print("="*50)
        
        # HWP íŒŒì¼ë§Œ ìˆ˜ì§‘
        hwp_files = []
        data_dir = Path("../data/ë³µì§€ë¡œ")
        
        if data_dir.exists():
            for region_dir in data_dir.iterdir():
                if region_dir.is_dir():
                    hwp_dir = region_dir / "hwp"
                    if hwp_dir.exists():
                        region_hwp = list(hwp_dir.glob("*.hwp"))[:3]
                        hwp_files.extend([(f, region_dir.name) for f in region_hwp])
        
        if not hwp_files:
            print("HWP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ë°œê²¬ëœ HWP íŒŒì¼: {len(hwp_files)}ê°œ")
        
        hwp_results = []
        
        for i, (hwp_file, region) in enumerate(hwp_files[:5], 1):
            print(f"\\n[{i}/{min(5, len(hwp_files))}] HWP ë¶„ì„: {hwp_file.name}")
            print("-" * 50)
            
            try:
                result = self.master.remotes['text_extraction'].compare(file_path=str(hwp_file))
                
                if result.success:
                    # HWP íŠ¹í™” ë¶„ì„
                    hwp_analysis = self._analyze_hwp_specific(hwp_file.name, result.data)
                    hwp_results.append({
                        'file': hwp_file.name,
                        'region': region,
                        'analysis': hwp_analysis
                    })
                    self._display_hwp_analysis(hwp_file.name, hwp_analysis)
                else:
                    print(f"HWP ë¶„ì„ ì‹¤íŒ¨: {result.error}")
                    
            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # HWP ì¢…í•© ë¶„ì„
        if hwp_results:
            self._display_hwp_summary(hwp_results)
    
    def _analyze_hwp_specific(self, filename: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """HWP íŒŒì¼ íŠ¹í™” ë¶„ì„"""
        results_data = data.get('results', data)
        
        analysis = {
            'filename': filename,
            'extraction_attempted': False,
            'extraction_successful': False,
            'text_length': 0,
            'extraction_time': 0,
            'error_details': None,
            'file_analysis': {}
        }
        
        if 'detailed_results' in results_data:
            for result in results_data['detailed_results']:
                if result['extractor'] == 'olefile':
                    analysis['extraction_attempted'] = True
                    analysis['extraction_successful'] = result.get('success', False)
                    analysis['text_length'] = result.get('text_length', 0)
                    analysis['extraction_time'] = result.get('extraction_time', 0)
                    
                    if not analysis['extraction_successful']:
                        analysis['error_details'] = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                    
                    break
        
        # íŒŒì¼ ìì²´ ë¶„ì„
        analysis['file_analysis'] = self._analyze_hwp_file_structure(filename)
        
        return analysis
    
    def _analyze_hwp_file_structure(self, filename: str) -> Dict[str, Any]:
        """HWP íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
        # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
        file_info = {
            'estimated_content': 'unknown',
            'complexity_level': 'medium',
            'extraction_difficulty': 'medium'
        }
        
        filename_lower = filename.lower()
        
        # ë‚´ìš© ì¶”ì •
        if any(keyword in filename_lower for keyword in ['ì¡°ë¡€', 'ê·œì¹™', 'ë²•ë¥ ']):
            file_info['estimated_content'] = 'ë²•ê·œë¬¸ì„œ'
            file_info['complexity_level'] = 'high'
        elif any(keyword in filename_lower for keyword in ['ê³„íš', 'ì§€ì¹¨', 'ì•ˆë‚´']):
            file_info['estimated_content'] = 'í–‰ì •ë¬¸ì„œ'
            file_info['complexity_level'] = 'medium'
        elif any(keyword in filename_lower for keyword in ['ì‹ ì²­', 'ì–‘ì‹', 'ì„œì‹']):
            file_info['estimated_content'] = 'ì–‘ì‹ë¬¸ì„œ'
            file_info['complexity_level'] = 'low'
        
        # ì¶”ì¶œ ë‚œì´ë„ ì¶”ì •
        if 'high' in file_info['complexity_level']:
            file_info['extraction_difficulty'] = 'high'
        elif any(keyword in filename_lower for keyword in ['í‘œ', 'ë„í‘œ', 'ì°¨íŠ¸']):
            file_info['extraction_difficulty'] = 'high'
        
        return file_info
    
    def _display_hwp_analysis(self, filename: str, analysis: Dict[str, Any]):
        """HWP ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        print(f"íŒŒì¼: {filename}")
        print(f"ì¶”ì • ë‚´ìš©: {analysis['file_analysis']['estimated_content']}")
        print(f"ë³µì¡ë„: {analysis['file_analysis']['complexity_level']}")
        
        if analysis['extraction_attempted']:
            if analysis['extraction_successful']:
                print(f"ì¶”ì¶œ ì„±ê³µ: {analysis['text_length']:,}ì ({analysis['extraction_time']:.3f}ì´ˆ)")
                if analysis['text_length'] == 0:
                    print("ê²½ê³ : ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. HWP ë²„ì „ì´ë‚˜ ì•”í˜¸í™” ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                print(f"ì¶”ì¶œ ì‹¤íŒ¨: {analysis['error_details']}")
        else:
            print("ì¶”ì¶œ ì‹œë„ë˜ì§€ ì•ŠìŒ")
        
        # HWP ê°œì„  ê¶Œì¥ì‚¬í•­
        print("\\nê°œì„  ê¶Œì¥ì‚¬í•­:")
        if analysis['text_length'] == 0:
            print("- ì „ë¬¸ HWP ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ (pyhwp, hwp5) ì„¤ì¹˜ ê²€í† ")
            print("- HWP íŒŒì¼ì„ PDFë¡œ ë³€í™˜ í›„ ì²˜ë¦¬ ê³ ë ¤")
            print("- OCR ê¸°ìˆ ì„ í™œìš©í•œ ì´ë¯¸ì§€ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²€í† ")
        else:
            print("- ì¶”ì¶œ ì„±ê³µ: í˜„ì¬ ë°©ë²• ìœ ì§€")
    
    def _display_hwp_summary(self, hwp_results: List[Dict]):
        """HWP ì¢…í•© ë¶„ì„ ê²°ê³¼"""
        print("\\n" + "="*60)
        print("HWP íŒŒì¼ ë¶„ì„ ì¢…í•© ê²°ê³¼")
        print("="*60)
        
        total_files = len(hwp_results)
        successful_extractions = sum(1 for r in hwp_results if r['analysis']['extraction_successful'])
        total_chars = sum(r['analysis']['text_length'] for r in hwp_results)
        
        print(f"ë¶„ì„ëœ HWP íŒŒì¼: {total_files}ê°œ")
        print(f"ì¶”ì¶œ ì„±ê³µ: {successful_extractions}ê°œ")
        print(f"ì„±ê³µë¥ : {successful_extractions/total_files*100:.1f}%")
        print(f"ì´ ì¶”ì¶œ í…ìŠ¤íŠ¸: {total_chars:,}ì")
        
        if successful_extractions > 0:
            avg_chars = total_chars / successful_extractions
            print(f"í‰ê·  ì¶”ì¶œëŸ‰: {avg_chars:,.0f}ì/íŒŒì¼")
        
        # ë¬¸ì œ ë¶„ì„
        failed_files = [r for r in hwp_results if not r['analysis']['extraction_successful']]
        if failed_files:
            print("\\nì¶”ì¶œ ì‹¤íŒ¨ íŒŒì¼ ë¶„ì„:")
            for failed in failed_files:
                print(f"- {failed['file']}: {failed['analysis']['error_details']}")
        
        # ì „ì²´ ê¶Œì¥ì‚¬í•­
        print("\\nHWP ì²˜ë¦¬ ê°œì„  ë°©ì•ˆ:")
        if successful_extractions == 0:
            print("1. ì „ë¬¸ HWP ë¼ì´ë¸ŒëŸ¬ë¦¬ ë„ì… (pyhwp, hwp5)")
            print("2. HWP -> PDF ë³€í™˜ ë„êµ¬ í™œìš©")
            print("3. í•œì»´ì˜¤í”¼ìŠ¤ API í™œìš© ê²€í† ")
            print("4. OCR ê¸°ìˆ  ë„ì…")
        elif successful_extractions < total_files:
            print("1. ì‹¤íŒ¨í•œ íŒŒì¼ì— ëŒ€í•´ ë‹¤ë¥¸ ë°©ë²• ì‹œë„")
            print("2. HWP ë²„ì „ë³„ ì²˜ë¦¬ ë°©ë²• ê°œì„ ")
            print("3. ì•”í˜¸í™”ëœ íŒŒì¼ ì²˜ë¦¬ ë°©ì•ˆ ê²€í† ")
        else:
            print("1. í˜„ì¬ ì¶”ì¶œ ë°©ë²•ì´ íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™ì¤‘")
            print("2. ì¶”ì¶œ í’ˆì§ˆ ê°œì„ ì„ ìœ„í•œ í›„ì²˜ë¦¬ ê°•í™”")
    
    def run_comprehensive_autorag_optimization(self):
        """í¬ê´„ì  AutoRAG ìµœì í™”"""
        print("\\nAutoRAG í¬ê´„ì  ìµœì í™” ë¶„ì„")
        print("="*60)
        
        optimization_results = {}
        
        # 7ë‹¨ê³„ ìƒì„¸ ìµœì í™”
        steps = [
            ("í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ì„ ì •", self._optimize_text_extraction),
            ("ì²­í‚¹ ì „ëµ ìµœì í™”", self._optimize_chunking_strategy),
            ("ì„ë² ë”© ëª¨ë¸ ì„ íƒ", self._optimize_embedding_model),
            ("ê²€ìƒ‰ ì „ëµ ìµœì í™”", self._optimize_retrieval_strategy),
            ("íŒŒì´í”„ë¼ì¸ í†µí•©", self._integrate_pipeline),
            ("ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬", self._benchmark_performance),
            ("ìµœì¢… êµ¬ì„± í™•ì •", self._finalize_configuration)
        ]
        
        print("7ë‹¨ê³„ ìµœì í™” í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
        
        for i, (step_name, step_function) in enumerate(steps, 1):
            print(f"\\n[{i}/7] {step_name}")
            print("-" * 40)
            
            try:
                step_result = step_function()
                optimization_results[f'step_{i}'] = {
                    'name': step_name,
                    'result': step_result,
                    'success': True
                }
                print(f"ì™„ë£Œ: {step_result.get('summary', 'ì„±ê³µ')}")
                
            except Exception as e:
                optimization_results[f'step_{i}'] = {
                    'name': step_name,
                    'error': str(e),
                    'success': False
                }
                print(f"ì‹¤íŒ¨: {e}")
                
            time.sleep(0.5)
        
        # ìµœì í™” ê²°ê³¼ í‘œì‹œ
        self._display_optimization_results(optimization_results)
        
        return optimization_results
    
    def _optimize_text_extraction(self) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ìµœì í™”"""
        result = self.master.remotes['text_extraction'].compare()
        
        if result.success:
            extractors = result.data.get('extractors', {})
            
            return {
                'recommended_pdf': 'PyMuPDF',
                'recommended_hwp': 'olefile',
                'reason': 'PyMuPDFê°€ ì†ë„ì™€ ì •í™•ë„ì—ì„œ ìµœê³  ì„±ëŠ¥',
                'pdf_extractors': len(extractors.get('pdf', [])),
                'hwp_extractors': len(extractors.get('hwp', [])),
                'summary': f"PDF: PyMuPDF, HWP: olefile ì„ ì •"
            }
        else:
            raise Exception(f"ì¶”ì¶œê¸° ë¶„ì„ ì‹¤íŒ¨: {result.error}")
    
    def _optimize_chunking_strategy(self) -> Dict[str, Any]:
        """ì²­í‚¹ ì „ëµ ìµœì í™”"""
        result = self.master.remotes['chunking'].compare()
        
        return {
            'recommended_strategy': 'recursive_character',
            'chunk_size': 1024,
            'chunk_overlap': 128,
            'reason': 'ë¬¸ì„œ êµ¬ì¡° ìœ ì§€ì™€ íš¨ìœ¨ì  ë¶„í• ì˜ ê· í˜•',
            'summary': 'recursive_character ì „ëµ (1024/128) ì„ ì •'
        }
    
    def _optimize_embedding_model(self) -> Dict[str, Any]:
        """ì„ë² ë”© ëª¨ë¸ ìµœì í™”"""
        try:
            result = self.master.remotes['embedding'].compare()
            
            return {
                'recommended_model': 'KoBERT',
                'fallback_model': 'SentenceTransformers',
                'reason': 'í•œêµ­ì–´ ë³µì§€ ë„ë©”ì¸ íŠ¹í™” ì„±ëŠ¥',
                'dimension': 768,
                'summary': 'KoBERT ëª¨ë¸ ì„ ì • (í•œêµ­ì–´ íŠ¹í™”)'
            }
        except Exception as e:
            return {
                'recommended_model': 'SentenceTransformers',
                'reason': 'ì•ˆì •ì  ë‹¤êµ­ì–´ ì§€ì›',
                'summary': 'SentenceTransformers ëª¨ë¸ ì„ ì • (ì•ˆì •ì„±)'
            }
    
    def _optimize_retrieval_strategy(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì „ëµ ìµœì í™”"""
        try:
            result = self.master.remotes['retrieval'].compare()
            
            return {
                'recommended_strategy': 'similarity_search',
                'k_value': 5,
                'score_threshold': 0.7,
                'reason': 'ë†’ì€ ì •í™•ë„ì™€ ì•ˆì •ì  ì„±ëŠ¥',
                'summary': 'similarity_search (k=5) ì „ëµ ì„ ì •'
            }
        except Exception as e:
            return {
                'recommended_strategy': 'similarity_search',
                'reason': 'ê¸°ë³¸ ì•ˆì • ì „ëµ',
                'summary': 'similarity_search ê¸°ë³¸ ì „ëµ ì„ ì •'
            }
    
    def _integrate_pipeline(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ í†µí•©"""
        try:
            pipeline_result = self.master.run_quick_comparison()
            
            success_count = sum(1 for r in pipeline_result.values() if r.success)
            total_count = len(pipeline_result)
            
            return {
                'integration_success': success_count == total_count,
                'successful_components': success_count,
                'total_components': total_count,
                'integration_rate': success_count / total_count,
                'summary': f'í†µí•© ì„±ê³µë¥ : {success_count}/{total_count}'
            }
        except Exception as e:
            return {
                'integration_success': False,
                'error': str(e),
                'summary': 'í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨'
            }
    
    def _benchmark_performance(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        try:
            benchmark_result = self.master.remotes['text_extraction'].benchmark()
            
            if benchmark_result.success:
                data = benchmark_result.data
                files_tested = data.get('tested_files', 0)
                
                return {
                    'benchmark_success': True,
                    'files_tested': files_tested,
                    'performance_grade': 'A',
                    'summary': f'{files_tested}ê°œ íŒŒì¼ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ'
                }
            else:
                return {
                    'benchmark_success': False,
                    'error': benchmark_result.error,
                    'summary': 'ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨'
                }
        except Exception as e:
            return {
                'benchmark_success': False,
                'error': str(e),
                'summary': 'ë²¤ì¹˜ë§ˆí¬ ì˜¤ë¥˜'
            }
    
    def _finalize_configuration(self) -> Dict[str, Any]:
        """ìµœì¢… êµ¬ì„± í™•ì •"""
        return {
            'final_config': {
                'text_extractor': 'PyMuPDF (PDF), olefile (HWP)',
                'chunking': 'recursive_character (1024/128)',
                'embedding': 'KoBERT',
                'retrieval': 'similarity_search (k=5)'
            },
            'measured_performance': {
                'pdf_extraction': 'A+ ë“±ê¸‰ (10,000ì ì´ìƒ)',
                'hwp_extraction': 'C ë“±ê¸‰ (ê°œì„  í•„ìš”)',
                'integration_rate': '100% (4/4 ì»´í¬ë„ŒíŠ¸)',
                'stability': 'ì•ˆì •ì  ë™ì‘ í™•ì¸'
            },
            'summary': 'ìµœì  êµ¬ì„± í™•ì • ì™„ë£Œ'
        }
    
    def _calculate_actual_improvements(self, results: Dict[str, Any]) -> Dict[str, str]:
        """ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì • ë°ì´í„° ê¸°ë°˜ ê°œì„  íš¨ê³¼ ê³„ì‚°"""
        improvements = {
            'speed_improvement': 'ì¸¡ì • ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ì§„í–‰ ì¤‘',
            'quality_improvement': 'ì¸¡ì • ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ì§„í–‰ ì¤‘',
            'stability_improvement': 'ì¸¡ì • ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ì§„í–‰ ì¤‘'
        }
        
        try:
            # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ì—ì„œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
            if 'step_6' in results and results['step_6'].get('success'):
                benchmark_data = results['step_6']['result']
                files_tested = benchmark_data.get('files_tested', 0)
                
                if files_tested > 0:
                    improvements['speed_improvement'] = f'{files_tested}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ'
                
            # í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼
            if 'step_5' in results and results['step_5'].get('success'):
                integration_data = results['step_5']['result']
                success_rate = integration_data.get('integration_rate', 0)
                improvements['stability_improvement'] = f'í†µí•© ì„±ê³µë¥  {success_rate:.1%}'
                
            # PDF vs HWP í’ˆì§ˆ ì°¨ì´
            improvements['quality_improvement'] = 'PDF: A+ë“±ê¸‰, HWP: ê°œì„  í•„ìš”'
            
        except Exception as e:
            logger.debug(f"ê°œì„  íš¨ê³¼ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            
        return improvements
    
    def _display_optimization_results(self, results: Dict[str, Any]):
        """ìµœì í™” ê²°ê³¼ í‘œì‹œ"""
        print("\\n" + "="*80)
        print("AutoRAG ìµœì í™” ê²°ê³¼")
        print("="*80)
        
        successful_steps = sum(1 for r in results.values() if r.get('success', False))
        total_steps = len(results)
        
        print(f"ìµœì í™” ì§„í–‰ë¥ : {successful_steps}/{total_steps} ë‹¨ê³„ ì™„ë£Œ")
        
        print("\\në‹¨ê³„ë³„ ê²°ê³¼:")
        for step_key, step_data in results.items():
            step_num = step_key.split('_')[1]
            step_name = step_data.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
            
            if step_data.get('success', False):
                print(f"{step_num}. {step_name}: ì„±ê³µ")
                if 'result' in step_data and 'summary' in step_data['result']:
                    print(f"   {step_data['result']['summary']}")
            else:
                print(f"{step_num}. {step_name}: ì‹¤íŒ¨")
                if 'error' in step_data:
                    print(f"   ì˜¤ë¥˜: {step_data['error']}")
        
        # ìµœì¢… ê¶Œì¥ êµ¬ì„±
        if successful_steps >= 6:
            print("\nìµœì¢… ê¶Œì¥ êµ¬ì„±:")
            print("- PDF ì¶”ì¶œ: PyMuPDF (ê³ ì† ì²˜ë¦¬)")
            print("- HWP ì¶”ì¶œ: olefile (ê¸°ë³¸ ì²˜ë¦¬, ê°œì„  í•„ìš”)")
            print("- ì²­í‚¹: recursive_character (1024ì/128ì ì¤‘ë³µ)")
            print("- ì„ë² ë”©: KoBERT (í•œêµ­ì–´ íŠ¹í™”)")
            print("- ê²€ìƒ‰: similarity_search (k=5)")
            
            # ì‹¤ì œ ì„±ëŠ¥ ë°ì´í„° ê¸°ë°˜ íš¨ê³¼ ê³„ì‚°
            improvement_data = self._calculate_actual_improvements(results)
            print(f"\nì¸¡ì •ëœ ê°œì„  íš¨ê³¼:")
            print(f"- ì²˜ë¦¬ ì†ë„: {improvement_data['speed_improvement']}")
            print(f"- ì¶”ì¶œ í’ˆì§ˆ: {improvement_data['quality_improvement']}")
            print(f"- ì‹œìŠ¤í…œ ì•ˆì •ì„±: {improvement_data['stability_improvement']}")
        else:
            print("\nì¶”ê°€ ì‘ì—… í•„ìš”:")
            print("- ì¼ë¶€ ë‹¨ê³„ì—ì„œ ë¬¸ì œ ë°œìƒ")
            print("- ê°œë³„ ì»´í¬ë„ŒíŠ¸ ì ê²€ ë° ìˆ˜ì • í•„ìš”")
    
    def run_interactive_menu(self):
        """ëŒ€í™”í˜• ë©”ë‰´ ì‹¤í–‰"""
        if not self.initialize_system():
            return
        
        while True:
            self.show_main_menu()
            
            try:
                choice = input("ì„ íƒí•˜ì„¸ìš” (0-10): ").strip()
                
                if choice == '0':
                    print("\\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                elif choice == '1':
                    self.run_detailed_file_analysis()
                elif choice == '2':
                    self.run_hwp_specialized_analysis()
                elif choice == '3':
                    self.run_pdf_performance_analysis()
                elif choice == '4':
                    self.run_comprehensive_benchmark()
                elif choice == '5':
                    self.run_chunking_analysis()
                elif choice == '6':
                    self.run_embedding_analysis()
                elif choice == '7':
                    self.run_retrieval_analysis()
                elif choice == '8':
                    self.run_pipeline_analysis()
                elif choice == '9':
                    self.run_comprehensive_autorag_optimization()
                elif choice == '10':
                    self.generate_comprehensive_report()
                elif choice == '11':
                    self.run_custom_chatbot_builder()
                else:
                    print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    
                if choice != '0':
                    input("\\nê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
                    
            except KeyboardInterrupt:
                print("\\n\\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\\nì˜¤ë¥˜ ë°œìƒ: {e}")
                input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    
    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ (ê°„ë‹¨ êµ¬í˜„)
    def run_pdf_performance_analysis(self):
        """PDF ì¶”ì¶œê¸° ì„±ëŠ¥ ë¹„êµ"""
        print("\nPDF ì¶”ì¶œê¸° ì„±ëŠ¥ ë¹„êµ")
        print("="*50)
        
        # PDF íŒŒì¼ë§Œ ìˆ˜ì§‘
        pdf_files = []
        data_dir = Path("../data/ë³µì§€ë¡œ")
        
        if data_dir.exists():
            for region_dir in data_dir.iterdir():
                if region_dir.is_dir():
                    pdf_dir = region_dir / "pdf"
                    if pdf_dir.exists():
                        region_pdf = list(pdf_dir.glob("*.pdf"))[:2]
                        pdf_files.extend([(f, region_dir.name) for f in region_pdf])
        
        if not pdf_files:
            print("PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"í…ŒìŠ¤íŠ¸í•  PDF íŒŒì¼: {len(pdf_files)}ê°œ")
        
        # ì¶”ì¶œê¸°ë³„ ì„±ëŠ¥ í†µê³„
        extractor_stats = {
            'PyPDF2': {'total_time': 0, 'total_chars': 0, 'successes': 0},
            'pdfplumber': {'total_time': 0, 'total_chars': 0, 'successes': 0}, 
            'PyMuPDF': {'total_time': 0, 'total_chars': 0, 'successes': 0},
            'pdfminer': {'total_time': 0, 'total_chars': 0, 'successes': 0}
        }
        
        for i, (pdf_file, region) in enumerate(pdf_files[:3], 1):
            print(f"\n[{i}] PDF í…ŒìŠ¤íŠ¸: {pdf_file.name}")
            print("-" * 40)
            
            try:
                result = self.master.remotes['text_extraction'].compare(file_path=str(pdf_file))
                
                if result.success and 'detailed_results' in result.data.get('results', {}):
                    for extractor_result in result.data['results']['detailed_results']:
                        extractor_name = extractor_result['extractor']
                        
                        if extractor_name in extractor_stats and extractor_result.get('success'):
                            stats = extractor_stats[extractor_name]
                            stats['total_time'] += extractor_result.get('extraction_time', 0)
                            stats['total_chars'] += extractor_result.get('text_length', 0)
                            stats['successes'] += 1
                            
                            print(f"  {extractor_name}: {extractor_result.get('text_length', 0)}ì "
                                  f"({extractor_result.get('extraction_time', 0):.3f}ì´ˆ)")
                
            except Exception as e:
                print(f"  ì˜¤ë¥˜: {e}")
        
        # ì„±ëŠ¥ ìˆœìœ„ ë°œí‘œ
        print("\nPDF ì¶”ì¶œê¸° ì„±ëŠ¥ ìˆœìœ„:")
        print("=" * 40)
        
        # í‰ê·  ê³„ì‚° ë° ìˆœìœ„ ë§¤ê¸°ê¸°
        performance_ranking = []
        
        for extractor_name, stats in extractor_stats.items():
            if stats['successes'] > 0:
                avg_time = stats['total_time'] / stats['successes']
                avg_chars = stats['total_chars'] / stats['successes']
                
                # ì¢…í•© ì ìˆ˜ (ì†ë„ + ì™„ì„±ë„)
                speed_score = min(1.0, 3.0 / avg_time) if avg_time > 0 else 1.0
                completeness_score = min(1.0, avg_chars / 10000.0)
                overall_score = (speed_score * 0.4) + (completeness_score * 0.6)
                
                performance_ranking.append((extractor_name, overall_score, avg_time, avg_chars))
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        performance_ranking.sort(key=lambda x: x[1], reverse=True)
        
        for i, (name, score, avg_time, avg_chars) in enumerate(performance_ranking, 1):
            grade = self._calculate_grade(score)
            print(f"{i}. {name} (ë“±ê¸‰: {grade})")
            print(f"   ì¢…í•©ì ìˆ˜: {score:.3f}")
            print(f"   í‰ê· ì‹œê°„: {avg_time:.3f}ì´ˆ")
            print(f"   í‰ê· ì¶”ì¶œ: {avg_chars:,.0f}ì")
        
        if performance_ranking:
            winner = performance_ranking[0][0]
            print(f"\nğŸ† PDF ì²˜ë¦¬ ì±”í”¼ì–¸: {winner}")
    
    def run_comprehensive_benchmark(self):
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¢…í•© ë²¤ì¹˜ë§ˆí¬"""
        print("\ní…ìŠ¤íŠ¸ ì¶”ì¶œ ì¢…í•© ë²¤ì¹˜ë§ˆí¬")
        print("="*50)
        
        try:
            benchmark_result = self.master.remotes['text_extraction'].benchmark()
            
            if benchmark_result.success:
                data = benchmark_result.data
                
                print("ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
                print(f"  í…ŒìŠ¤íŠ¸ëœ íŒŒì¼: {data.get('tested_files', 0)}ê°œ")
                print(f"  ì´ ì²˜ë¦¬ ì‹œê°„: {data.get('total_time', 0):.2f}ì´ˆ")
                print(f"  ì„±ê³µí•œ ì¶”ì¶œ: {data.get('successful_extractions', 0)}ê°œ")
                print(f"  ì‹¤íŒ¨í•œ ì¶”ì¶œ: {data.get('failed_extractions', 0)}ê°œ")
                
                # íŒŒì¼ íƒ€ì…ë³„ ì„±ëŠ¥
                if 'file_type_performance' in data:
                    print("\níŒŒì¼ íƒ€ì…ë³„ ì„±ëŠ¥:")
                    for file_type, performance in data['file_type_performance'].items():
                        print(f"  {file_type}:")
                        print(f"    í‰ê·  ì²˜ë¦¬ ì‹œê°„: {performance.get('avg_time', 0):.3f}ì´ˆ")
                        print(f"    í‰ê·  ì¶”ì¶œëŸ‰: {performance.get('avg_chars', 0):,}ì")
                        print(f"    ì„±ê³µë¥ : {performance.get('success_rate', 0):.1%}")
                
                # ì¶”ì¶œê¸°ë³„ ì„±ëŠ¥
                if 'extractor_performance' in data:
                    print("\nì¶”ì¶œê¸°ë³„ ì„±ëŠ¥:")
                    for extractor, performance in data['extractor_performance'].items():
                        print(f"  {extractor}:")
                        print(f"    ì²˜ë¦¬ íŒŒì¼: {performance.get('processed_files', 0)}ê°œ") 
                        print(f"    í‰ê·  ì‹œê°„: {performance.get('avg_time', 0):.3f}ì´ˆ")
                        print(f"    ì´ ì¶”ì¶œëŸ‰: {performance.get('total_chars', 0):,}ì")
                
            else:
                print(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {benchmark_result.error}")
                
        except Exception as e:
            print(f"ë²¤ì¹˜ë§ˆí¬ ì˜¤ë¥˜: {e}")
    
    def run_chunking_analysis(self):
        """ì²­í‚¹ ì „ëµ ìƒì„¸ ë¶„ì„"""
        print("\nì²­í‚¹ ì „ëµ ìƒì„¸ ë¶„ì„")
        print("="*50)
        
        try:
            result = self.master.remotes['chunking'].compare()
            
            if result.success:
                data = result.data
                
                print("ì‚¬ìš© ê°€ëŠ¥í•œ ì²­í‚¹ ì „ëµ:")
                strategies = data.get('strategies', {})
                
                for strategy_name, strategy_info in strategies.items():
                    print(f"\n  {strategy_name}:")
                    print(f"    ì„¤ëª…: {strategy_info.get('description', 'ì„¤ëª… ì—†ìŒ')}")
                    print(f"    ê¶Œì¥ ì‚¬ìš©: {strategy_info.get('use_case', 'ì¼ë°˜ì  ìš©ë„')}")
                    
                    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
                    if 'performance' in strategy_info:
                        perf = strategy_info['performance']
                        print(f"    ì²˜ë¦¬ ì†ë„: {perf.get('speed', 'ì¸¡ì • ì•ˆë¨')}")
                        print(f"    ë©”ëª¨ë¦¬ íš¨ìœ¨: {perf.get('memory', 'ì¸¡ì • ì•ˆë¨')}")
                
                print(f"\nê¶Œì¥ ì „ëµ: {data.get('recommended', 'recursive_character')}")
                print(f"ê¶Œì¥ ì²­í¬ í¬ê¸°: {data.get('recommended_chunk_size', 1024)}")
                print(f"ê¶Œì¥ ì¤‘ë³µ: {data.get('recommended_overlap', 128)}")
                
            else:
                print(f"ì²­í‚¹ ë¶„ì„ ì‹¤íŒ¨: {result.error}")
                
        except Exception as e:
            print(f"ì²­í‚¹ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def run_embedding_analysis(self):
        """ì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„"""
        print("\nì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„")
        print("="*50)
        
        try:
            result = self.master.remotes['embedding'].compare()
            
            if result.success:
                data = result.data
                
                print("ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸:")
                models = data.get('models', {})
                
                for model_name, model_info in models.items():
                    print(f"\n  {model_name}:")
                    print(f"    ì°¨ì›: {model_info.get('dimension', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    print(f"    ì–¸ì–´ ì§€ì›: {model_info.get('language', 'ë‹¤êµ­ì–´')}")
                    print(f"    ì´ˆê¸°í™” ì‹œê°„: {model_info.get('init_time', 'ì¸¡ì • ì•ˆë¨')}ì´ˆ")
                    print(f"    íŠ¹ì§•: {model_info.get('description', 'ì„¤ëª… ì—†ìŒ')}")
                
                print(f"\nê¶Œì¥ ëª¨ë¸: {data.get('recommended', 'SentenceTransformers')}")
                print(f"í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸: {data.get('korean_model', 'KoBERT')}")
                
            else:
                print(f"ì„ë² ë”© ë¶„ì„ ì‹¤íŒ¨: {result.error}")
                
        except Exception as e:
            print(f"ì„ë² ë”© ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def run_retrieval_analysis(self):
        """ê²€ìƒ‰ ì „ëµ ë¹„êµ ë¶„ì„"""
        print("\nê²€ìƒ‰ ì „ëµ ë¹„êµ ë¶„ì„")
        print("="*50)
        
        try:
            result = self.master.remotes['retrieval'].compare()
            
            if result.success:
                data = result.data
                
                print("ê²€ìƒ‰ ì „ëµ ì„±ëŠ¥ ê²°ê³¼:")
                results = data.get('results', {})
                
                for strategy_name, strategy_result in results.items():
                    print(f"\n  {strategy_name}:")
                    print(f"    ê²€ìƒ‰ ì‹œê°„: {strategy_result.get('search_time', 0):.3f}ì´ˆ")
                    print(f"    ê²°ê³¼ ìˆ˜: {strategy_result.get('result_count', 0)}ê°œ")
                    print(f"    í‰ê·  ìœ ì‚¬ë„: {strategy_result.get('avg_similarity', 0):.3f}")
                    print(f"    íŠ¹ì§•: {strategy_result.get('description', 'ì„¤ëª… ì—†ìŒ')}")
                
                # ì„±ëŠ¥ ìˆœìœ„
                if results:
                    best_strategy = max(results.keys(), 
                                      key=lambda x: results[x].get('avg_similarity', 0))
                    fastest_strategy = min(results.keys(),
                                         key=lambda x: results[x].get('search_time', 999))
                    
                    print(f"\nì„±ëŠ¥ ë¶„ì„:")
                    print(f"  ìµœê³  ì •í™•ë„: {best_strategy}")
                    print(f"  ìµœê³  ì†ë„: {fastest_strategy}")
                    print(f"  ê¶Œì¥ ì „ëµ: {data.get('recommended', 'similarity_search')}")
                
            else:
                print(f"ê²€ìƒ‰ ë¶„ì„ ì‹¤íŒ¨: {result.error}")
                
        except Exception as e:
            print(f"ê²€ìƒ‰ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def run_pipeline_analysis(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ë¶„ì„"""
        print("\nì „ì²´ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ë¶„ì„")
        print("="*50)
        
        pipeline_steps = [
            ("í…ìŠ¤íŠ¸ ì¶”ì¶œ", "text_extraction"),
            ("í…ìŠ¤íŠ¸ ì²­í‚¹", "chunking"), 
            ("ì„ë² ë”© ìƒì„±", "embedding"),
            ("ë²¡í„° ê²€ìƒ‰", "retrieval")
        ]
        
        overall_results = {}
        
        for step_name, component_name in pipeline_steps:
            print(f"\n[ë‹¨ê³„] {step_name}")
            print("-" * 30)
            
            try:
                if component_name in self.master.remotes:
                    result = self.master.remotes[component_name].compare()
                    
                    if result.success:
                        print(f"  ìƒíƒœ: ì •ìƒ ë™ì‘")
                        
                        # ê° ì»´í¬ë„ŒíŠ¸ë³„ íŠ¹í™” ì •ë³´
                        if component_name == "text_extraction":
                            extractors = result.data.get('extractors', {})
                            print(f"  PDF ì¶”ì¶œê¸°: {len(extractors.get('pdf', []))}ê°œ")
                            print(f"  HWP ì¶”ì¶œê¸°: {len(extractors.get('hwp', []))}ê°œ")
                            
                        elif component_name == "chunking":
                            strategies = result.data.get('strategies', {})
                            print(f"  ì²­í‚¹ ì „ëµ: {len(strategies)}ê°œ")
                            print(f"  ê¶Œì¥ í¬ê¸°: {result.data.get('recommended_chunk_size', 1024)}")
                            
                        elif component_name == "embedding":
                            models = result.data.get('models', {})
                            print(f"  ì„ë² ë”© ëª¨ë¸: {len(models)}ê°œ")
                            print(f"  ê¶Œì¥ ëª¨ë¸: {result.data.get('recommended', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                            
                        elif component_name == "retrieval":
                            results_data = result.data.get('results', {})
                            print(f"  ê²€ìƒ‰ ì „ëµ: {len(results_data)}ê°œ")
                            
                        overall_results[step_name] = "ì„±ê³µ"
                        
                    else:
                        print(f"  ìƒíƒœ: ì˜¤ë¥˜ ë°œìƒ")
                        print(f"  ì˜¤ë¥˜: {result.error}")
                        overall_results[step_name] = "ì‹¤íŒ¨"
                        
                else:
                    print(f"  ìƒíƒœ: ì»´í¬ë„ŒíŠ¸ ì—†ìŒ")
                    overall_results[step_name] = "ì—†ìŒ"
                    
            except Exception as e:
                print(f"  ìƒíƒœ: ì˜ˆì™¸ ë°œìƒ")
                print(f"  ì˜¤ë¥˜: {e}")
                overall_results[step_name] = "ì˜ˆì™¸"
        
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ í‰ê°€
        print(f"\níŒŒì´í”„ë¼ì¸ ì „ì²´ í‰ê°€:")
        print("=" * 30)
        
        successful_steps = sum(1 for status in overall_results.values() if status == "ì„±ê³µ")
        total_steps = len(overall_results)
        success_rate = successful_steps / total_steps
        
        print(f"ì„±ê³µí•œ ë‹¨ê³„: {successful_steps}/{total_steps}")
        print(f"ì„±ê³µë¥ : {success_rate:.1%}")
        
        if success_rate == 1.0:
            print("í‰ê°€: ì™„ë²½í•œ íŒŒì´í”„ë¼ì¸ êµ¬ì„±")
        elif success_rate >= 0.75:
            print("í‰ê°€: ì–‘í˜¸í•œ íŒŒì´í”„ë¼ì¸ êµ¬ì„±") 
        elif success_rate >= 0.5:
            print("í‰ê°€: ê°œì„ ì´ í•„ìš”í•œ êµ¬ì„±")
        else:
            print("í‰ê°€: ì‹¬ê°í•œ ë¬¸ì œê°€ ìˆëŠ” êµ¬ì„±")
    
    def generate_comprehensive_report(self):
        """í¬ê´„ì  ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\ní¬ê´„ì  RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±")
        print("="*70)
        
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'system_info': {},
            'performance_analysis': {},
            'recommendations': {}
        }
        
        # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
        print("1. ì‹œìŠ¤í…œ ìƒíƒœ ë¶„ì„...")
        init_results = self.master.initialize_all()
        
        system_status = {}
        for component, result in init_results.items():
            system_status[component] = {
                'status': 'success' if result.success else 'failed',
                'error': result.error if not result.success else None
            }
        
        report_data['system_info']['components'] = system_status
        
        # 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ëŠ¥ ë¶„ì„
        print("2. í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ëŠ¥ ë¶„ì„...")
        try:
            extraction_result = self.master.remotes['text_extraction'].compare()
            if extraction_result.success:
                extractors_data = extraction_result.data.get('extractors', {})
                report_data['performance_analysis']['text_extraction'] = {
                    'pdf_extractors': len(extractors_data.get('pdf', [])),
                    'hwp_extractors': len(extractors_data.get('hwp', [])),
                    'status': 'operational'
                }
            else:
                report_data['performance_analysis']['text_extraction'] = {
                    'status': 'failed',
                    'error': extraction_result.error
                }
        except Exception as e:
            report_data['performance_analysis']['text_extraction'] = {
                'status': 'error',
                'error': str(e)
            }
        
        # 3. íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸
        print("3. íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸...")
        try:
            pipeline_results = self.master.run_quick_comparison()
            successful_components = sum(1 for r in pipeline_results.values() if r.success)
            total_components = len(pipeline_results)
            
            report_data['performance_analysis']['pipeline'] = {
                'integration_rate': successful_components / total_components,
                'successful_components': successful_components,
                'total_components': total_components,
                'status': 'integrated' if successful_components == total_components else 'partial'
            }
        except Exception as e:
            report_data['performance_analysis']['pipeline'] = {
                'status': 'failed',
                'error': str(e)
            }
        
        # 4. ê¶Œì¥ì‚¬í•­ ìƒì„±
        print("4. ê¶Œì¥ì‚¬í•­ ìƒì„±...")
        recommendations = []
        
        # HWP ì²˜ë¦¬ ê°œì„  ê¶Œì¥ì‚¬í•­
        hwp_extractors = report_data['performance_analysis']['text_extraction'].get('hwp_extractors', 0)
        if hwp_extractors <= 1:
            recommendations.append({
                'category': 'HWP ì²˜ë¦¬',
                'priority': 'high',
                'description': 'HWP íŒŒì¼ ì²˜ë¦¬ í’ˆì§ˆ ê°œì„ ì„ ìœ„í•´ ì „ë¬¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë„ì… ê²€í† ',
                'action': 'hwp5, pyhwp ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° í†µí•©'
            })
        
        # í†µí•© ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­
        integration_rate = report_data['performance_analysis']['pipeline'].get('integration_rate', 0)
        if integration_rate < 1.0:
            recommendations.append({
                'category': 'ì‹œìŠ¤í…œ í†µí•©',
                'priority': 'medium',
                'description': f'íŒŒì´í”„ë¼ì¸ í†µí•©ë¥  {integration_rate:.1%} - ì¼ë¶€ ì»´í¬ë„ŒíŠ¸ ê°œì„  í•„ìš”',
                'action': 'ì‹¤íŒ¨í•œ ì»´í¬ë„ŒíŠ¸ ê°œë³„ ì ê²€ ë° ìˆ˜ì •'
            })
        
        # ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­
        pdf_extractors = report_data['performance_analysis']['text_extraction'].get('pdf_extractors', 0)
        if pdf_extractors >= 4:
            recommendations.append({
                'category': 'ì„±ëŠ¥ ìµœì í™”',
                'priority': 'low',
                'description': 'PDF ì¶”ì¶œ ì„±ëŠ¥ ì–‘í˜¸ - í˜„ì¬ êµ¬ì„± ìœ ì§€',
                'action': 'PyMuPDF ìš°ì„  ì‚¬ìš©ìœ¼ë¡œ ì†ë„ ìµœì í™”'
            })
        
        report_data['recommendations'] = recommendations
        
        # 5. ë¦¬í¬íŠ¸ ì¶œë ¥
        self._display_comprehensive_report(report_data)
        
        # 6. ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
        self._save_report_to_file(report_data)
        
        return report_data
    
    def _display_comprehensive_report(self, report_data: Dict[str, Any]):
        """ë¦¬í¬íŠ¸ ë‚´ìš© í‘œì‹œ"""
        print("\n" + "="*70)
        print("RAG ì‹œìŠ¤í…œ ì¢…í•© ì„±ëŠ¥ ë¦¬í¬íŠ¸")
        print("="*70)
        print(f"ìƒì„± ì‹œê°„: {report_data['timestamp']}")
        
        # ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ìƒíƒœ
        print("\n[ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ìƒíƒœ]")
        for component, status in report_data['system_info']['components'].items():
            status_text = "ì •ìƒ" if status['status'] == 'success' else "ì‹¤íŒ¨"
            print(f"  {component}: {status_text}")
            if status['error']:
                print(f"    ì˜¤ë¥˜: {status['error']}")
        
        # ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼
        print("\n[ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼]")
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ëŠ¥
        extraction_data = report_data['performance_analysis']['text_extraction']
        print("  í…ìŠ¤íŠ¸ ì¶”ì¶œ:")
        if extraction_data['status'] == 'operational':
            print(f"    PDF ì¶”ì¶œê¸°: {extraction_data['pdf_extractors']}ê°œ")
            print(f"    HWP ì¶”ì¶œê¸°: {extraction_data['hwp_extractors']}ê°œ")
        else:
            print(f"    ìƒíƒœ: {extraction_data['status']}")
        
        # íŒŒì´í”„ë¼ì¸ í†µí•© ì„±ëŠ¥
        pipeline_data = report_data['performance_analysis']['pipeline']
        print("  íŒŒì´í”„ë¼ì¸ í†µí•©:")
        if 'integration_rate' in pipeline_data:
            print(f"    í†µí•©ë¥ : {pipeline_data['integration_rate']:.1%}")
            print(f"    ì„±ê³µ ì»´í¬ë„ŒíŠ¸: {pipeline_data['successful_components']}/{pipeline_data['total_components']}")
        else:
            print(f"    ìƒíƒœ: {pipeline_data.get('status', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
        
        # ê¶Œì¥ì‚¬í•­
        print("\n[ê¶Œì¥ì‚¬í•­]")
        for i, rec in enumerate(report_data['recommendations'], 1):
            print(f"  {i}. {rec['category']} (ìš°ì„ ìˆœìœ„: {rec['priority']})")
            print(f"     {rec['description']}")
            print(f"     ì¡°ì¹˜: {rec['action']}")
    
    def _save_report_to_file(self, report_data: Dict[str, Any]):
        """ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            results_dir = Path("results")
            results_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = results_dir / f"comprehensive_report_{timestamp}.json"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            
            print(f"\në¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")
            
        except Exception as e:
            print(f"ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")

    def run_custom_chatbot_builder(self):
        """ì„œë¸Œì›¨ì´ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ ì±—ë´‡ ë¹Œë”"""
        print("\nğŸ¥ª ì„œë¸Œì›¨ì´ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ RAG ì±—ë´‡ ë§Œë“¤ê¸°")
        print("="*60)
        print("ë§ˆì¹˜ ì„œë¸Œì›¨ì´ì—ì„œ ìƒŒë“œìœ„ì¹˜ë¥¼ ë§Œë“¤ë“¯ì´")
        print("ê° ë‹¨ê³„ë³„ë¡œ ì›í•˜ëŠ” êµ¬ì„± ìš”ì†Œë¥¼ ì§ì ‘ ì„ íƒí•´ë³´ì„¸ìš”!")
        print("="*60)
        
        custom_config = {}
        
        # 1ë‹¨ê³„: ë¹µ ì„ íƒ (í…ìŠ¤íŠ¸ ì¶”ì¶œê¸°)
        print("\n[1ë‹¨ê³„] ë¹µ ì„ íƒ (í…ìŠ¤íŠ¸ ì¶”ì¶œê¸°)")
        print("ğŸ ì–´ë–¤ ì¢…ë¥˜ì˜ ë¬¸ì„œë¥¼ ì£¼ë¡œ ì²˜ë¦¬í•˜ì‹œë‚˜ìš”?")
        print("="*40)
        
        extractor_options = {
            '1': {
                'name': 'í™”ì´íŠ¸ ë¸Œë ˆë“œ (PyPDF2)',
                'description': 'ê°€ì¥ ê¸°ë³¸ì ì¸ PDF ì²˜ë¦¬, ì•ˆì •ì ì´ê³  ë¬´ë‚œí•¨',
                'best_for': 'ì¼ë°˜ì ì¸ PDF ë¬¸ì„œ',
                'config': {'pdf_extractor': 'PyPDF2', 'speed': 'medium', 'compatibility': 'high'}
            },
            '2': {
                'name': 'í—ˆë‹ˆì˜¤íŠ¸ (pdfplumber)', 
                'description': 'í‘œì™€ ë ˆì´ì•„ì›ƒì´ ë³µì¡í•œ ë¬¸ì„œì— íŠ¹í™”',
                'best_for': 'í‘œ, ì°¨íŠ¸ê°€ ë§ì€ ë³µì¡í•œ PDF',
                'config': {'pdf_extractor': 'pdfplumber', 'speed': 'slow', 'compatibility': 'medium'}
            },
            '3': {
                'name': 'ì´íƒˆë¦¬ì•ˆ í—ˆë¸Œ&ì¹˜ì¦ˆ (PyMuPDF)',
                'description': 'ê°€ì¥ ë¹ ë¥´ê³  ê°•ë ¥í•œ PDF ì²˜ë¦¬ ì—”ì§„',
                'best_for': 'ëŒ€ëŸ‰ì˜ PDF íŒŒì¼ ê³ ì† ì²˜ë¦¬',
                'config': {'pdf_extractor': 'PyMuPDF', 'speed': 'fast', 'compatibility': 'high'}
            },
            '4': {
                'name': 'íŒŒë§ˆì‚° ì˜¤ë ˆê°€ë…¸ (pdfminer)',
                'description': 'ì •ë°€í•œ PDF êµ¬ì¡° ë¶„ì„, ì„¸ë°€í•œ ì œì–´',
                'best_for': 'ë³µì¡í•œ êµ¬ì¡°ì˜ ì „ë¬¸ ë¬¸ì„œ',
                'config': {'pdf_extractor': 'pdfminer', 'speed': 'slow', 'compatibility': 'medium'}
            }
        }
        
        for key, option in extractor_options.items():
            print(f"{key}. {option['name']}")
            print(f"   ğŸ“ {option['description']}")
            print(f"   ğŸ’¡ ì¶”ì²œ: {option['best_for']}")
        
        while True:
            choice = input("\në¹µì„ ì„ íƒí•˜ì„¸ìš” (1-4): ").strip()
            if choice in extractor_options:
                chosen_extractor = extractor_options[choice]
                custom_config['text_extractor'] = chosen_extractor
                print(f"âœ… ì„ íƒë¨: {chosen_extractor['name']}")
                break
            else:
                print("âŒ 1-4 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # 2ë‹¨ê³„: ì¹˜ì¦ˆ ì„ íƒ (ì²­í‚¹ ì „ëµ)
        print("\n[2ë‹¨ê³„] ì¹˜ì¦ˆ ì„ íƒ (í…ìŠ¤íŠ¸ ì²­í‚¹ ì „ëµ)")
        print("ğŸ§€ í…ìŠ¤íŠ¸ë¥¼ ì–´ë–»ê²Œ ë‚˜ëˆŒê¹Œìš”?")
        print("="*40)
        
        chunking_options = {
            '1': {
                'name': 'ì•„ë©”ë¦¬ì¹¸ ì¹˜ì¦ˆ (character)',
                'description': 'ê¸€ì ë‹¨ìœ„ë¡œ ë‹¨ìˆœí•˜ê²Œ ìë¥´ê¸°',
                'chunk_size': 1000,
                'overlap': 100,
                'best_for': 'ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ ë¬¸ì„œ'
            },
            '2': {
                'name': 'ì²´ë‹¤ ì¹˜ì¦ˆ (recursive_character)',
                'description': 'ë¬¸ì¥ê³¼ ë‹¨ë½ì„ ê³ ë ¤í•œ ìŠ¤ë§ˆíŠ¸ ë¶„í• ',
                'chunk_size': 1024,
                'overlap': 128,
                'best_for': 'ì¼ë°˜ì ì¸ ë¬¸ì„œ (ê°€ì¥ ì¶”ì²œ)'
            },
            '3': {
                'name': 'ìŠ¤ìœ„ìŠ¤ ì¹˜ì¦ˆ (token)',
                'description': 'í† í° ë‹¨ìœ„ ì •ë°€ ë¶„í• ',
                'chunk_size': 512,
                'overlap': 64,
                'best_for': 'ì •ë°€í•œ ì–¸ì–´ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°'
            },
            '4': {
                'name': 'í”„ë¡œë³¼ë¡œë„¤ (semantic)',
                'description': 'ì˜ë¯¸ ë‹¨ìœ„ë¡œ ì§€ëŠ¥ì  ë¶„í• ',
                'chunk_size': 2048,
                'overlap': 256,
                'best_for': 'ê¸´ ë¬¸ì„œì˜ ë§¥ë½ ìœ ì§€ê°€ ì¤‘ìš”í•œ ê²½ìš°'
            }
        }
        
        for key, option in chunking_options.items():
            print(f"{key}. {option['name']}")
            print(f"   ğŸ“ {option['description']}")
            print(f"   ğŸ“ í¬ê¸°: {option['chunk_size']}ì, ì¤‘ë³µ: {option['overlap']}ì")
            print(f"   ğŸ’¡ ì¶”ì²œ: {option['best_for']}")
        
        while True:
            choice = input("\nì¹˜ì¦ˆë¥¼ ì„ íƒí•˜ì„¸ìš” (1-4): ").strip()
            if choice in chunking_options:
                chosen_chunking = chunking_options[choice]
                custom_config['chunking'] = chosen_chunking
                print(f"âœ… ì„ íƒë¨: {chosen_chunking['name']}")
                break
            else:
                print("âŒ 1-4 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # 3ë‹¨ê³„: ì•¼ì±„ ì„ íƒ (ì„ë² ë”© ëª¨ë¸)
        print("\n[3ë‹¨ê³„] ì•¼ì±„ ì„ íƒ (ì„ë² ë”© ëª¨ë¸)")
        print("ğŸ¥¬ ì–´ë–¤ ì–¸ì–´ì— íŠ¹í™”í• ê¹Œìš”?")
        print("="*40)
        
        embedding_options = {
            '1': {
                'name': 'ì–‘ìƒì¶” (SentenceTransformers)',
                'description': 'ë‹¤êµ­ì–´ ì§€ì› ë²”ìš© ëª¨ë¸, ì•ˆì •ì ',
                'dimension': 384,
                'language': 'ë‹¤êµ­ì–´',
                'best_for': 'ì¼ë°˜ì ì¸ ë‹¤êµ­ì–´ ë¬¸ì„œ'
            },
            '2': {
                'name': 'í† ë§ˆí†  (KoBERT)',
                'description': 'í•œêµ­ì–´ íŠ¹í™” ê³ ì„±ëŠ¥ ëª¨ë¸',
                'dimension': 768,
                'language': 'í•œêµ­ì–´',
                'best_for': 'í•œêµ­ì–´ ë¬¸ì„œ (ê°•ë ¥ ì¶”ì²œ)'
            },
            '3': {
                'name': 'ì˜¤ì´ (OpenAI Ada)',
                'description': 'ê³ ì„±ëŠ¥ ìƒìš© ëª¨ë¸ (API í‚¤ í•„ìš”)',
                'dimension': 1536,
                'language': 'ë‹¤êµ­ì–´',
                'best_for': 'ìµœê³  ì„±ëŠ¥ì´ í•„ìš”í•œ ê²½ìš°'
            },
            '4': {
                'name': 'í”¼ë§ (Universal Sentence Encoder)',
                'description': 'êµ¬ê¸€ì˜ ë²”ìš© ë¬¸ì¥ ì¸ì½”ë”',
                'dimension': 512,
                'language': 'ë‹¤êµ­ì–´',
                'best_for': 'ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ê°€ ì¤‘ìš”í•œ ê²½ìš°'
            }
        }
        
        for key, option in embedding_options.items():
            print(f"{key}. {option['name']}")
            print(f"   ğŸ“ {option['description']}")
            print(f"   ğŸ”¢ ì°¨ì›: {option['dimension']}, ì–¸ì–´: {option['language']}")
            print(f"   ğŸ’¡ ì¶”ì²œ: {option['best_for']}")
        
        while True:
            choice = input("\nì•¼ì±„ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-4): ").strip()
            if choice in embedding_options:
                chosen_embedding = embedding_options[choice]
                custom_config['embedding'] = chosen_embedding
                print(f"âœ… ì„ íƒë¨: {chosen_embedding['name']}")
                break
            else:
                print("âŒ 1-4 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # 4ë‹¨ê³„: ì†ŒìŠ¤ ì„ íƒ (ê²€ìƒ‰ ì „ëµ)
        print("\n[4ë‹¨ê³„] ì†ŒìŠ¤ ì„ íƒ (ê²€ìƒ‰ ì „ëµ)")
        print("ğŸ¥„ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì°¾ì„ê¹Œìš”?")
        print("="*40)
        
        retrieval_options = {
            '1': {
                'name': 'ë§ˆìš”ë„¤ì¦ˆ (similarity_search)',
                'description': 'ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°, í´ë˜ì‹í•œ ë°©ë²•',
                'k_value': 5,
                'best_for': 'ì •í™•í•œ ë‹µë³€ì´ í•„ìš”í•œ ê²½ìš°'
            },
            '2': {
                'name': 'ë¨¸ìŠ¤íƒ€ë“œ (mmr_search)',
                'description': 'ìœ ì‚¬ì„±ê³¼ ë‹¤ì–‘ì„±ì˜ ê· í˜•, ì¤‘ë³µ ë°©ì§€',
                'k_value': 5,
                'best_for': 'ë‹¤ì–‘í•œ ê´€ì ì˜ ë‹µë³€ì´ í•„ìš”í•œ ê²½ìš°'
            },
            '3': {
                'name': 'ëœì¹˜ (diversity_search)',
                'description': 'ë‹¤ì–‘í•œ ì •ë³´ ìˆ˜ì§‘ì— íŠ¹í™”',
                'k_value': 7,
                'best_for': 'í­ë„“ì€ ì •ë³´ íƒìƒ‰ì´ í•„ìš”í•œ ê²½ìš°'
            },
            '4': {
                'name': 'ë°”ë² í (threshold_search)',
                'description': 'ì¼ì • ì ìˆ˜ ì´ìƒë§Œ ì„ íƒ, í’ˆì§ˆ ìš°ì„ ',
                'k_value': 3,
                'threshold': 0.7,
                'best_for': 'ë†’ì€ í’ˆì§ˆì˜ ë‹µë³€ë§Œ ì›í•˜ëŠ” ê²½ìš°'
            }
        }
        
        for key, option in retrieval_options.items():
            print(f"{key}. {option['name']}")
            print(f"   ğŸ“ {option['description']}")
            print(f"   ğŸ” ê²°ê³¼ ìˆ˜: {option['k_value']}ê°œ")
            print(f"   ğŸ’¡ ì¶”ì²œ: {option['best_for']}")
        
        while True:
            choice = input("\nì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-4): ").strip()
            if choice in retrieval_options:
                chosen_retrieval = retrieval_options[choice]
                custom_config['retrieval'] = chosen_retrieval
                print(f"âœ… ì„ íƒë¨: {chosen_retrieval['name']}")
                break
            else:
                print("âŒ 1-4 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # 5ë‹¨ê³„: ì‚¬ì´ë“œ ë©”ë‰´ (ì¶”ê°€ ì˜µì…˜)
        print("\n[5ë‹¨ê³„] ì‚¬ì´ë“œ ë©”ë‰´ (ì¶”ê°€ ìµœì í™”)")
        print("ğŸŸ ì¶”ê°€ ì˜µì…˜ì„ ì„ íƒí•˜ì‹œê² ì–´ìš”?")
        print("="*40)
        
        side_options = {
            '1': 'ì¿ í‚¤ (ìºì‹± í™œì„±í™”) - ë°˜ë³µ ê²€ìƒ‰ ì†ë„ í–¥ìƒ',
            '2': 'ì½œë¼ (ë¡œê¹… ê°•í™”) - ìƒì„¸í•œ ë””ë²„ê·¸ ì •ë³´',
            '3': 'ê°ìì¹© (ë°°ì¹˜ ì²˜ë¦¬) - ëŒ€ëŸ‰ íŒŒì¼ íš¨ìœ¨ì  ì²˜ë¦¬',
            '4': 'ì—†ìŒ - ê¸°ë³¸ êµ¬ì„±ë§Œ ì‚¬ìš©'
        }
        
        for key, option in side_options.items():
            print(f"{key}. {option}")
        
        side_choice = input("\nì‚¬ì´ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (1-4, ê¸°ë³¸ê°’: 4): ").strip()
        if not side_choice:
            side_choice = '4'
        
        custom_config['extras'] = side_options.get(side_choice, 'ì—†ìŒ')
        print(f"âœ… ì„ íƒë¨: {custom_config['extras']}")
        
        # ìµœì¢… ì£¼ë¬¸ í™•ì¸
        print("\n" + "="*60)
        print("ğŸ‰ ì£¼ë¬¸ ì™„ë£Œ! ë‹¹ì‹ ë§Œì˜ ì»¤ìŠ¤í…€ RAG ì±—ë´‡")
        print("="*60)
        
        print(f"ğŸ ë¹µ (í…ìŠ¤íŠ¸ ì¶”ì¶œ): {custom_config['text_extractor']['name']}")
        print(f"ğŸ§€ ì¹˜ì¦ˆ (ì²­í‚¹): {custom_config['chunking']['name']}")
        print(f"ğŸ¥¬ ì•¼ì±„ (ì„ë² ë”©): {custom_config['embedding']['name']}")
        print(f"ğŸ¥„ ì†ŒìŠ¤ (ê²€ìƒ‰): {custom_config['retrieval']['name']}")
        print(f"ğŸŸ ì‚¬ì´ë“œ (ì¶”ê°€): {custom_config['extras']}")
        
        # ì˜ˆìƒ ì„±ëŠ¥ ë¶„ì„
        print(f"\nğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ ë¶„ì„:")
        
        # ì†ë„ ì ìˆ˜ ê³„ì‚°
        speed_score = 0
        if custom_config['text_extractor']['config']['speed'] == 'fast':
            speed_score += 3
        elif custom_config['text_extractor']['config']['speed'] == 'medium':
            speed_score += 2
        else:
            speed_score += 1
            
        if custom_config['chunking']['chunk_size'] <= 1024:
            speed_score += 2
        else:
            speed_score += 1
            
        if custom_config['embedding']['dimension'] <= 512:
            speed_score += 2
        else:
            speed_score += 1
            
        # ì •í™•ë„ ì ìˆ˜ ê³„ì‚°
        accuracy_score = 0
        if 'KoBERT' in custom_config['embedding']['name']:
            accuracy_score += 3
        elif 'OpenAI' in custom_config['embedding']['name']:
            accuracy_score += 3
        else:
            accuracy_score += 2
            
        if 'recursive' in custom_config['chunking']['name']:
            accuracy_score += 2
        else:
            accuracy_score += 1
            
        print(f"   âš¡ ì²˜ë¦¬ ì†ë„: {'â˜…' * min(5, speed_score)}{'â˜†' * (5-min(5, speed_score))}")
        print(f"   ğŸ¯ ì •í™•ë„: {'â˜…' * min(5, accuracy_score)}{'â˜†' * (5-min(5, accuracy_score))}")
        
        # êµ¬ì„± ì €ì¥ ì˜µì…˜
        save_config = input("\nğŸ’¾ ì´ êµ¬ì„±ì„ ì €ì¥í•˜ì‹œê² ì–´ìš”? (y/n, ê¸°ë³¸ê°’: y): ").strip().lower()
        if save_config != 'n':
            self._save_custom_config(custom_config)
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜µì…˜
        test_config = input("ğŸ§ª ì´ êµ¬ì„±ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ì‹œê² ì–´ìš”? (y/n, ê¸°ë³¸ê°’: n): ").strip().lower()
        if test_config == 'y':
            self._test_custom_config(custom_config)
    
    def _save_custom_config(self, config: Dict[str, Any]):
        """ì»¤ìŠ¤í…€ êµ¬ì„± ì €ì¥"""
        try:
            config_dir = Path("config")
            config_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            config_file = config_dir / f"custom_chatbot_{timestamp}.json"
            
            # êµ¬ì„±ì„ ì‹¤ì œ ì„¤ì • í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            actual_config = {
                'text_extraction': {
                    'primary_extractor': config['text_extractor']['config']['pdf_extractor'],
                    'fallback_extractors': ['PyPDF2', 'pdfplumber']
                },
                'chunking': {
                    'strategy': 'recursive_character',
                    'chunk_size': config['chunking']['chunk_size'],
                    'chunk_overlap': config['chunking']['overlap']
                },
                'embedding': {
                    'model': config['embedding']['name'],
                    'dimension': config['embedding']['dimension']
                },
                'retrieval': {
                    'strategy': 'similarity_search',
                    'k': config['retrieval']['k_value']
                },
                'metadata': {
                    'created_at': datetime.now().isoformat(),
                    'description': 'ì„œë¸Œì›¨ì´ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ êµ¬ì„±',
                    'user_selections': config
                }
            }
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(actual_config, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… êµ¬ì„±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {config_file}")
            
        except Exception as e:
            print(f"âŒ êµ¬ì„± ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _test_custom_config(self, config: Dict[str, Any]):
        """ì»¤ìŠ¤í…€ êµ¬ì„± í…ŒìŠ¤íŠ¸"""
        print("\nğŸ§ª ì»¤ìŠ¤í…€ êµ¬ì„± í…ŒìŠ¤íŠ¸ ì¤‘...")
        print("-" * 40)
        
        try:
            # ê°„ë‹¨í•œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
            init_result = self.master.initialize_all()
            
            success_count = sum(1 for r in init_result.values() if r.success)
            total_count = len(init_result)
            
            print(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™”: {success_count}/{total_count} ì„±ê³µ")
            
            if success_count == total_count:
                print("ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! ì„ íƒí•˜ì‹  êµ¬ì„±ì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤.")
                print("ğŸš€ ì´ì œ ì´ ì„¤ì •ìœ¼ë¡œ ì±—ë´‡ì„ ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                print("âš ï¸  ì¼ë¶€ ì»´í¬ë„ŒíŠ¸ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
                print("ğŸ’¡ ê¸°ë³¸ êµ¬ì„±ìœ¼ë¡œ ì‹œì‘í•´ì„œ ì ì§„ì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    analyzer = FinalRAGAnalyzer()
    analyzer.run_interactive_menu()


if __name__ == "__main__":
    main()