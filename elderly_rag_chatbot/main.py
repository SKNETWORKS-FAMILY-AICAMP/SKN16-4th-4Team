# =========================================
# ğŸš€ ë…¸ì¸ë³µì§€ ì •ì±… RAG ì±—ë´‡ ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# =========================================

import os
import sys
import logging
import argparse
import asyncio
from typing import Dict, Any, Optional
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from config.settings import SystemSettings
    from src.text_extractor import WelfareDocumentExtractor
    from src.text_extraction_comparison import TextExtractionComparison
    from src.chunk_strategy import ChunkStrategyComparator
    from src.embedding_models import EmbeddingModelComparator
    from src.vector_store import WelfareVectorStore
    from src.retriever import RetrieverComparator
    from src.rag_system import ElderlyWelfareRAGChain, MultiRAGSystem
    from src.langgraph_workflow import ElderlyWelfareWorkflow
    from src.chatbot_interface import ElderlyWelfareChatbot, GradioInterface, StreamlitInterface
    from src.autorag_optimizer import AutoRAGOptimizer, AutoRAGInterface, AutoRAGConfig
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    print("í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    print("ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install -r requirements.txt")
    sys.exit(1)


class ElderlyRAGChatbotSystem:
    """ë…¸ì¸ë³µì§€ ì •ì±… RAG ì±—ë´‡ ì „ì²´ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config_path: Optional[str] = None):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        
        # ì„¤ì • ë¡œë“œ
        self.settings = SystemSettings()
        if config_path and os.path.exists(config_path):
            self.settings.load_config(config_path)
        
        # ë¡œê¹… ì„¤ì •
        self._setup_logging()
        
        # ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸
        self.document_extractor = None
        self.chunk_comparison = None
        self.embedding_comparison = None
        self.vector_store = None
        self.retriever_comparison = None
        self.rag_system = None
        self.workflow_system = None
        self.chatbot = None
        
        # ì´ˆê¸°í™” ìƒíƒœ
        self.is_initialized = False
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("ë…¸ì¸ë³µì§€ RAG ì±—ë´‡ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.settings.logging.log_directory, exist_ok=True)
        
        # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        log_file = os.path.join(
            self.settings.logging.log_directory,
            self.settings.logging.log_file_name
        )
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=getattr(logging, self.settings.logging.log_level),
            format=self.settings.logging.log_format,
            datefmt=self.settings.logging.date_format,
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
    
    async def initialize_system(self, force_rebuild: bool = False) -> bool:
        """ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        
        try:
            self.logger.info("ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
            
            # 1. ë¬¸ì„œ ì¶”ì¶œê¸° ì´ˆê¸°í™”
            self.logger.info("ğŸ“„ ë¬¸ì„œ ì¶”ì¶œê¸° ì´ˆê¸°í™”...")
            self.document_extractor = WelfareDocumentExtractor(
                data_directory=self.settings.data.data_directory,
                cache_enabled=self.settings.data.enable_document_cache,
                cache_directory=self.settings.data.cache_directory
            )
            
            # 2. ì²­í‚¹ ì „ëµ ë¹„êµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self.logger.info("âœ‚ï¸ ì²­í‚¹ ì „ëµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
            self.chunk_comparison = ChunkStrategyComparator()
            
            # 3. ì„ë² ë”© ëª¨ë¸ ë¹„êµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self.logger.info("ğŸ”¢ ì„ë² ë”© ëª¨ë¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
            self.embedding_comparison = EmbeddingModelComparator()
            
            # 4. ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
            self.logger.info("ğŸ—„ï¸ ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”...")
            
            # ìµœì  ì„ë² ë”© ëª¨ë¸ ì„ íƒ
            recommendation = self.embedding_comparison.get_model_recommendation(priority="balanced")
            best_embedding_model = recommendation.get('recommended_model', 'sentence-transformers/all-MiniLM-L6-v2')
            
            self.vector_store = WelfareVectorStore(
                persist_directory=self.settings.vector_store.persist_directory,
                collection_name=self.settings.vector_store.collection_name,
                embedding_function=best_embedding_model
            )
            
            # 5. ë¬¸ì„œ ì²˜ë¦¬ ë° ë²¡í„°í™” (í•„ìš”ì‹œ)
            if force_rebuild or not self.vector_store.collection.count():
                self.logger.info("ğŸ“š ë¬¸ì„œ ì²˜ë¦¬ ë° ë²¡í„°í™”...")
                await self._process_documents()
            else:
                self.logger.info("ğŸ“š ê¸°ì¡´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©")
            
            # 6. ê²€ìƒ‰ê¸° ë¹„êµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self.logger.info("ğŸ” ê²€ìƒ‰ê¸° ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
            self.retriever_comparison = RetrieverComparator()
            
            # 7. RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self.logger.info("ğŸ¤– RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
            
            # ìµœì  ê²€ìƒ‰ê¸° ì„ íƒ
            # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ ì‚¬ìš© (ë¹„êµ ì‹œìŠ¤í…œì€ ë‚˜ì¤‘ì— êµ¬í˜„)
            best_retriever = None
            
            self.rag_system = ElderlyWelfareRAGChain(
                retriever=best_retriever,
                llm=None,  # ê¸°ë³¸ OpenAI GPT ì‚¬ìš©
                memory_k=self.settings.rag.memory_k
            )
            
            # 8. ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self.logger.info("ğŸ”„ ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
            self.workflow_system = ElderlyWelfareWorkflow(
                retriever=best_retriever,
                llm=None,  # ë”ë¯¸ ëª¨ë“œ ì‚¬ìš©
                enable_checkpointing=True
            )
            
            # 9. ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”
            self.logger.info("ğŸ’¬ ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”...")
            self.chatbot = ElderlyWelfareChatbot(
                rag_system=self.rag_system,
                workflow_system=self.workflow_system
            )
            
            self.is_initialized = True
            self.logger.info("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def _process_documents(self):
        """ë¬¸ì„œ ì²˜ë¦¬ ë° ë²¡í„°í™”"""
        
        try:
            # ë¬¸ì„œ ì¶”ì¶œ
            self.logger.info("ë¬¸ì„œ ì¶”ì¶œ ì¤‘...")
            documents = self.document_extractor.extract_all_documents()
            
            if not documents:
                self.logger.warning("ì¶”ì¶œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            self.logger.info(f"{len(documents)}ê°œ ë¬¸ì„œ ì¶”ì¶œ ì™„ë£Œ")
            
            # ìµœì  ì²­í‚¹ ì „ëµ ì„ íƒ
            self.logger.info("ìµœì  ì²­í‚¹ ì „ëµ í‰ê°€ ì¤‘...")
            sample_texts = [doc["content"] for doc in documents[:5]]  # ìƒ˜í”Œë¡œ í‰ê°€
            
            chunk_evaluation = self.chunk_comparison.evaluate_strategies(
                sample_texts,
                criteria=["coherence", "coverage", "diversity"]
            )
            
            best_strategy = max(chunk_evaluation.items(), key=lambda x: x[1]["overall_score"])[0]
            self.logger.info(f"ìµœì  ì²­í‚¹ ì „ëµ: {best_strategy}")
            
            # ë¬¸ì„œ ì²­í‚¹
            self.logger.info("ë¬¸ì„œ ì²­í‚¹ ì¤‘...")
            chunked_documents = []
            
            for doc in documents:
                chunks = self.chunk_comparison.apply_strategy(
                    best_strategy,
                    doc["content"],
                    metadata={
                        "source": doc["source"],
                        "region": doc.get("region", ""),
                        "document_type": doc.get("document_type", "")
                    }
                )
                chunked_documents.extend(chunks)
            
            self.logger.info(f"{len(chunked_documents)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
            
            # ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€
            self.logger.info("ë²¡í„° ì €ì¥ì†Œì— ë¬¸ì„œ ì¶”ê°€ ì¤‘...")
            self.vector_store.add_documents(chunked_documents)
            
            self.logger.info("ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def run_evaluation(self) -> Dict[str, Any]:
        """ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€"""
        
        if not self.is_initialized:
            raise ValueError("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.logger.info("ğŸ” ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ì‹œì‘...")
        
        evaluation_results = {}
        
        try:
            # 1. ì²­í‚¹ ì „ëµ í‰ê°€
            if self.chunk_comparison:
                self.logger.info("ì²­í‚¹ ì „ëµ í‰ê°€...")
                # ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¡œ í‰ê°€
                sample_docs = self.document_extractor.extract_documents_by_region("ì „êµ­")[:3]
                if sample_docs:
                    sample_texts = [doc["content"] for doc in sample_docs]
                    chunk_eval = self.chunk_comparison.evaluate_strategies(sample_texts)
                    evaluation_results["chunking"] = chunk_eval
            
            # 2. ì„ë² ë”© ëª¨ë¸ í‰ê°€
            if self.embedding_comparison:
                self.logger.info("ì„ë² ë”© ëª¨ë¸ í‰ê°€...")
                embedding_eval = self.embedding_comparison.compare_models(
                    ["ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì›", "ëŒë´„ ì„œë¹„ìŠ¤", "ê¸°ì´ˆì—°ê¸ˆ"]
                )
                evaluation_results["embedding"] = embedding_eval
            
            # 3. ê²€ìƒ‰ê¸° ì„±ëŠ¥ í‰ê°€
            if self.retriever_comparison:
                self.logger.info("ê²€ìƒ‰ê¸° ì„±ëŠ¥ í‰ê°€...")
                retriever_eval = self.retriever_comparison.evaluate_retrievers(
                    ["65ì„¸ ì´ìƒ ì˜ë£Œë¹„ ì§€ì› ë°©ë²•ì€?", "ë…¸ì¸ ëŒë´„ ì„œë¹„ìŠ¤ ì‹ ì²­ ì ˆì°¨ëŠ”?"]
                )
                evaluation_results["retrieval"] = retriever_eval
            
            # 4. RAG ì‹œìŠ¤í…œ í‰ê°€ (ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ìœ¼ë¡œ)
            if self.rag_system:
                self.logger.info("RAG ì‹œìŠ¤í…œ í‰ê°€...")
                
                test_questions = [
                    "65ì„¸ ì´ìƒ ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì› ì œë„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                    "ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
                    "ë…ê±°ë…¸ì¸ì„ ìœ„í•œ ëŒë´„ ì„œë¹„ìŠ¤ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?"
                ]
                
                rag_results = []
                for question in test_questions:
                    result = self.rag_system.ask(question)
                    rag_results.append({
                        "question": question,
                        "success": result.get("success", False),
                        "response_length": len(result.get("answer", "")),
                        "sources_count": len(result.get("sources", []))
                    })
                
                evaluation_results["rag_system"] = {
                    "test_results": rag_results,
                    "success_rate": sum(r["success"] for r in rag_results) / len(rag_results),
                    "avg_response_length": sum(r["response_length"] for r in rag_results) / len(rag_results)
                }
            
            self.logger.info("âœ… ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ!")
            return evaluation_results
            
        except Exception as e:
            self.logger.error(f"âŒ ì„±ëŠ¥ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def run_interface(self, interface_type: str = "gradio", **kwargs):
        """ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰"""
        
        if not self.is_initialized:
            raise ValueError("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.logger.info(f"ğŸŒ {interface_type} ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰...")
        
        try:
            if interface_type.lower() == "gradio":
                gradio_interface = GradioInterface(self.chatbot)
                return gradio_interface.launch(
                    server_name=self.settings.interface.gradio_server_name,
                    server_port=self.settings.interface.gradio_server_port,
                    share=self.settings.interface.gradio_share,
                    debug=self.settings.interface.gradio_debug,
                    **kwargs
                )
            
            elif interface_type.lower() == "streamlit":
                streamlit_interface = StreamlitInterface(self.chatbot)
                return streamlit_interface.run_interface()
            
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¸í„°í˜ì´ìŠ¤ íƒ€ì…: {interface_type}")
                
        except Exception as e:
            self.logger.error(f"âŒ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´"""
        
        return {
            "initialized": self.is_initialized,
            "components": {
                "document_extractor": self.document_extractor is not None,
                "chunk_comparison": self.chunk_comparison is not None,
                "embedding_comparison": self.embedding_comparison is not None,
                "vector_store": self.vector_store is not None,
                "retriever_comparison": self.retriever_comparison is not None,
                "rag_system": self.rag_system is not None,
                "workflow_system": self.workflow_system is not None,
                "chatbot": self.chatbot is not None
            },
            "vector_store_count": self.vector_store.collection.count() if self.vector_store else 0,
            "settings": self.settings.get_config_dict()
        }


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì‹±
    parser = argparse.ArgumentParser(description="ë…¸ì¸ë³µì§€ ì •ì±… RAG ì±—ë´‡ ì‹œìŠ¤í…œ")
    
    parser.add_argument(
        "--config", "-c",
        type=str,
        help="ì„¤ì • íŒŒì¼ ê²½ë¡œ",
        default=None
    )
    
    parser.add_argument(
        "--interface", "-i",
        type=str,
        choices=["gradio", "streamlit", "none"],
        default="gradio",
        help="ì¸í„°í˜ì´ìŠ¤ íƒ€ì…"
    )
    
    parser.add_argument(
        "--rebuild", "-r",
        action="store_true",
        help="ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬êµ¬ì„±"
    )
    
    parser.add_argument(
        "--evaluate", "-e",
        action="store_true",
        help="ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰"
    )
    
    parser.add_argument(
        "--port", "-p",
        type=int,
        help="ì¸í„°í˜ì´ìŠ¤ í¬íŠ¸ ë²ˆí˜¸",
        default=None
    )
    
    parser.add_argument(
        "--autorag", "-a",
        action="store_true",
        help="AutoRAG ìë™ ìµœì í™” ì‹¤í–‰"
    )
    
    parser.add_argument(
        "--autorag-target",
        type=str,
        choices=["speed", "quality", "balanced"],
        default="balanced",
        help="AutoRAG ìµœì í™” ëª©í‘œ"
    )
    
    args = parser.parse_args()
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("ğŸš€ ë…¸ì¸ë³µì§€ ì •ì±… RAG ì±—ë´‡ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # AutoRAG ìë™ ìµœì í™” ì‹¤í–‰
    if args.autorag:
        print("\nğŸ¤– AutoRAG ìë™ ìµœì í™” ëª¨ë“œ")
        print("=" * 30)
        
        try:
            autorag_interface = AutoRAGInterface()
            
            # AutoRAG ì„¤ì • ìƒì„±
            autorag_config = AutoRAGConfig(
                evaluation_queries=[
                    "65ì„¸ ì´ìƒ ë…¸ì¸ ì˜ë£Œë¹„ ì§€ì›ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
                    "ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ ì‹ ì²­ ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ ìê²©ê³¼ ì‹ ì²­ ì ˆì°¨ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                    "ë…ê±°ë…¸ì¸ì„ ìœ„í•œ ëŒë´„ ì„œë¹„ìŠ¤ëŠ” ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”?",
                    "ë…¸ì¸ ì£¼ê±° ì§€ì› ì •ì±…ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                ],
                evaluation_documents=[],
                optimization_target=args.autorag_target,
                automation_level="full"
            )
            
            # ìë™ ìµœì í™” ì‹¤í–‰
            optimization_results = await autorag_interface.run_optimization(autorag_config)
            
            # ìµœì í™”ëœ ì±—ë´‡ìœ¼ë¡œ ì‹œìŠ¤í…œ êµ¬ì„±
            optimized_chatbot = autorag_interface.get_optimized_chatbot()
            
            if optimized_chatbot and args.interface != "none":
                print(f"\nğŸŒ ìµœì í™”ëœ {args.interface} ì¸í„°í˜ì´ìŠ¤ ì‹œì‘...")
                
                if args.interface == "gradio":
                    from src.chatbot_interface import GradioInterface
                    gradio_interface = GradioInterface(optimized_chatbot)
                    gradio_interface.launch(
                        server_port=args.port or 7860,
                        share=False,
                        debug=False
                    )
                elif args.interface == "streamlit":
                    from src.chatbot_interface import StreamlitInterface  
                    streamlit_interface = StreamlitInterface(optimized_chatbot)
                    streamlit_interface.run_interface()
            else:
                print("âœ… AutoRAG ìµœì í™” ì™„ë£Œ. ìµœì í™”ëœ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            return
            
        except Exception as e:
            print(f"âŒ AutoRAG ìµœì í™” ì‹¤íŒ¨: {e}")
            print("ì¼ë°˜ ëª¨ë“œë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
    
    # ì¼ë°˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = ElderlyRAGChatbotSystem(config_path=args.config)
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("âš™ï¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    success = await system.initialize_system(force_rebuild=args.rebuild)
    
    if not success:
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        sys.exit(1)
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
    status = system.get_system_status()
    print(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"ğŸ“Š ë²¡í„° ì €ì¥ì†Œ: {status['vector_store_count']}ê°œ ë¬¸ì„œ")
    
    # ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰
    if args.evaluate:
        print("\nğŸ” ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
        evaluation_results = system.run_evaluation()
        
        if "error" not in evaluation_results:
            print("âœ… ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ")
            
            # ê°„ë‹¨í•œ ê²°ê³¼ ìš”ì•½
            if "chunking" in evaluation_results:
                best_chunk = max(evaluation_results["chunking"].items(), 
                               key=lambda x: x[1]["overall_score"])
                print(f"ğŸ“ ìµœì  ì²­í‚¹ ì „ëµ: {best_chunk[0]} (ì ìˆ˜: {best_chunk[1]['overall_score']:.3f})")
            
            if "rag_system" in evaluation_results:
                success_rate = evaluation_results["rag_system"]["success_rate"]
                print(f"ğŸ¤– RAG ì‹œìŠ¤í…œ ì„±ê³µë¥ : {success_rate:.1%}")
        else:
            print(f"âŒ ì„±ëŠ¥ í‰ê°€ ì‹¤íŒ¨: {evaluation_results['error']}")
    
    # ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
    if args.interface != "none":
        print(f"\nğŸŒ {args.interface} ì¸í„°í˜ì´ìŠ¤ ì‹œì‘...")
        
        # í¬íŠ¸ ì„¤ì •
        kwargs = {}
        if args.port:
            if args.interface == "gradio":
                kwargs["server_port"] = args.port
            elif args.interface == "streamlit":
                kwargs["port"] = args.port
        
        try:
            system.run_interface(interface_type=args.interface, **kwargs)
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì‹œìŠ¤í…œ ì¢…ë£Œ")
        except Exception as e:
            print(f"\nâŒ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    else:
        print("\nâœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ (ì¸í„°í˜ì´ìŠ¤ ë¯¸ì‹¤í–‰)")
        print("ì‹œìŠ¤í…œì„ í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(main())